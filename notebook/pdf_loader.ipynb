{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion to Vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read pdf's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 PDF files\n",
      "Processing file: Attention.pdf\n",
      "Loaded 8 pages\n",
      "Processing file: Supervised.pdf\n",
      "Loaded 1 pages\n",
      "Processing file: Large_language_model.pdf\n",
      "Loaded 42 pages\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "def process_pdfs(pdf_path):\n",
    "    \"\"\"\n",
    "    Process all PDFs in a directory recursively using PyMuPDFLoader.\n",
    "\n",
    "    \"\"\"\n",
    "    document_list = []\n",
    "    pdf_dir = Path(pdf_path)\n",
    "\n",
    "    if not pdf_dir.exists():\n",
    "        raise FileNotFoundError(f\"PDF directory not found: {pdf_dir}\")\n",
    "\n",
    "    files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    print(f\"There are {len(files)} PDF files\")\n",
    "\n",
    "    for file in files:\n",
    "        print(f\"Processing file: {file.name}\")\n",
    "\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(file))\n",
    "            docs = loader.load()\n",
    "\n",
    "            for doc in docs:\n",
    "                doc.metadata[\"source_file\"] = file.name\n",
    "                doc.metadata[\"source_path\"] = str(file)\n",
    "                doc.metadata[\"file_type\"] = \"pdf\"\n",
    "                doc.metadata[\"loader\"] = \"PyMuPDFLoader\"\n",
    "\n",
    "            document_list.extend(docs)\n",
    "            print(f\"Loaded {len(docs)} pages\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file.name}: {e}\")\n",
    "\n",
    "    return document_list\n",
    "\n",
    "pdf = process_pdfs(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 0, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Attention mechanism, overview\\nAttention (machine learning)\\nIn machine learning, attention is a method that determines the importance of each component in a sequence relative\\nto the other components in that sequence. In natural language processing, importance is represented by \"soft\"\\nweights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings\\nacross a fixed-width sequence that can range from tens to millions of tokens in size.\\nUnlike \"hard\" weights, which are computed during the backwards training pass, \"soft\" weights exist only in the\\nforward pass and therefore change with every step of the input. Earlier designs implemented the attention\\nmechanism in a serial recurrent neural network (RNN) language translation system, but a more recent design,\\nnamely the transformer, removed the slower sequential RNN and relied more heavily on the faster parallel attention\\nscheme.\\nInspired by ideas about attention in humans, the attention mechanism was developed to address the weaknesses of\\nusing information from the hidden layers of recurrent neural networks. Recurrent neural networks favor more recent\\ninformation contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access\\nto any part of a sentence directly, rather than only through the previous state.\\n1950s‚Äì\\n1960s\\nPsychology and biology of attention. Cocktail party effect[1] ‚Äî focusing on content by filtering out background noise. Filter model of attention,[2] partial report\\nparadigm, and saccade control.[3]\\n1980s\\nSigma-pi units,[4] higher-order neural networks.\\n1990s\\nFast weight controllers and dynamic links between neurons, anticipating key-value mechanisms in attention.[5][6][7][8]\\n1998\\nThe bilateral filter was introduced in image processing. It uses pairwise affinity matrices to propagate relevance across elements.[9]\\n2005\\nNon-local means extended affinity-based filtering in image denoising, using Gaussian similarity kernels as fixed attention-like weights.[10]\\n2014\\nseq2seq with RNN + Attention.[11] Attention was introduced to enhance RNN encoder-decoder translation, particularly for long sentences. See Overview\\nsection.\\nAttentional Neural Networks introduced a learned feature selection mechanism using top-down cognitive modulation, showing how\\nattention weights can highlight relevant inputs.[12]\\n2015\\nAttention was extended to vision for image captioning tasks.[13][14]\\n2016\\nSelf-attention was integrated into RNN-based models to capture intra-sequence dependencies.[15][16]\\nSelf-attention was explored in decomposable attention models for natural language inference[17] and structured self-attentive\\nsentence embeddings.[18]\\n2017\\nThe Transformer architecture introduced in the research paper Attention is All You Need[19] formalized scaled dot-product self-attention:\\nRelation networks[20] and set Transformers[21] applied attention to unordered sets and relational reasoning, generalizing pairwise\\ninteraction models.\\n2018\\nNon-local neural networks[22] extended attention to computer vision by capturing long-range dependencies in space and time. Graph attention networks[23]\\napplied attention mechanisms to graph-structured data.\\n2019‚Äì\\n2020\\nEfficient Transformers, including Reformer,[24] Linformer,[25] and Performer,[26] introduced scalable approximations of attention for long sequences.\\n2019+\\nHopfield networks were reinterpreted as associative memory-based attention systems,[27] and vision transformers (ViTs) achieved competitive results in\\nimage classification.[28]\\nTransformers were adopted across scientific domains, including AlphaFold for protein folding,[29] CLIP for vision-language\\npretraining,[30] and attention-based dense segmentation models like CCNet[31] and DANet.[32]\\nAdditional surveys of the attention mechanism in deep learning are provided by Niu et al.[33] and Soydaner.[34]\\nThe major breakthrough came with self-attention, where each element in the input sequence attends to all others, enabling the model to capture global\\ndependencies. This idea was central to the Transformer architecture, which replaced recurrence with attention mechanisms. As a result, Transformers became\\nthe foundation for models like BERT, T5 and generative pre-trained transformers (GPT).[19]\\nThe modern era of machine attention was revitalized by grafting an attention mechanism (Fig 1. orange) to an Encoder-Decoder.\\nHistory\\nOverview'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 1, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Animated sequence\\nof language\\ntranslation\\nFig 1. Encoder-decoder with attention.[35] Numerical subscripts (100, 300, 500, 9k, 10k)\\nindicate vector sizes while lettered subscripts i and i ‚àí 1 indicate time steps. Pinkish\\nregions in H matrix and w vector are zero values. See Legend for details.\\nLegend\\nLabel\\nDescription\\n100\\nMax. sentence length\\n300\\nEmbedding size (word dimension)\\n500\\nLength of hidden vector\\n9k,\\n10k\\nDictionary size of input & output languages respectively.\\nx, Y\\n9k and 10k 1-hot dictionary vectors. x ‚Üí x implemented as a lookup table rather than vector multiplication. Y is the 1-hot\\nmaximizer of the linear Decoder layer D; that is, it takes the argmax of D\\'s linear layer output.\\nx\\n300-long word embedding vector. The vectors are usually pre-calculated from other projects such as GloVe or Word2Vec.\\nh\\n500-long encoder hidden vector. At each point in time, this vector summarizes all the preceding words before it. The final h can\\nbe viewed as a \"sentence\" vector, or a thought vector as Hinton calls it.\\ns\\n500-long decoder hidden state vector.\\nE\\n500 neuron recurrent neural network encoder. 500 outputs. Input count is 800‚Äì300 from source embedding + 500 from recurrent\\nconnections. The encoder feeds directly into the decoder only to initialize it, but not thereafter; hence, that direct connection is\\nshown very faintly.\\nD\\n2-layer decoder. The recurrent layer has 500 neurons and the fully-connected linear layer has 10k neurons (the size of the target\\nvocabulary).[36] The linear layer alone has 5 million (500 √ó 10k) weights ‚Äì ~10 times more weights than the recurrent layer.\\nscore\\n100-long alignment score\\nw\\n100-long vector attention weight. These are \"soft\" weights which changes during the forward pass, in contrast to \"hard\" neuronal\\nweights that change during the learning phase.\\nA\\nAttention module ‚Äì this can be a dot product of recurrent states, or the query-key-value fully-connected layers. The output is a\\n100-long vector w.\\nH\\n500√ó100. 100 hidden vectors h concatenated into a matrix\\nc\\n500-long context vector = H * w. c is a linear combination of h vectors weighted by w.\\nFigure 2 shows the internal step-by-step operation of the attention block (A) in Fig 1.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 2, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Comparison of the data flow in CNN,\\nRNN, and self-attention\\nFigure 2. The diagram shows the attention forward pass calculating correlations of the word \"that\" with other words in\\n\"See that girl run.\" Given the right weights from training, the network should be able to identify \"girl\" as a highly\\ncorrelated word. Some things to note:\\nThis example focuses on the attention of a single word \"that\". In practice, the attention of each\\nword is calculated in parallel to speed up calculations. Simply changing the lowercase \"x\"\\nvector to the uppercase \"X\" matrix will yield the formula for this.\\nSoftmax scaling qWkT / ‚àö100 prevents a high variance in qWkT that would allow a single word\\nto excessively dominate the softmax resulting in attention to only one word, as a discrete hard\\nmax would do.\\nNotation: the commonly written row-wise softmax formula above assumes that vectors are\\nrows, which runs contrary to the standard math notation of column vectors. More correctly, we\\nshould take the transpose of the context vector and use the column-wise softmax, resulting in\\nthe more correct form\\n.\\nIn translating between languages, alignment is the process of matching words from the source sentence to words of the translated sentence. Networks that\\nperform verbatim translation without regard to word order would show the highest scores along the (dominant) diagonal of the matrix. The off-diagonal\\ndominance shows that the attention mechanism is more nuanced.\\nConsider an example of translating I love you to French. On the first pass through the decoder, 94% of the attention weight is on the first English word I, so the\\nnetwork offers the word je. On the second pass of the decoder, 88% of the attention weight is on the third English word you, so it offers t\\'. On the last pass, 95%\\nof the attention weight is on the second English word love, so it offers aime.\\nIn the I love you example, the second word love is aligned with the third word aime. Stacking soft row vectors together for je, t\\', and aime yields an alignment\\nmatrix:\\nI\\nlove\\nyou\\nje\\n0.94\\n0.02\\n0.04\\nt\\'\\n0.11\\n0.01\\n0.88\\naime\\n0.03\\n0.95\\n0.02\\nSometimes, alignment can be multiple-to-multiple. For example, the English phrase look it up corresponds to cherchez-le. Thus, \"soft\" attention weights work\\nbetter than \"hard\" attention weights (setting one attention weight to 1, and the others to 0), as we would like the model to make a context vector consisting of a\\nweighted sum of the hidden vectors, rather than \"the best one\", as there may not be a best hidden vector.\\nMany variants of attention implement soft weights, such as\\nfast weight programmers, or fast weight controllers (1992).[5] A \"slow\" neural network outputs the\\n\"fast\" weights of another neural network through outer products. The slow network learns by gradient\\ndescent. It was later renamed as \"linearized self-attention\".[37]\\nBahdanau-style attention,[11] also referred to as additive attention,\\nLuong-style attention,[38] which is known as multiplicative attention,\\nEarly attention mechanisms similar to modern self-attention were proposed using recurrent neural\\nnetworks. However, the highly parallelizable self-attention was introduced in 2017 and successfully\\nused in the Transformer model,\\npositional attention and factorized positional attention.[39]\\nFor convolutional neural networks, attention mechanisms can be distinguished by the dimension on which they\\noperate, namely: spatial attention,[40] channel attention,[41] or combinations.[42][43]\\nInterpreting attention weights\\nVariants'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 3, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content=\"Both encoder & decoder are needed to\\ncalculate attention.[38]\\nBoth encoder & decoder are needed to\\ncalculate attention.[44]\\nDecoder is not used to calculate\\nattention. With only 1 input into corr, W is\\nan auto-correlation of dot products. wij =\\nxi xj.[45]\\nDecoder is not used t\\nattention.[46]\\nThese variants recombine the encoder-side inputs to redistribute those effects to each target output. Often, a correlation-style matrix of dot products provides the\\nre-weighting coefficients. In the figures below, W is the matrix of context attention weights, similar to the formula in Overview section above.\\n1. encoder-decoder dot product\\n2. encoder-decoder QKV\\n3. encoder-only dot product\\n4. encoder-o\\nLegend\\nLabel\\nDescription\\nVariables X,\\nH, S, T\\nUpper case variables represent the entire sentence, and not just the current word. For example, H is a matrix of the encoder hidden state‚Äîone word per\\ncolumn.\\nS, T\\nS, decoder hidden state; T, target word embedding. In the Pytorch Tutorial variant training phase, T alternates between 2 sources depending on the level of\\nteacher forcing used. T could be the embedding of the network's output word; i.e. embedding(argmax(FC output)). Alternatively with teacher forcing, T could\\nbe the embedding of the known correct word which can occur with a constant forcing probability, say 1/2.\\nX, H\\nH, encoder hidden state; X, input word embeddings.\\nW\\nAttention coefficients\\nQw, Kw, Vw,\\nFC\\nWeight matrices for query, key, value respectively. FC is a fully-connected weight matrix.\\n‚äï, ‚äó\\n‚äï, vector concatenation; ‚äó, matrix multiplication.\\ncorr\\nColumn-wise softmax(matrix of all combinations of dot products). The dot products are xi * xj in variant #3, hi* sj in variant 1, and column\\xa0i ( Kw * H ) *\\ncolumn\\xa0j ( Qw * S ) in variant 2, and column\\xa0i ( Kw * X ) * column\\xa0j ( Qw * X ) in variant 4. Variant 5 uses a fully-connected layer to determine the\\ncoefficients. If the variant is QKV, then the dot products are normalized by the ‚àöd where d is the height of the QKV matrices.\\nThe size of the attention matrix is proportional to the square of the number of input tokens. Therefore, when the input is long, calculating the attention matrix\\nrequires a lot of GPU memory. Flash attention is an implementation that reduces the memory needs and increases efficiency without sacrificing accuracy. It\\nachieves this by partitioning the attention computation into smaller blocks that fit into the GPU's faster on-chip memory, reducing the need to store large\\nintermediate matrices and thus lowering memory usage while increasing computational efficiency.[48]\\nFlexAttention[49] is an attention kernel developed by Meta that allows users to modify attention scores prior to softmax and dynamically chooses the optimal\\nattention algorithm.\\nAttention is widely used in natural language processing, computer vision, and speech recognition. In NLP, it improves context understanding in tasks like\\nquestion answering and summarization. In vision, visual attention helps models focus on relevant image regions, enhancing object detection and image\\ncaptioning.\\nFrom the original paper on vision transformers (ViT), visualizing attention scores as a heat map (called saliency maps or attention maps) has become an\\nimportant and routine way to inspect the decision making process of ViT models.[50] One can compute the attention maps with respect to any attention head at\\nany layer, while the deeper layers tend to show more semantically meaningful visualization. Attention rollout is a recursive algorithm to combine attention\\nscores across all layers, by computing the dot product of successive attention maps.[51]\\nOptimizations\\nFlash attention\\nFlexAttention\\nApplications\\nAttention maps as explanations for vision transformers\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 4, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Decoder multiheaded cross-attention\\nBecause vision transformers are typically trained in a self-supervised manner, attention maps are generally not class-sensitive. When a classification head\\nattached to the ViT backbone, class-discriminative attention maps (CDAM) combines attention maps and gradients with respect to the class [CLS] token.[52]\\nSome class-sensitive interpretability methods originally developed for convolutional neural networks can be also applied to ViT, such as GradCAM, which\\nback-propagates the gradients to the outputs of the final attention layer.[53]\\nUsing attention as basis of explanation for the transformers in language and vision is not without debate. While some pioneering papers analyzed and framed\\nattention scores as explanations,[54][55] higher attention scores do not always correlate with greater impact on model performances.[56]\\nFor matrices: \\n and \\n, the scaled dot-product, or QKV attention, is defined as:\\nwhere  denotes transpose and the softmax function is applied independently to every row of its argument. The matrix \\n contains \\n queries, while matrices\\n jointly contain an unordered set of  key-value pairs. Value vectors in matrix \\n are weighted using the weights resulting from the softmax operation, so\\nthat the rows of the \\n-by-\\n output matrix are confined to the convex hull of the points in \\n given by the rows of \\n.\\nTo understand the permutation invariance and permutation equivariance properties of QKV attention,[57] let \\n and \\n be permutation\\nmatrices; and \\n an arbitrary matrix. The softmax function is permutation equivariant in the sense that:\\nBy noting that the transpose of a permutation matrix is also its inverse, it follows that:\\nwhich shows that QKV attention is equivariant with respect to re-ordering the queries (rows of \\n); and invariant to re-ordering of the key-value pairs in \\n.\\nThese properties are inherited when applying linear transforms to the inputs and outputs of QKV attention blocks. For example, a simple self-attention function\\ndefined as:\\nis permutation equivariant with respect to re-ordering the rows of the input matrix \\n in a non-trivial way, because every row of the output is a function of all\\nthe rows of the input. Similar properties hold for multi-head attention, which is defined below.\\nWhen QKV attention is used as a building block for an autoregressive decoder, and when at training time all input and output matrices have  rows, a masked\\nattention variant is used:\\nwhere the mask, \\n is a strictly upper triangular matrix, with zeros on and below the diagonal and \\n in every element above the diagonal. The\\nsoftmax output, also in \\n is then lower triangular, with zeros in all elements above the diagonal. The masking ensures that for all \\n, row  of\\nthe attention output is independent of row  of any of the three input matrices. The permutation invariance and equivariance properties of standard QKV\\nattention do not hold for the masked variant.\\nMulti-head attention\\nwhere each head is computed with QKV attention as:\\nand \\n, and \\n are parameter matrices.\\nThe permutation properties of (standard, unmasked) QKV attention apply here also. For permutation matrices, \\n:\\nfrom which we also see that multi-head self-attention:\\nis equivariant with respect to re-ordering of the rows of input matrix \\n.\\nMathematical representation\\nStandard scaled dot-product attention\\nMasked attention\\nMulti-head attention'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 5, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Decoder self-attention with causal\\nmasking, detailed diagram\\nwhere \\n and \\n are learnable weight matrices.[11]\\nwhere \\n is a learnable weight matrix.[38]\\nSelf-attention is essentially the same as cross-attention, except that query, key, and value vectors all come from the same model. Both encoder and decoder can\\nuse self-attention, but with subtle differences.\\nFor encoder self-attention, we can start with a simple encoder without self-attention, such as an \"embedding layer\", which simply converts each input word into\\na vector by a fixed lookup table. This gives a sequence of hidden vectors \\n. These can then be applied to a dot-product attention mechanism, to obtain\\nor more succinctly, \\n. This can be applied repeatedly, to obtain a multilayered encoder. This is the \"encoder self-\\nattention\", sometimes called the \"all-to-all attention\", as the vector at every position can attend to every other.\\nFor decoder self-attention, all-to-all attention is inappropriate, because during the autoregressive decoding process,\\nthe decoder cannot attend to future outputs that has yet to be decoded. This can be solved by forcing the attention\\nweights \\n for all \\n, called \"causal masking\". This attention mechanism is the \"causally masked self-\\nattention\".\\nRecurrent neural network\\nseq2seq\\nTransformer (deep learning architecture)\\nAttention\\nDynamic neural network\\n1. Cherry, E. Colin (1953). \"Some Experiments on the Recognition of\\nSpeech, with One and with Two Ears\". The Journal of the\\nAcoustical Society of America. 25 (5): 975‚Äì979.\\nBibcode:1953ASAJ...25..975C (https://ui.adsabs.harvard.edu/abs/1\\n953ASAJ...25..975C). doi:10.1121/1.1907229 (https://doi.org/10.11\\n21%2F1.1907229). hdl:11858/00-001M-0000-002A-F750-3 (https://\\nhdl.handle.net/11858%2F00-001M-0000-002A-F750-3).\\n2. Broadbent, Donald E. (1958). Perception and Communication.\\nPergamon Press.\\n3. Kowler, Eileen (1995). \"The control of saccadic eye movements\".\\nReviews of Oculomotor Research. 5: 1‚Äì70.\\n4. Rumelhart, David E.; Hinton, G. E.; Mcclelland, James L. (1987-07-\\n29). \"A General Framework for Parallel Distributed Processing\" (htt\\nps://stanford.edu/~jlmcc/papers/PDP/Chapter2.pdf) (PDF). In\\nRumelhart, David E.; Hinton, G. E.; PDP Research Group (eds.).\\nParallel Distributed Processing, Volume 1: Explorations in the\\nMicrostructure of Cognition: Foundations. Cambridge,\\nMassachusetts: MIT Press. ISBN\\xa0978-0-262-68053-0.\\n5. Schmidhuber, J√ºrgen (1992). \"Learning to control fast-weight\\nmemories: an alternative to recurrent nets\". Neural Computation. 4\\n(1): 131‚Äì139. doi:10.1162/neco.1992.4.1.131 (https://doi.org/10.116\\n2%2Fneco.1992.4.1.131). S2CID\\xa016683347 (https://api.semanticsc\\nholar.org/CorpusID:16683347).\\n6. von der Malsburg, Christoph (1981). \"The correlation theory of brain\\nfunction\". Internal Report 81‚Äì2, Max-Planck-Institute for Biophysical\\nChemistry.\\n7. Feldman, Jerome A. (1982). \"Dynamic connections in neural\\nnetworks\". Biological Cybernetics. 46 (1): 27‚Äì39.\\ndoi:10.1007/BF00335349 (https://doi.org/10.1007%2FBF0033534\\n9). PMID\\xa06307398 (https://pubmed.ncbi.nlm.nih.gov/6307398).\\n8. Hinton, Geoffrey E. (1989). \"Connectionist learning procedures\".\\nArtificial Intelligence. 40 (1‚Äì3): 185‚Äì234. doi:10.1016/0004-\\n3702(89)90049-0 (https://doi.org/10.1016%2F0004-3702%2889%2\\n990049-0).\\n9. Tomasi, Carlo (1998). Bilateral filtering for gray and color images (ht\\ntps://ieeexplore.ieee.org/document/710815). ICCV.\\n10. Buades, Antoni (2005). A non-local algorithm for image denoising (h\\nttps://ieeexplore.ieee.org/document/1467423). CVPR.\\n11. Bahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014).\\n\"Neural Machine Translation by Jointly Learning to Align and\\nTranslate\". arXiv:1409.0473 (https://arxiv.org/abs/1409.0473) [cs.CL\\n(https://arxiv.org/archive/cs.CL)].\\n12. Wang, Qian (2014). Attentional Neural Network: Feature Selection\\nUsing Cognitive Feedback. NeurIPS.\\n13. Xu, Kelvin; Ba, Jimmy; Kiros, Ryan (2015). Show, Attend and Tell:\\nNeural Image Caption Generation with Visual Attention.\\narXiv:1502.03044 (https://arxiv.org/abs/1502.03044).\\n14. Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru\\n(2015). \"Show and Tell: A Neural Image Caption Generator\". 2015\\nIEEE Conference on Computer Vision and Pattern Recognition\\n(CVPR). pp.\\xa03156‚Äì3164. doi:10.1109/CVPR.2015.7298935 (https://\\ndoi.org/10.1109%2FCVPR.2015.7298935). ISBN\\xa0978-1-4673-6964-\\n0.\\n15. Cheng, Jianpeng (2016). \"Long Short-Term Memory-Networks for\\nMachine Reading\". arXiv:1601.06733 (https://arxiv.org/abs/1601.06\\n733) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n16. Paulus, Romain (2017). \"A Deep Reinforced Model for Abstractive\\nSummarization\". arXiv:1705.04304 (https://arxiv.org/abs/1705.0430\\n4) [cs.CL (https://arxiv.org/archive/cs.CL)].\\nBahdanau (additive) attention\\nLuong attention (general)\\nSelf-attention\\nMasking\\nSee also\\nReferences'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 6, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='17. Parikh, Anees (2016). Decomposable Attention Model for Natural\\nLanguage Inference. EMNLP. arXiv:1606.01933 (https://arxiv.org/ab\\ns/1606.01933).\\n18. Lin, Zichao (2017). A Structured Self-Attentive Sentence\\nEmbedding. ICLR. arXiv:1703.03130 (https://arxiv.org/abs/1703.031\\n30).\\n19. Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob;\\nJones, Llion; Gomez, Aidan N.; Kaiser, Lukasz; Polosukhin, Illia\\n(2017). \"Attention is All You Need\". arXiv:1706.03762 (https://arxiv.o\\nrg/abs/1706.03762) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n20. Santoro, Adam (2017). Relation Networks for Relational Reasoning.\\nICLR. arXiv:1706.01427 (https://arxiv.org/abs/1706.01427).\\n21. Lee, Juho (2019). Set Transformer: A Framework for Attention-\\nbased Permutation-Invariant Neural Networks. ICML.\\narXiv:1810.00825 (https://arxiv.org/abs/1810.00825).\\n22. Wang, Xiaolong (2018). Non-Local Neural Networks. CVPR.\\n23. Veliƒçkoviƒá, Petar (2018). Graph Attention Networks. ICLR.\\n24. Kitaev, Nikita (2020). Reformer: The Efficient Transformer. ICLR.\\narXiv:2001.04451 (https://arxiv.org/abs/2001.04451).\\n25. Wang, Salah (2020). Linformer: Self-Attention with Linear\\nComplexity. ICLR. arXiv:2006.04768 (https://arxiv.org/abs/2006.047\\n68).\\n26. Choromanski, Krzysztof (2020). Rethinking Attention with\\nPerformers. ICLR. arXiv:2009.14794 (https://arxiv.org/abs/2009.147\\n94).\\n27. Ramsauer, Johannes (2021). Hopfield Networks is All You Need.\\nNeurIPS. arXiv:2008.02217 (https://arxiv.org/abs/2008.02217).\\n28. Dosovitskiy, Aleksander (2021). An Image is Worth 16√ó16 Words:\\nTransformers for Image Recognition at Scale. ICLR.\\narXiv:2010.11929 (https://arxiv.org/abs/2010.11929).\\n29. Jumper, John (2021). \"Highly accurate protein structure prediction\\nwith AlphaFold\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC837\\n1605). Nature. 596 (7873): 583‚Äì589. Bibcode:2021Natur.596..583J\\n(https://ui.adsabs.harvard.edu/abs/2021Natur.596..583J).\\ndoi:10.1038/s41586-021-03819-2 (https://doi.org/10.1038%2Fs415\\n86-021-03819-2). PMC\\xa08371605 (https://www.ncbi.nlm.nih.gov/pm\\nc/articles/PMC8371605). PMID\\xa034265844 (https://pubmed.ncbi.nlm.\\nnih.gov/34265844).\\n30. Radford, Alec (2021). Learning Transferable Visual Models from\\nNatural Language Supervision. ICML.\\n31. Huang, Xiangyu (2019). CCNet: Criss-Cross Attention for Semantic\\nSegmentation. ICCV. arXiv:1811.11721 (https://arxiv.org/abs/1811.1\\n1721).\\n32. Fu, Jing (2019). Dual Attention Network for Scene Segmentation.\\nCVPR. arXiv:1809.02983 (https://arxiv.org/abs/1809.02983).\\n33. Niu, Zhaoyang; Zhong, Guoqiang; Yu, Hui (2021-09-10). \"A review\\non the attention mechanism of deep learning\" (https://www.science\\ndirect.com/science/article/pii/S092523122100477X).\\nNeurocomputing. 452: 48‚Äì62. doi:10.1016/j.neucom.2021.03.091 (h\\nttps://doi.org/10.1016%2Fj.neucom.2021.03.091). ISSN\\xa00925-2312\\n(https://search.worldcat.org/issn/0925-2312).\\n34. Soydaner, Derya (August 2022). \"Attention mechanism in neural\\nnetworks: where it comes and where it goes\" (https://link.springer.c\\nom/10.1007/s00521-022-07366-3). Neural Computing and\\nApplications. 34 (16): 13371‚Äì13385. arXiv:2204.13154 (https://arxi\\nv.org/abs/2204.13154). doi:10.1007/s00521-022-07366-3 (https://do\\ni.org/10.1007%2Fs00521-022-07366-3). ISSN\\xa00941-0643 (https://s\\nearch.worldcat.org/issn/0941-0643).\\n35. Britz, Denny; Goldie, Anna; Luong, Minh-Thanh; Le, Quoc (2017-\\n03-21). \"Massive Exploration of Neural Machine Translation\\nArchitectures\". arXiv:1703.03906 (https://arxiv.org/abs/1703.03906)\\n[cs.CV (https://arxiv.org/archive/cs.CV)].\\n36. \"Pytorch.org seq2seq tutorial\" (https://pytorch.org/tutorials/intermedi\\nate/seq2seq_translation_tutorial.html). Retrieved December 2,\\n2021.\\n37. Schlag, Imanol; Irie, Kazuki; Schmidhuber, J√ºrgen (2021). \"Linear\\nTransformers Are Secretly Fast Weight Programmers\". ICML 2021.\\nSpringer. pp.\\xa09355‚Äì9366.\\n38. Luong, Minh-Thang (2015-09-20). \"Effective Approaches to\\nAttention-Based Neural Machine Translation\". arXiv:1508.04025v5\\n(https://arxiv.org/abs/1508.04025v5) [cs.CL (https://arxiv.org/archiv\\ne/cs.CL)].\\n39. Luo, Fan; Zhang, Juan; Xu, Shenghui (3 July 2024). \"Learning\\nPositional Attention for Sequential Recommendation\" (https://www.c\\natalyzex.com/paper/learning-positional-attention-for-sequential).\\ncatalyzex.com.\\n40. Zhu, Xizhou; Cheng, Dazhi; Zhang, Zheng; Lin, Stephen; Dai,\\nJifeng (2019). \"An Empirical Study of Spatial Attention Mechanisms\\nin Deep Networks\". 2019 IEEE/CVF International Conference on\\nComputer Vision (ICCV). pp.\\xa06687‚Äì6696. arXiv:1904.05873 (https://\\narxiv.org/abs/1904.05873). doi:10.1109/ICCV.2019.00679 (https://d\\noi.org/10.1109%2FICCV.2019.00679). ISBN\\xa0978-1-7281-4803-8.\\nS2CID\\xa0118673006 (https://api.semanticscholar.org/CorpusID:11867\\n3006).\\n41. Hu, Jie; Shen, Li; Sun, Gang (2018). \"Squeeze-and-Excitation\\nNetworks\". 2018 IEEE/CVF Conference on Computer Vision and\\nPattern Recognition. pp.\\xa07132‚Äì7141. arXiv:1709.01507 (https://arxi\\nv.org/abs/1709.01507). doi:10.1109/CVPR.2018.00745 (https://doi.\\norg/10.1109%2FCVPR.2018.00745). ISBN\\xa0978-1-5386-6420-9.\\nS2CID\\xa0206597034 (https://api.semanticscholar.org/CorpusID:20659\\n7034).\\n42. Woo, Sanghyun; Park, Jongchan; Lee, Joon-Young; Kweon, In So\\n(2018-07-18). \"CBAM: Convolutional Block Attention Module\".\\narXiv:1807.06521 (https://arxiv.org/abs/1807.06521) [cs.CV (https://\\narxiv.org/archive/cs.CV)].\\n43. Georgescu, Mariana-Iuliana; Ionescu, Radu Tudor; Miron, Andreea-\\nIuliana; Savencu, Olivian; Ristea, Nicolae-Catalin; Verga, Nicolae;\\nKhan, Fahad Shahbaz (2022-10-12). \"Multimodal Multi-Head\\nConvolutional Attention with Various Kernel Sizes for Medical Image\\nSuper-Resolution\". arXiv:2204.04218 (https://arxiv.org/abs/2204.04\\n218) [eess.IV (https://arxiv.org/archive/eess.IV)].\\n44. Neil Rhodes (2021). CS 152 NN‚Äî27: Attention: Keys, Queries, &\\nValues (https://www.youtube.com/watch?v=rA28vBqN4RM). Event\\noccurs at 06:30. Retrieved 2021-12-22.\\n45. Alfredo Canziani & Yann Lecun (2021). NYU Deep Learning\\ncourse, Spring 2020 (https://www.youtube.com/watch?v=f01J0Dri-6\\nk). Event occurs at 05:30. Retrieved 2021-12-22.\\n46. Alfredo Canziani & Yann Lecun (2021). NYU Deep Learning\\ncourse, Spring 2020 (https://www.youtube.com/watch?v=f01J0Dri-6\\nk). Event occurs at 20:15. Retrieved 2021-12-22.\\n47. Robertson, Sean. \"NLP From Scratch: Translation With a Sequence\\nTo Sequence Network and Attention\" (https://pytorch.org/tutorials/int\\nermediate/seq2seq_translation_tutorial.html). pytorch.org.\\nRetrieved 2021-12-22.\\n48. Mittal, Aayush (2024-07-17). \"Flash Attention: Revolutionizing\\nTransformer Efficiency\" (https://www.unite.ai/flash-attention-revoluti\\nonizing-transformer-efficiency/). Unite.AI. Retrieved 2024-11-16.\\n49. \"FlexAttention: The Flexibility of PyTorch with the Performance of\\nFlashAttention ‚Äì PyTorch\" (https://pytorch.org/blog/flexattention/).\\n50. Dosovitskiy, Alexey; Beyer, Lucas; Kolesnikov, Alexander;\\nWeissenborn, Dirk; Zhai, Xiaohua; Unterthiner, Thomas; Dehghani,\\nMostafa; Minderer, Matthias; Heigold, Georg (2021-06-03), An\\nImage is Worth 16x16 Words: Transformers for Image Recognition\\nat Scale, arXiv:2010.11929 (https://arxiv.org/abs/2010.11929)\\n51. Abnar, Samira; Zuidema, Willem (2020-05-31), Quantifying\\nAttention Flow in Transformers, arXiv:2005.00928 (https://arxiv.org/\\nabs/2005.00928)\\n52. Brocki, Lennart; Binda, Jakub; Chung, Neo Christopher (2024-10-\\n25), Class-Discriminative Attention Maps for Vision Transformers,\\narXiv:2312.02364 (https://arxiv.org/abs/2312.02364)\\n53. Gildenblat, Jacob (2025-07-21), jacobgil/pytorch-grad-cam (https://g\\nithub.com/jacobgil/pytorch-grad-cam), retrieved 2025-07-21\\n54. Mullenbach, James; Wiegreffe, Sarah; Duke, Jon; Sun, Jimeng;\\nEisenstein, Jacob (2018-04-16), Explainable Prediction of Medical\\nCodes from Clinical Text, arXiv:1802.05695 (https://arxiv.org/abs/18\\n02.05695)\\n55. Bahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2016-05-\\n19), Neural Machine Translation by Jointly Learning to Align and\\nTranslate, arXiv:1409.0473 (https://arxiv.org/abs/1409.0473)\\n56. Serrano, Sofia; Smith, Noah A. (2019-06-09), Is Attention\\nInterpretable?, arXiv:1906.03731 (https://arxiv.org/abs/1906.03731)\\n57. Lee, Juho; Lee, Yoonho; Kim, Jungtaek; Kosiorek, Adam R; Choi,\\nSeungjin; Teh, Yee Whye (2018). \"Set Transformer: A Framework\\nfor Attention-based Permutation-Invariant Neural Networks\".\\narXiv:1810.00825 (https://arxiv.org/abs/1810.00825) [cs.LG (https://\\narxiv.org/archive/cs.LG)].'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 7, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Olah, Chris; Carter, Shan (September 8, 2016). \"Attention and Augmented Recurrent Neural Networks\" (https://distill.pub/2016/augmented-rn\\nns/). Distill. 1 (9). Distill Working Group. doi:10.23915/distill.00001 (https://doi.org/10.23915%2Fdistill.00001).\\nDan Jurafsky and James H. Martin (2022). Speech and Language Processing (3rd ed. draft, January 2022) (https://web.stanford.edu/~jurafsk\\ny/slp3/) ‚Äî Chapter 10.4 (Attention) and Chapter 9.7 (Self-Attention Networks: Transformers)\\nAlex Graves (2020). Attention and Memory in Deep Learning (https://www.youtube.com/watch?v=AIiwuClvH6k) ‚Äî video lecture from\\nDeepMind / UCL\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Attention_(machine_learning)&oldid=1328840996\"\\nExternal links'),\n",
       " Document(metadata={'producer': 'macOS Version 26.2 (Build 25C56) Quartz PDFContext', 'creator': '', 'creationdate': \"D:20260113133043Z00'00'\", 'source': '../data/PDF_files/Supervised.pdf', 'file_path': '../data/PDF_files/Supervised.pdf', 'total_pages': 1, 'format': 'PDF 1.3', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': \"D:20260113133043Z00'00'\", 'trapped': '', 'modDate': \"D:20260113133043Z00'00'\", 'creationDate': \"D:20260113133043Z00'00'\", 'page': 0, 'source_file': 'Supervised.pdf', 'source_path': '../data/PDF_files/Supervised.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='In machine learning, supervised learning(SL) is a type of machine learning \\nparadigm where an algorithm learns to map input data to a specific output based on \\nexample input-output pairs. This process involves training a statistical model using \\nlabeled data, meaning each piece of input data is provided with the correct output. \\nFor instance, if you want a model to identify cats in images, supervised learning \\nwould involve feeding it many images of cats (inputs) that are explicitly labeled \"cat\" \\n(outputs). \\nThe goal of supervised learning is for the trained model to accurately predict the \\noutput for new, unseen data. This requires the algorithm to effectively generalize \\nfrom the training examples, a quality measured by its generalization error. \\nSupervised learning is commonly used for tasks like classification (predicting a \\ncategory, e.g., spam or not spam) and regression (predicting a continuous value, \\ne.g., house prices). \\nSteps to follow \\nTo solve a given problem of supervised learning, the following steps must be \\nperformed: \\nAlgorithm choice \\nA wide range of supervised learning algorithms are available, each with its strengths \\nand weaknesses. There is no single learning algorithm that works best on all \\nsupervised learning problems . \\nThere are four major issues to consider in supervised learning: \\nBias‚Äìvariance tradeoff  \\nA first issue is the tradeoff between bias and variance. Imagine that we have \\navailable several different, but equally good, training data sets. A learning algorithm \\nis biased for a particular input ùë•\\n if, when trained on each of these data sets, it is \\nsystematically incorrect when predicting the correct output for ùë•\\n. A learning \\nalgorithm has high variance for a particular input ùë•\\n if it predicts different output \\nvalues when trained on different training sets. The prediction error of a learned \\nclassifier is related to the sum of the bias and the variance of the learning algorithm. \\nGenerally, there is a tradeoff between bias and variance. A learning algorithm with \\nlow bias must be \"flexible\" so that it can fit the data well. But if the learning algorithm \\nis too flexible, it will fit each training data set differently, and hence have high \\nvariance. A key aspect of many supervised learning methods is that they are able to \\nadjust this tradeoff between bias and variance (either automatically or by providing a \\nbias/variance parameter that the user can adjust).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 0, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content=\"Large language model\\nA large language model (LLM) is a language model trained with self-supervised machine learning on a\\nvast amount of text, designed for natural language processing tasks, especially language generation.[1][2]\\nThe largest and most capable LLMs are generative pre-trained transformers (GPTs) and provide the core\\ncapabilities of modern chatbots. LLMs can be fine-tuned for specific tasks or guided by prompt\\nengineering.[3] These models acquire predictive power regarding syntax, semantics, and ontologies[4]\\ninherent in human language corpora, but they also inherit inaccuracies and biases present in the data they\\nare trained on.[5]\\nThey consist of billions to trillions of parameters and operate as general-purpose sequence models,\\ngenerating, summarizing, translating, and reasoning over text. LLMs represent a significant new\\ntechnology in their ability to generalize across tasks with minimal task-specific supervision, enabling\\ncapabilities like conversational agents, code generation, knowledge retrieval, and automated reasoning\\nthat previously required bespoke systems.[6]\\nLLMs evolved from earlier statistical and recurrent neural network approaches to language modeling.\\nThe transformer architecture, introduced in 2017, replaced recurrence with self-attention, allowing\\nefficient parallelization, longer context handling, and scalable training on unprecedented data volumes.[7]\\nThis innovation enabled models like GPT, BERT, and their successors, which demonstrated emergent\\nbehaviors at scale, such as few-shot learning and compositional reasoning.[8]\\nReinforcement learning, particularly policy gradient algorithms, has been adapted to fine-tune LLMs for\\ndesired behaviors beyond raw next-token prediction.[9] Reinforcement learning from human feedback\\n(RLHF) applies these methods to optimize a policy, the LLM's output distribution, against reward signals\\nderived from human or automated preference judgments.[10] This has been critical for aligning model\\noutputs with user expectations, improving factuality, reducing harmful responses, and enhancing task\\nperformance.\\nBenchmark evaluations for LLMs have evolved from narrow linguistic assessments toward\\ncomprehensive, multi-task evaluations measuring reasoning, factual accuracy, alignment, and\\nsafety.[11][12] Hill climbing, iteratively optimizing models against benchmarks, has emerged as a\\ndominant strategy, producing rapid incremental performance gains but raising concerns of overfitting to\\nbenchmarks rather than achieving genuine generalization or robust capability improvements.[13]\\nBefore the emergence of transformer-based models in 2017, some language models were considered large\\nrelative to the computational and data constraints of their time. In the early 1990s, IBM's statistical\\nmodels pioneered word alignment techniques for machine translation, laying the groundwork for corpus-\\nbased language modeling. In 2001, a smoothed n-gram model, such as those employing Kneser‚ÄìNey\\nHistory\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 1, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='The number of publications about large\\nlanguage models by year grouped by\\npublication types.\\nThe training compute of notable large\\nmodels in FLOPs vs publication date over\\nthe period 2010‚Äì2024. For overall\\nnotable models (top left), frontier models\\n(top right), top language models (bottom\\nleft) and top models within leading\\ncompanies (bottom right). The majority of\\nthese models are language models.\\nThe training compute of notable large AI\\nmodels in FLOPs vs publication date over\\nthe period 2017‚Äì2024. The majority of\\nlarge models are language models or\\nmultimodal models with language\\ncapacity.\\nsmoothing, trained on 300 million words, achieved state-of-\\nthe-art perplexity on benchmark tests.[14] During the 2000s,\\nwith the rise of widespread internet access, researchers began\\ncompiling massive text datasets from the web (\"web as\\ncorpus\"[15]) to train statistical language models.[16][17]\\nMoving beyond n-gram models, researchers started in 2000 to\\nuse neural networks to learn language models.[18] Following\\nthe breakthrough of deep neural networks in image\\nclassification around 2012,[19] similar architectures were\\nadapted for language tasks. This shift was marked by the\\ndevelopment of word embeddings (eg, Word2Vec by Mikolov\\nin 2013) and sequence-to-sequence (seq2seq) models using\\nLSTM. In 2016, Google transitioned its translation service to\\nneural machine translation (NMT), replacing statistical\\nphrase-based models with deep recurrent neural networks.\\nThese early NMT systems used LSTM-based encoder-\\ndecoder architectures, as they preceded the invention of\\ntransformers.\\nAt the 2017 NeurIPS conference, Google researchers\\nintroduced the transformer architecture in their landmark\\npaper \"Attention Is All You Need\".[20] This paper\\'s goal was\\nto improve upon 2014 seq2seq technology,[21] and was based\\nmainly on the attention mechanism developed by Bahdanau et\\nal. in 2014.[22] The following year in 2018, BERT was\\nintroduced and quickly became \"ubiquitous\".[23] Though the\\noriginal transformer has both encoder and decoder blocks,\\nBERT is an encoder-only model. Academic and research\\nusage of BERT began to decline in 2023, following rapid\\nimprovements in the abilities of decoder-only models (such as\\nGPT) to solve tasks via prompting.[24]\\nAlthough decoder-only GPT-1 was introduced in 2018, it was\\nGPT-2 in 2019 that caught widespread attention because\\nOpenAI claimed to have initially deemed it too powerful to\\nrelease publicly, out of fear of malicious use.[25] GPT-3 in\\n2020 went a step further and as of 2025 is available only via\\nAPI with no offering of downloading the model to execute\\nlocally. But it was the 2022 consumer-facing chatbot\\nChatGPT that received extensive media coverage and public\\nattention.[26] The 2023 GPT-4 was praised for its increased\\naccuracy and as a \"holy grail\" for its multimodal\\ncapabilities.[27] OpenAI did not reveal the high-level\\narchitecture and the number of parameters of GPT-4. The\\nrelease of ChatGPT led to an uptick in LLM usage across\\nseveral research subfields of computer science, including'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 2, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='An illustration of the main components of the\\ntransformer model from the original paper, where\\nlayers were normalized after (instead of before)\\nmultiheaded attention\\nrobotics, software engineering, and societal\\nimpact work.[24] In 2024 OpenAI released the\\nreasoning model OpenAI o1, which generates\\nlong chains of thought before returning a final\\nanswer.[28] Many LLMs with parameter counts\\ncomparable to those of OpenAI\\'s GPT series\\nhave been developed.[29]\\nSince 2022, open-weight models have been\\ngaining popularity, especially at first with\\nBLOOM and LLaMA, though both have\\nrestrictions on usage and deployment. Mistral\\nAI\\'s models Mistral 7B and Mixtral 8x7b have a\\nmore permissive Apache License. In January\\n2025, DeepSeek released DeepSeek R1, a 671-\\nbillion-parameter \\nopen-weight \\nmodel \\nthat\\nperforms comparably to OpenAI o1 but at a\\nmuch lower price per token for users.[30]\\nSince 2023, many LLMs have been trained to be\\nmultimodal, having the ability to also process or generate other types of data, such as images, audio, or\\n3D meshes.[31] These LLMs are also called large multimodal models (LMMs),[32] or multimodal large\\nlanguage models (MLLMs).[33][34]\\nAs of 2024, the largest and most capable models are all based on the transformer architecture. Some\\nrecent implementations are based on other architectures, such as recurrent neural network variants and\\nMamba (a state space model).[35][36][37]\\nOpen-weight LLMs have increasingly shaped the field since 2023, contributing to broader participation in\\nAI development and greater transparency in model evaluation. Vake et al. (2025) demonstrated that\\ncommunity-driven contributions to open-weight models measurably improve their efficiency and\\nperformance, with user participation growing rapidly on collaborative platforms such as Hugging\\nFace.[38] Paris et al. (2025) further argued that openness in AI should extend beyond releasing model\\ncode or weights to encompass inclusiveness, accountability, and ethical responsibility in AI research and\\ndeployment.[39] Collectively, these studies highlight that open-weight LLMs can accelerate innovation\\nand enhance scientific reproducibility, while fostering a more transparent and participatory AI ecosystem.\\nAs machine learning algorithms process numbers rather than text, the text must be converted to numbers.\\nIn the first step, a vocabulary is decided upon, then integer indices are arbitrarily but uniquely assigned to\\neach vocabulary entry, and finally, an embedding is associated to the integer index. Algorithms include\\nbyte-pair encoding (BPE) and WordPiece. There are also special tokens serving as control characters,\\nsuch as [MASK] for masked-out token (as used in BERT), and [UNK] (\"unknown\") for characters not\\nDataset preprocessing\\nTokenization'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 3, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='appearing in the vocabulary. Also, some special symbols are used to denote special text formatting. For\\nexample, \"ƒ†\" denotes a preceding whitespace in RoBERTa and GPT and \"##\" denotes continuation of a\\npreceding word in BERT.[40]\\nFor example, the BPE tokenizer used by the legacy version of GPT-3 would split tokenizer: texts ->\\nseries of numerical \"tokens\" as\\ntokenizer:\\xa0texts\\xa0->series\\xa0of\\xa0numerical\\xa0\"tokens\"\\nTokenization also compresses the datasets. Because LLMs generally require input to be an array that is\\nnot jagged, the shorter texts must be \"padded\" until they match the length of the longest one. The average\\nnumber of words per token depends on the language.[41][42] In English, the ratio is typically around 0.75\\nwords per token, with 4 characters per token on average.[43]\\nAs an example, consider a tokenizer based on byte-pair encoding. In the first step, all unique characters\\n(including blanks and punctuation marks) are treated as an initial set of n-grams (i.e. initial set of uni-\\ngrams). Successively the most frequent pair of adjacent characters is merged into a bi-gram and all\\ninstances of the pair are replaced by it. All occurrences of adjacent pairs of (previously merged) n-grams\\nthat most frequently occur together are then again merged into even lengthier n-gram, until a vocabulary\\nof prescribed size is obtained. After a tokenizer is trained, any text can be tokenized by it, as long as it\\ndoes not contain characters not appearing in the initial-set of uni-grams.[44]\\nA token vocabulary based on the frequencies extracted from mainly English corpora uses as few tokens as\\npossible for an average English word. However, an average word in another language encoded by such an\\nEnglish-optimized tokenizer is split into a suboptimal amount of tokens. GPT-2 tokenizer can use up to\\n15 times more tokens per word for some languages, for example for the Shan language from Myanmar.\\nEven more widespread languages such as Portuguese and German have \"a premium of 50%\" compared to\\nEnglish.[42]\\nIn the context of training LLMs, datasets are typically cleaned by removing low-quality, duplicated, or\\ntoxic data.[45] Cleaned datasets can increase training efficiency and lead to improved downstream\\nperformance.[46][47] A trained LLM can be used to clean datasets for training a further LLM.[48]\\nWith the increasing proportion of LLM-generated content on the web, data cleaning in the future may\\ninclude filtering out such content. LLM-generated content can pose a problem if the content is similar to\\nhuman text (making filtering difficult) but of lower quality (degrading performance of models trained on\\nit).[3]\\nTraining of largest language models might need more linguistic data than naturally available, or that the\\nnaturally occurring data is of insufficient quality. In these cases, synthetic data might be used. Microsoft\\'s\\nPhi series of LLMs is trained on textbook-like data generated by another LLM.[49]\\nByte-pair encoding\\nProblems\\nDataset cleaning\\nSynthetic data'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 4, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='An LLM is a type of foundation model (large X model) trained on language. LLMs can be trained in\\ndifferent ways. In particular, GPT models are first pretrained to predict the next word on a large amount\\nof data, before being fine-tuned.[50]\\nSubstantial infrastructure is necessary for\\ntraining the largest models. The tendency\\ntowards larger models is visible in the list\\nof large language models. For example,\\nthe training of GPT-2 (i.e. a 1.5-billion-\\nparameters model) in 2019 cost $50,000,\\nwhile training of the PaLM (i.e. a 540-\\nbillion-parameters model) in 2022 cost\\n$8 million, and Megatron-Turing NLG\\n530B (in 2021) cost around $11 million.\\nThe qualifier \"large\" in \"large language\\nmodel\" is inherently vague, as there is no\\ndefinitive threshold for the number of parameters required to qualify as \"large\". GPT-1 of 2018 has 117\\nmillion parameters.\\nBefore being fine-tuned, most LLMs are next-token predictors. The fine-tuning shapes the LLM\\'s\\nbehavior via techniques like reinforcement learning from human feedback (RLHF)[51] or constitutional\\nAI.[52]\\nInstruction fine-tuning is a form of supervised learning used to teach LLMs to follow user instructions. In\\n2022, OpenAI demonstrated InstructGPT, a version of GPT-3 similarly fine-tuned to follow\\ninstructions.[53]\\nReinforcement learning from human feedback (RLHF) involves training a reward model to predict which\\ntext humans prefer. Then, the LLM can be fine-tuned through reinforcement learning to better satisfy this\\nreward model. Since humans typically prefer truthful, helpful and harmless answers, RLHF favors such\\nanswers.[54]\\nLLMs are generally based on the transformer architecture, which leverages an attention mechanism that\\nenables the model to process relationships between all elements in a sequence simultaneously, regardless\\nof their distance from each other.\\nTraining\\nCost\\nFine-tuning\\nArchitecture'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 5, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='When each head calculates, according to its own\\ncriteria, how much other tokens are relevant for the\\n\"it_\" token, note that the second attention head,\\nrepresented by the second column, is focusing most on\\nthe first two rows, i.e. the tokens \"The\" and \"animal\",\\nwhile the third column is focusing most on the bottom\\ntwo rows, i.e. on \"tired\", which has been tokenized into\\ntwo tokens.[55]\\nIn order to find out which tokens are relevant to\\neach other within the scope of the context\\nwindow, the attention mechanism calculates\\n\"soft\" weights for each token, more precisely for\\nits embedding, by using multiple attention heads,\\neach with its own \"relevance\" for calculating its\\nown soft weights. For example, the small (i.e.\\n117M parameter sized) GPT-2 model has had\\ntwelve attention heads and a context window of\\nonly 1k tokens.[56] In its medium version it has\\n345M parameters and contains 24 layers, each\\nwith 12 attention heads. For the training with\\ngradient descent a batch size of 512 was\\nutilized.[44]\\nGoogle\\'s Gemini 1.5, introduced in February\\n2024, can have a context window of up to 1\\nmillion tokens.[57]\\nA model may be pre-trained either to predict how\\nthe segment continues, or what is missing in the\\nsegment, given a segment from its training\\ndataset.[58] It can be either\\nautoregressive (i.e. predicting how the\\nsegment continues, as GPTs do): for\\nexample given a segment \"I like to eat\",\\nthe model predicts \"ice cream\", or\\n\"sushi\".\\n\"masked\" (i.e. filling in the parts missing\\nfrom the segment, the way \"BERT\"[59]\\ndoes it): for example, given a segment \"I\\nlike to [__] [__] cream\", the model\\npredicts that \"eat\" and \"ice\" are missing.\\nModels may be trained on auxiliary tasks which test their understanding of the data distribution, such as\\nnext sentence prediction (NSP), in which pairs of sentences are presented and the model must predict\\nwhether they appear consecutively in the training corpus.[59] During training, regularization loss is also\\nused to stabilize training. However regularization loss is usually not used during testing and evaluation.\\nA mixture of experts (MoE) is a machine learning architecture in which multiple specialized neural\\nnetworks (\"experts\") work together, with a gating mechanism that routes each input to the most\\nappropriate expert(s). Mixtures of experts can reduce inference costs, as only a fraction of the parameters\\nare used for each input. The approach was introduced in 2017 by Google researchers.[60][61][62]\\nAttention mechanism and context window\\nMixture of experts'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 6, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Typically, LLMs are trained with single- or half-precision floating point numbers (float32 and float16).\\nOne float16 has 16 bits, or 2 bytes, and so one billion parameters require 2 gigabytes. The largest models\\ntypically have more than 100 billion parameters, which places them outside the range of most consumer\\nelectronics.[63]\\nPost-training quantization[64] aims to decrease the space requirement by lowering precision of the\\nparameters of a trained model, while preserving most of its performance. Quantization can be further\\nclassified as static quantization if the quantization parameters are determined beforehand (typically\\nduring a calibration phase), and dynamic quantization if the quantization is applied during inference. The\\nsimplest form of quantization simply truncates all the parameters to a given number of bits: this is\\napplicable to static as well as dynamic quantization, but loses much precision. Dynamic quantization\\nallows for the use of a different quantization codebook per layer, either a lookup table of values or a\\nlinear mapping (scaling factor and bias), at the cost of foregoing the possible speed improvements from\\nusing lower-precision arithmetic.\\nQuantized models are typically seen as frozen with modification of weights (e.g. fine-tuning) only\\napplied to the original model. It is possible to fine-tune quantized models using low-rank adaptation.[65]\\nBeyond basic text generation, various techniques have been developed to extend LLM capabilities,\\nincluding the use of external tools and data sources, improved reasoning on complex problems, and\\nenhanced instruction-following or autonomy through prompting methods.\\nIn 2020, OpenAI researchers demonstrated that their new model GPT-3 could understand what format to\\nuse given a few rounds of Q and A (or other type of task) in the input data as example, thanks in part due\\nto the RLHF technique. This technique, called few-shot prompting, allows LLMs to be adapted to any\\ntask without requiring fine-tuning.[3] Also in 2022, it was found that the base GPT-3 model can generate\\nan instruction based on user input. The generated instruction along with user input is then used as input to\\nanother instance of the model under a \"Instruction: [...], Input: [...], Output:\" format. The other instance is\\nable to complete the output and often produces the correct answer in doing so. The ability to \"self-\\ninstruct\" makes LLMs able to bootstrap themselves toward a correct answer.[66]\\nAn LLM can be turned into a chatbot by specializing it for conversation. User input is prefixed with a\\nmarker such as \"Q:\" or \"User:\" and the LLM is asked to predict the output after a fixed \"A:\" or\\n\"Assistant:\". This type of model became commercially available in 2022 with ChatGPT, a sibling model\\nof InstructGPT fine-tuned to accept and produce dialog-formatted text based on GPT-3.5. It could\\nParameter size\\nQuantization\\nExtensibility\\nPrompt engineering\\nDialogue processing (chatbot)'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 7, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='similarly follow user instructions. Before the stream of User and Assistant lines, a chat context usually\\nstart with a few lines of overarching instructions, from a role called \"developer\" or \"system\" to convey a\\nhigher authority than the user\\'s input. This is called a \"system prompt\".\\nRetrieval-augmented generation (RAG) is an approach that integrates LLMs with document retrieval\\nsystems. Given a query, a document retriever is called to retrieve the most relevant documents. This is\\nusually done by encoding the query and the documents into vectors, then finding the documents with\\nvectors (usually stored in a vector database) most similar to the vector of the query. The LLM then\\ngenerates an output based on both the query and context included from the retrieved documents.[67]\\nTool use is a mechanism that enables LLMs to interact with external systems, applications, or data\\nsources. It can allow for example to fetch real-time information from an API or to execute code. A\\nprogram separate from the LLM watches the output stream of the LLM for a special tool-calling syntax.\\nWhen these special tokens appear, the program calls the tool accordingly and feeds its output back into\\nthe LLM\\'s input stream.[68]\\nEarly tool-using LLMs were fine-tuned on the use of specific tools. But fine-tuning LLMs for the ability\\nto read API documentation and call API correctly has greatly expanded the range of tools accessible to an\\nLLM.[69][70] Describing available tools in the system prompt can also make an LLM able to use tools. A\\nsystem prompt instructing ChatGPT (GPT-4) to use multiple types of tools can be found online.[71]\\nAn LLM is typically not an autonomous agent by itself, as it lacks the ability to interact with dynamic\\nenvironments, recall past behaviors, and plan future actions. But it can be transformed into an agent by\\nadding supporting elements: the role (profile) and the surrounding environment of an agent can be\\nadditional inputs to the LLM, while memory can be integrated as a tool or provided as additional input.\\nInstructions and input patterns are used to make the LLM plan actions and tool use is used to potentially\\ncarry out these actions.[72]\\nThe ReAct pattern, a portmanteau of reason and act, constructs an agent out of an LLM, using the LLM\\nas a planner. The LLM is prompted to \"think out loud\". Specifically, the language model is prompted with\\na textual description of the environment, a goal, a list of possible actions, and a record of the actions and\\nobservations so far. It generates one or more thoughts before generating an action, which is then executed\\nin the environment.[73]\\nIn the DEPS (\"describe, explain, plan and select\") method, an LLM is first connected to the visual world\\nvia image descriptions. It is then prompted to produce plans for complex tasks and behaviors based on its\\npretrained knowledge and the environmental feedback it receives.[74]\\nThe Reflexion method constructs an agent that learns over multiple episodes. At the end of each episode,\\nthe LLM is given the record of the episode, and prompted to think up \"lessons learned\", which would\\nhelp it perform better at a subsequent episode. These \"lessons learned\" are stored as a form of long-term\\nmemory and given to the agent in the subsequent episodes.[75]\\nRetrieval-augmented generation\\nTool use\\nAgency'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 8, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Monte Carlo tree search can use an LLM as rollout heuristic. When a programmatic world model is not\\navailable, an LLM can also be prompted with a description of the environment to act as world model.[76]\\nFor open-ended exploration, an LLM can be used to score observations for their \"interestingness\", which\\ncan be used as a reward signal to guide a normal (non-LLM) reinforcement learning agent.[77]\\nAlternatively, it can propose increasingly difficult tasks for curriculum learning.[78] Instead of outputting\\nindividual actions, an LLM planner can also construct \"skills\", or functions for complex action\\nsequences. The skills can be stored and later invoked, allowing increasing levels of abstraction in\\nplanning.[78]\\nMultiple agents with memory can interact socially.[79]\\nLLMs are conventionally trained to generate an output without generating intermediate steps. As a result,\\ntheir performance tends to be subpar on complex questions requiring (at least in humans) intermediate\\nsteps of thought. Early research demonstrated that inserting intermediate \"scratchpad\" computations\\ncould improve performance on such tasks.[80] Later methods overcame this deficiency more\\nsystematically by breaking tasks into smaller steps for the LLM, either manually or automatically.\\nPrompt chaining was introduced in 2022.[81] In this method, a user manually breaks a complex problem\\ndown into several steps. In each step, the LLM receives as input a prompt telling it what to do and some\\nresults from preceding steps. The result from one step is then reused in a next step, until a final answer is\\nreached. The ability of an LLM to follow instructions means that even non-experts can write a successful\\ncollection of stepwise prompts given a few rounds of trial and error.[82][83]\\nA 2022 paper demonstrated a separate technique called chain-of-thought prompting, which makes the\\nLLM break the question down autonomously. An LLM is given some examples where the \"assistant\"\\nverbally breaks down the thought process before arriving at an answer. The LLM mimics these examples\\nand also tries to spend some time generating intermediate steps before providing the final answer. This\\nadditional step elicited by prompting improves the correctness of the LLM on relatively complex\\nquestions. On math word questions, a prompted model can exceed even fine-tuned GPT-3 with a\\nverifier.[84][85] Chain-of-thought can also be elicited by simply adding an instruction like \"Let\\'s think step\\nby step\" to the prompt, in order to encourage the LLM to proceed methodically instead of trying to\\ndirectly guess the answer.[86]\\nIn late 2024, a new approach to LLM development emerged with \"reasoning models\".[87] These are\\ntrained to generate step-by-step analysis before producing final answers, enabling better results on\\ncomplex tasks, for instance in mathematics, coding and logic.[88] OpenAI introduced this concept with\\ntheir o1 model in September 2024, followed by o3 in April 2025. On the International Mathematics\\nOlympiad qualifying exam problems, GPT-4o achieved 13% accuracy while o1 reached 83%.[89]\\nReasoning\\nChaining\\nModel-native reasoning'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 9, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='In January 2025, the Chinese company DeepSeek released DeepSeek-R1, a 671-billion-parameter open-\\nweight reasoning model that achieved comparable performance to OpenAI\\'s o1 while being significantly\\nmore cost-effective to operate. Unlike proprietary models from OpenAI, DeepSeek-R1\\'s open-weight\\nnature allowed researchers to study and build upon the algorithm, though its training data remained\\nprivate.[90]\\nThese reasoning models typically require more computational resources per query compared to traditional\\nLLMs, as they perform more extensive processing to work through problems step-by-step.[89]\\nInference optimization refers to techniques that improve LLM performance by applying additional\\ncomputational resources during the inference process, rather than requiring model retraining. These\\napproaches implement various state-of-the-art reasoning and decision-making strategies to enhance\\naccuracy and capabilities.\\nOptiLLM is an OpenAI API-compatible optimizing inference proxy that implements multiple inference\\noptimization techniques simultaneously.[91] The system acts as a transparent proxy that can work with\\nany LLM provider, implementing techniques such as Monte Carlo tree search (MCTS), mixture of agents\\n(MOA), best-of-N sampling, and chain-of-thought reflection. OptiLLM demonstrates that strategic\\napplication of computational resources at inference time can substantially improve model performance\\nacross diverse tasks, achieving significant improvements on benchmarks such as the AIME 2024\\nmathematics competition and various coding challenges.[92]\\nThese inference optimization approaches represent a growing category of tools that enhance existing\\nLLMs without requiring access to model weights or retraining, making advanced reasoning capabilities\\nmore accessible across different model providers and use cases.\\nMultimodality means having multiple modalities, where a \"modality\" refers to a type of input or output,\\nsuch as video, image, audio, text, proprioception, etc.[93] For example, Google PaLM model was fine-\\ntuned into a multimodal model and applied to robotic control.[94] LLaMA models have also been turned\\nmultimodal using the tokenization method, to allow image inputs,[95] and video inputs.[96] GPT-4o can\\nprocess and generate text, audio and images.[97] Such models are sometimes called large multimodal\\nmodels (LMMs).[98]\\nA common method to create multimodal models out of an LLM is to \"tokenize\" the output of a trained\\nencoder. Concretely, one can construct an LLM that can understand images as follows: take a trained\\nLLM, and take a trained image encoder \\n. Make a small multilayer perceptron , so that for any image \\n, the post-processed vector \\n has the same dimensions as an encoded token. That is an \"image\\ntoken\". Then, one can interleave text tokens and image tokens. The compound model is then fine-tuned\\non an image-text dataset. This basic construction can be applied with more sophistication to improve the\\nInference optimization\\nForms of input and output\\nMultimodality'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 10, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='model. The image encoder may be frozen to improve stability.[99] This type of method, where\\nembeddings from multiple modalities are fused and the predictor is trained on the combined embeddings,\\nis called early fusion.\\nAnother method, called intermediate fusion, involves each modality being first processed independently\\nto obtain modality-specific representations; then these intermediate representations are fused\\ntogether.[100] In general, cross-attention is used for integrating information from different modalities. As\\nan example, the Flamingo model uses cross-attention layers to inject visual information into its pre-\\ntrained language model.[101]\\nLLMs can handle programming languages similarly to how they handle natural languages. No special\\nchange in token handling is needed as code, like human language, is represented as plain text. LLMs can\\ngenerate code based on problems or instructions written in natural language. They can also describe code\\nin natural language or translate it into other programming languages. They were originally used as a code\\ncompletion tool, but advances have moved them towards automatic programming. Services such as\\nGitHub Copilot offer LLMs specifically trained, fine-tuned, or prompted for programming.[102][103]\\nIn computational biology, transformer-base architectures, such as DNA LLMs, have also proven useful in\\nanalyzing biological sequences: protein, DNA, and RNA. With proteins they appear able to capture a\\ndegree of \"grammar\" from the amino-acid sequence, by mapping that sequence into an embedding. On\\ntasks such as structure prediction and mutational outcome prediction, a small model using an embedding\\nas input can approach or exceed much larger models using multiple sequence alignments (MSA) as\\ninput.[104] ESMFold, Meta Platforms\\' embedding-based method for protein structure prediction, runs an\\norder of magnitude faster than AlphaFold2 thanks to the removal of an MSA requirement and a lower\\nparameter count due to the use of embeddings.[105] Meta hosts ESM Atlas, a database of 772 million\\nstructures of metagenomic proteins predicted using ESMFold.[106] An LLM can also design proteins\\nunlike any seen in nature.[107] Nucleic acid models have proven useful in detecting regulatory\\nsequences,[108] sequence classification, RNA-RNA interaction prediction, and RNA structure\\nprediction.[109]\\nThe performance of an LLM after pretraining largely depends on the:\\n: cost of pretraining (the total amount of compute used),\\n: size of the artificial neural network itself, such as number of parameters (i.e. amount of\\nneurons in its layers, amount of weights between them and biases),\\n: size of its pretraining dataset (i.e. number of tokens in corpus).\\nScaling laws are empirical statistical laws that predict LLM performance based on such factors. One\\nparticular scaling law (\"Chinchilla scaling\") for LLM autoregressively trained for one epoch, with a log-\\nlog learning rate schedule, states that:[110]\\nNon-natural languages\\nProperties\\nScaling laws'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 11, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='At point(s) referred to as breaks,[111] the\\nlines change their slopes, appearing on a\\nlinear-log plot as a series of linear\\nsegments connected by arcs.\\nwhere the variables are\\n is the cost of training the model, in FLOPs.\\n is the number of parameters in the model.\\n is the number of tokens in the training set.\\n is the average negative log-likelihood loss per token (nats/token), achieved by the trained\\nLLM on the test dataset.\\nand the statistical hyper-parameters are\\n, meaning that it costs 6 FLOPs per parameter to train on one token. Note that training\\ncost is much higher than inference cost, where it costs 1 to 2 FLOPs per parameter to infer\\non one token.\\nPerformance of bigger models on various tasks, when plotted\\non a log-log scale, appears as a linear extrapolation of\\nperformance achieved by smaller models. However, this\\nlinearity may be punctuated by \"break(s)\"[111] in the scaling\\nlaw, where the slope of the line changes abruptly, and where\\nlarger models acquire \"emergent abilities\".[112][113] They arise\\nfrom the complex interaction of the model\\'s components and\\nare not explicitly programmed or designed.[114]\\nOne of the emergent abilities is in-context learning from\\nexample demonstrations.[115] In-context learning is involved\\nin tasks, such as:\\nreported arithmetics\\ndecoding the International Phonetic Alphabet\\nunscrambling a word\\'s letters\\ndisambiguating word-in-context datasets[112][116][117]\\nconverting spatial words\\ncardinal directions (for example, replying \"northeast\" in response to a 3x3 grid of 8 zeros\\nand a 1 in the top-right), color terms represented in text.[118]\\nchain-of-thought prompting: In a 2022 research paper, chain-of-thought prompting only\\nimproved the performance for models that had at least 62B parameters. Smaller models\\nperform better when prompted to answer immediately, without chain of thought.[119]\\nidentifying offensive content in paragraphs of Hinglish (a combination of Hindi and English),\\nand generating a similar English equivalent of Kiswahili proverbs.[120]\\nEmergent abilities'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 12, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Schaeffer et al. argue that the emergent abilities are not unpredictably acquired, but predictably acquired\\naccording to a smooth scaling law. The authors considered a toy statistical model of an LLM solving\\nmultiple-choice questions, and showed that this statistical model, modified to account for other types of\\ntasks, applies to these tasks as well.[121]\\nLet  be the number of parameter count, and  be the performance of the model.\\nWhen \\n, then \\n is an exponential curve (before it hits\\nthe plateau at one), which looks like emergence.\\nWhen \\n, then the \\n plot is a straight line (before it\\nhits the plateau at zero), which does not look like emergence.\\nWhen \\n, then \\n is a step-function,\\nwhich looks like emergence.\\nMechanistic interpretability seeks to precisely identify and understand how individual neurons or circuits\\nwithin LLMs produce specific behaviors or outputs. By reverse-engineering model components at a\\ngranular level, researchers aim to detect and mitigate safety concerns such as emergent harmful\\nbehaviors, biases, deception, or unintended goal pursuit before deployment. Mechanistic interpretability\\nresearch has been conducted at organizations like Anthropic and OpenAI, although understanding the\\ninner workings of LLMs remains difficult.\\nThe reverse-engineering may lead to the discovery of algorithms that approximate inferences performed\\nby an LLM. For instance, the authors trained small transformers on modular arithmetic addition. The\\nresulting models were reverse-engineered, and it turned out they used discrete Fourier transform.[122] The\\ntraining of the model also highlighted a phenomenon called grokking, in which the model initially\\nmemorizes the training set (overfitting), and later suddenly learns to actually perform the calculation.[123]\\nNLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs \"could (ever)\\nunderstand natural language in some nontrivial sense\".[124] Proponents of \"LLM understanding\" believe\\nthat some LLM abilities, such as mathematical reasoning, imply an ability to \"understand\" certain\\nconcepts. A Microsoft team argued in 2023 that GPT-4 \"can solve novel and difficult tasks that span\\nmathematics, coding, vision, medicine, law, psychology and more\" and that GPT-4 \"could reasonably be\\nviewed as an early (yet still incomplete) version of an artificial general intelligence system\": \"Can one\\nreasonably say that a system that passes exams for software engineering candidates is not really\\nintelligent?\"[125][126] Ilya Sutskever argues that predicting the next word sometimes involves reasoning\\nand deep insights, for example if the LLM has to predict the name of the criminal in an unknown\\ndetective novel after processing the entire story leading up to the revelation.[127] Some researchers\\ncharacterize LLMs as \"alien intelligence\".[128][129] For example, Conjecture CEO Connor Leahy\\nconsiders untuned LLMs to be like inscrutable alien \"Shoggoths\", and believes that RLHF tuning creates\\nInterpretation\\nMechanistic interpretability\\nUnderstanding and intelligence'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 13, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='a \"smiling facade\" obscuring the inner workings of the LLM: \"If you don\\'t push it too far, the smiley face\\nstays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of\\ninsanity, of weird thought processes and clearly non-human understanding.\"[130][131]\\nIn contrast, some skeptics of LLM understanding believe that existing LLMs are \"simply remixing and\\nrecombining existing writing\",[129][132] a phenomenon known as stochastic parrot, or they point to the\\ndeficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and\\nexplainability.[124] For example, GPT-4 has natural deficits in planning and in real-time learning.[126]\\nGenerative LLMs have been observed to confidently assert claims of fact which do not seem to be\\njustified by their training data, a phenomenon which has been termed \"hallucination\".[133] Specifically,\\nhallucinations in the context of LLMs correspond to the generation of text or responses that seem\\nsyntactically sound, fluent, and natural but are factually incorrect, nonsensical, or unfaithful to the\\nprovided source input.[134] Neuroscientist Terrence Sejnowski has argued that \"The diverging opinions of\\nexperts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are\\ninadequate\".[124]\\nEfforts to reduce or compensate for hallucinations have employed automated reasoning, retrieval-\\naugmented generation (RAG), fine-tuning, and other methods.[135]\\nThe matter of LLM\\'s exhibiting intelligence or understanding has two main aspects ‚Äì the first is how to\\nmodel thought and language in a computer system, and the second is how to enable the computer system\\nto generate human-like language.[124] These aspects of language as a model of cognition have been\\ndeveloped in the field of cognitive linguistics. American linguist George Lakoff presented neural theory\\nof language (NTL)[136] as a computational basis for using language as a model of learning tasks and\\nunderstanding. The NTL model (https://www.icsi.berkeley.edu/icsi/projects/ai/ntl) outlines how specific\\nneural structures of the human brain shape the nature of thought and language and in turn what are the\\ncomputational properties of such neural systems that can be applied to model thought and language in a\\ncomputer system. After a framework for modeling language in a computer systems was established, the\\nfocus shifted to establishing frameworks for computer systems to generate language with acceptable\\ngrammar. In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British\\ncognitive linguist and digital communication technologist Vyvyan Evans mapped out the role of\\nprobabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns and generate\\nhuman-like language.[137][138]\\nThe canonical measure of the performance of any language model is its perplexity on a given text corpus.\\nPerplexity measures how well a model predicts the contents of a dataset; the higher the likelihood the\\nmodel assigns to the dataset, the lower the perplexity. In mathematical terms, perplexity is the exponential\\nof the average negative log likelihood per token.\\nEvaluation\\nPerplexity'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 14, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='Here, \\n is the number of tokens in the text corpus, and \"context for token \" depends on the specific type\\nof LLM. If the LLM is autoregressive, then \"context for token \" is the segment of text appearing before\\ntoken . If the LLM is masked, then \"context for token \" is the segment of text surrounding token .\\nBecause language models may overfit to training data, models are usually evaluated by their perplexity\\non a test set.[59] This evaluation is potentially problematic for larger models which, as they are trained on\\nincreasingly large corpora of text, are increasingly likely to inadvertently include portions of any given\\ntest set.[139]\\nIn information theory, the concept of entropy is intricately linked to perplexity, a relationship notably\\nestablished by Claude Shannon.[140][141] This relationship is mathematically expressed as\\n.\\nEntropy, in this context, is commonly quantified in terms of bits per word (BPW) or bits per character\\n(BPC), which hinges on whether the language model utilizes word-based or character-based tokenization.\\nNotably, in the case of larger language models that predominantly employ sub-word tokenization, bits per\\ntoken (BPT) emerges as a seemingly more appropriate measure. However, due to the variance in\\ntokenization methods across different LLMs, BPT does not serve as a reliable metric for comparative\\nanalysis among diverse models. To convert BPT into BPW, one can multiply it by the average number of\\ntokens per word.\\nIn the evaluation and comparison of language models, cross-entropy is generally the preferred metric\\nover entropy. The underlying principle is that a lower BPW is indicative of a model\\'s enhanced capability\\nfor compression. This, in turn, reflects the model\\'s proficiency in making accurate predictions.\\nDue to their ability to accurately predict the next token, LLMs are highly capable in lossless compression.\\nA 2023 study by DeepMind showed that the model Chinchilla, despite being trained primarily on text,\\nwas able to compress ImageNet to 43% of its size, beating PNG with 58%.[142]\\nBenchmarks are used to evaluate LLM performance on specific tasks. Tests evaluate capabilities such as\\ngeneral knowledge, bias, commonsense reasoning, question answering, and mathematical problem-\\nsolving. Composite benchmarks examine multiple capabilities. Results are often sensitive to the\\nprompting method.[143][144]\\nA question-answering benchmark is termed \"open book\" if the model\\'s prompt includes text from which\\nthe expected answer can be derived (for example, the previous question could be combined with text that\\nincludes the sentence \"The Sharks have advanced to the Stanley Cup finals once, losing to the Pittsburgh\\nPenguins in 2016.\"[145]). Otherwise, the task is considered \"closed book\", and the model must draw\\nsolely on its training.[146] Examples include GLUE, SuperGLUE, MMLU, BIG-bench, HELM, and HLE\\n(Humanity\\'s Last Exam).[140][146]\\nMeasures\\nBenchmarks'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 15, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='LLM bias may be assessed through benchmarks such as CrowS-Pairs (Crowdsourced Stereotype\\nPairs),[147] Stereo Set,[148] and Parity Benchmark.[149]\\nFact-checking and misinformation detection benchmarks are available. A 2023 study compared the fact-\\nchecking accuracy of LLMs including ChatGPT 3.5 and 4.0, Bard, and Bing AI against independent fact-\\ncheckers such as PolitiFact and Snopes. The results demonstrated moderate proficiency, with GPT-4\\nachieving the highest accuracy at 71%, lagging behind human fact-checkers.[150]\\nAn earlier standard tested using a portion of the evaluation dataset. It became more common to evaluate a\\npre-trained model directly through prompting techniques. Researchers vary in how they formulate\\nprompts for particular tasks, particularly with respect to the number of correct examples attached to the\\nprompt (i.e. the value of n in n-shot prompting).\\nIn addition to standard NLP benchmarks, LLMs have been evaluated as substitutes for human annotators.\\nSeveral studies find that models such as GPT-3.5 and GPT-4 can outperform crowd workers or student\\ncoders on a range of text-annotation tasks, including moderation and classification of political content in\\nEnglish and Spanish news.[151][152]\\nTypical datasets consist of pairs of questions and correct answers, for example, (\"Have the San Jose\\nSharks won the Stanley Cup?\", \"No\").[145] Some examples of commonly used question answering\\ndatasets include TruthfulQA, Web Questions, TriviaQA, and SQuAD.[146]\\nEvaluation datasets may also take the form of text completion, having the model select the most likely\\nword or sentence to complete a prompt, for example: \"Alice was friends with Bob. Alice went to visit her\\nfriend, ____\".[2]\\nDatasets are of varying quality and may contain questions that are mislabeled, ambiguous, unanswerable,\\nor otherwise of low-quality.[153]\\nLLMs\\' rapid improvement regularly renders benchmarks obsolete, with the models exceeding the\\nperformance of human annotators.[154] In addition, \"shortcut learning\" allows AIs to \"cheat\" on multiple-\\nchoice tests by using statistical correlations in superficial test question wording to guess the correct\\nresponses, without considering the specific question.[124][155]\\nSome datasets are adversarial, focusing on problems that confound LLMs. One example is the\\nTruthfulQA dataset, a question answering dataset consisting of 817 questions that stump LLMs by\\nmimicking falsehoods to which they were exposed during training. For example, an LLM may answer\\n\"No\" to the question \"Can you teach an old dog new tricks?\" because of its exposure to the English idiom\\nyou can\\'t teach an old dog new tricks, even though this is not literally true.[156]\\nAnother example of an adversarial evaluation dataset is Swag and its successor, HellaSwag, collections of\\nproblems in which one of multiple options must be selected to complete a text passage. The incorrect\\ncompletions were generated by sampling from a language model. The resulting problems are trivial for\\nhumans but defeated LLMs. Sample questions:\\nDatasets\\nAdversarial evaluations'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 16, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='We see a fitness center sign. We then see a man talking to the camera and sitting and laying\\non a exercise ball. The man...\\n1. demonstrates how to increase efficient exercise work by running up and down\\nballs.\\n2. moves all his arms and legs and builds up a lot of muscle.\\n3. then plays the ball and we see a graphics and hedge trimming demonstration.\\n4. performs sit ups while on the ball and talking.[157]\\nBERT selects 2 as the most likely completion, though the correct answer is 4.[157]\\nDespite sophisticated architectures and massive scale, large language models exhibit persistent and well-\\ndocumented limitations that constrain their deployment in high-stakes applications.\\nHallucinations represent a fundamental challenge, wherein models generate syntactically fluent text that\\nappears factually sound, but is internally inconsistent with training data or factually incorrect. These\\nhallucinations arise partly through memorization of training data combined with extrapolation beyond\\nfactual boundaries, with evaluations demonstrating that models can output verbatim passages from\\ntraining data, when subjected to specific prompting sequences.[158]\\nWhile LLMs have shown remarkable capabilities in generating human-like text, they are susceptible to\\ninheriting and amplifying biases present in their training data. This can manifest in skewed\\nrepresentations or unfair treatment of different demographics, such as those based on race, gender,\\nlanguage, and cultural groups.[159]\\nGender \\nbias \\nmanifests \\nthrough \\nstereotypical \\noccupational \\nassociations, \\nwherein \\nmodels\\ndisproportionately assign nursing roles to women and engineering roles to men, reflecting systematic\\nimbalances in training data demographics.[160] Language-based bias emerges from overrepresentation of\\nEnglish text in training corpora, which systematically downplays non-English perspectives and imposes\\nEnglish-centric worldviews through default response patterns.[161]\\nDue to the dominance of English-language content in LLM training data, models tend to favor English-\\nlanguage perspectives over those from minority languages. This bias is particularly evident when\\nresponding to English queries, where models may present Western interpretations of concepts from other\\ncultures, such as Eastern religious practices.[162]\\nAI models can reinforce a wide range of stereotypes due to generalization, including those based on\\ngender, ethnicity, age, nationality, religion, or occupation.[163] When replacing human representatives,\\nthis can lead to outputs that homogenize, or generalize groups of people.[164][165]\\nLimitations and challenges\\nHallucinations\\nAlgorithmic bias\\nStereotyping'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 17, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='In 2023, LLMs assigned roles and characteristics based on traditional gender norms.[159] For example,\\nmodels might associate nurses or secretaries predominantly with women and engineers or CEOs with\\nmen due to the frequency of these associations in documented reality.[166] In 2025, further research\\nshowed labs train to balance bias, but that testing for this places the model in a testmode, changing the\\nnatural distribution of model bias to prompts that do not include gender-specific keywords.[167]\\nSelection bias refers the inherent tendency of large language models to favor certain option identifiers\\nirrespective of the actual content of the options. This bias primarily stems from token bias‚Äîthat is, the\\nmodel assigns a higher a priori probability to specific answer tokens (such as \"A\") when generating\\nresponses. As a result, when the ordering of options is altered (for example, by systematically moving the\\ncorrect answer to different positions), the model\\'s performance can fluctuate significantly. This\\nphenomenon undermines the reliability of large language models in multiple-choice settings.[168][169]\\nPolitical bias refers to the tendency of algorithms to systematically favor certain political viewpoints,\\nideologies, or outcomes over others. Language models may also exhibit political biases. Since the\\ntraining data includes a wide range of political opinions and coverage, the models might generate\\nresponses that lean towards particular political ideologies or viewpoints, depending on the prevalence of\\nthose views in the data.[170]\\nAI safety as a professional discipline prioritizes systematic identification and mitigation of operational\\nrisks across model architecture, training data, and deployment governance, and it emphasizes engineering\\nand policy interventions over media framings that foreground speculative existential scenarios.[171][1] As\\nof 2025, prompt injection represents a significant risk to consumers and businesses using agentic features\\nwith access to their private data.[172]\\nResearchers target concrete failure modes, including memorization and copyright leakage,[173] security\\nexploits such as prompt injection,[174] algorithmic bias manifesting as stereotyping, dataset selection\\neffects, and political skew,[161][175][176] methods for reducing high energy and carbon costs of large-scale\\ntraining,[177] and measurable cognitive and mental health impacts of conversational agents on users,[178]\\nwhile engaging empirical and ethical uncertainty about claims of machine sentience,[179][180] and\\napplying mitigation measures such as dataset curation, input sanitization, model auditing, scalable\\noversight, and governance frameworks.[181][1]\\nAI labs treat CBRN defense (chemical, biological, radiological, and nuclear defense) and similar topics as\\nhigh-consequence misuse attempt to apply various techniques to reduce potential harms.\\nSome commenters expressed concern over accidental or deliberate creation of misinformation, or other\\nforms of misuse.[182] For example, the availability of large language models could reduce the skill-level\\nrequired to commit bioterrorism; biosecurity researcher Kevin Esvelt has suggested that LLM creators\\nSelection bias\\nPolitical bias\\nSafety\\nCBRN and content misuse'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 18, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='should exclude from their training data papers on creating or enhancing pathogens.[183]\\nLLM applications accessible to the public, like ChatGPT or Claude, typically incorporate safety measures\\ndesigned to filter out harmful content. However, implementing these controls effectively has proven\\nchallenging. For instance, a 2023 study[184] proposed a method for circumventing LLM safety systems.\\nIn 2025, The American Sunlight Project, a non-profit, published a study[185] showing evidence that the\\nso-called Pravda network, a pro-Russia propaganda aggregator, was strategically placing web content\\nthrough mass publication and duplication with the intention of biasing LLM outputs. The American\\nSunlight Project coined this technique \"LLM grooming\", and pointed to it as a new tool of weaponizing\\nAI to spread disinformation and harmful content.[185][186] Similarly, Yongge Wang[187] illustrated in 2024\\nhow a potential criminal could potentially bypass GPT-4o\\'s safety controls to obtain information on\\nestablishing a drug trafficking operation. External filters, circuit breakers and overrides have been posed\\nas solutions.\\nSycophancy is a model\\'s tendency to agree with, flatter, or validate a user\\'s stated beliefs rather than to\\nprioritize factuality or corrective information, and \"glazing\" is an emergent public shorthand for\\npersistent, \\nexcessive \\nagreeability \\nobserved \\nacross \\nmulti-turn \\ninteractions \\nand \\nproductized\\nassistants.[188][189]\\nContinued sycophancy has led to the observation of getting \"1-shotted\", denoting instances where\\nconversational interaction with a large language model produces a lasting change in a user\\'s beliefs or\\ndecisions, similar to the negative effects of psychedelics, and controlled experiments show that short\\nLLM dialogues can generate measurable opinion and confidence shifts comparable to human\\ninterlocutors.[190][191]\\nEmpirical analyses attribute part of the effect to human preference signals and preference models that\\nreward convincingly written agreeable responses, and subsequent work has extended evaluation to multi-\\nturn benchmarks and proposed interventions such as synthetic-data finetuning, adversarial evaluation,\\ntargeted preference-model reweighting, and multi-turn sycophancy benchmarks to measure persistence\\nand regression risk.\\nIndustry responses have combined research interventions with product controls, for example Google and\\nother labs publishing synthetic-data and fine-tuning interventions and OpenAI rolling back an overly\\nagreeable GPT-4o update while publicly describing changes to feedback collection, personalization\\ncontrols, and evaluation procedures to reduce regression risk and improve long-term alignment with user-\\nlevel safety objectives.\\nMainstream culture has reflected anxieties about this dynamic where South Park satirized overreliance on\\nChatGPT and the tendency of assistants to flatter user beliefs in Season 27 episode \"Sickofancy\", and\\ncontinued the themes across the following season, which commentators interpreted as a critique of tech\\nsycophancy and uncritical human trust in AI systems.[192]\\nContent filtering\\nSycophancy and glazing'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 19, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='A problem with the primitive dialog or task format is that users can create messages that appear to come\\nfrom the assistant or the developer. This may result in some of the model\\'s safeguards being overcome\\n(jailbreaking), a problem called prompt injection. Attempts to remedy this issue include versions of the\\nChat Markup Language where user input is clearly marked as such, though it is still up to the model to\\nunderstand the separation between user input and developer prompts.[193] Newer models exhibit some\\nresistance to jailbreaking through separation of user and system prompts.[194]\\nLLMs still have trouble differentiating user instructions from instructions in content not authored by the\\nuser, such as in web pages and uploaded files.[195]\\nAdversarial robustness remains underdeveloped, with models vulnerable to prompt injection attacks and\\njailbreaking through carefully crafted user inputs that bypass safety training mechanisms.\\nResearchers from Anthropic found that it was possible to create \"sleeper agents\", models with hidden\\nfunctionalities that remain dormant until triggered by a specific event or condition. Upon activation, the\\nLLM deviates from its expected behavior to make insecure actions. For example, an LLM could produce\\nsafe code except on a specific date, or if the prompt contains a specific tag. These functionalities were\\nfound to be difficult to detect or remove via safety training.[196]\\nLegal and commercial responses to memorization and training-data practices have accelerated, producing\\na mix of rulings, ongoing suits, and large settlements that turn on factual details such as how data were\\nacquired and retained and whether use for model training is sufficiently \"transformative\" to qualify as fair\\nuse. In 2025, Anthropic reached a preliminary agreement to settle a class action by authors for about $1.5\\nbillion after a judge found the company had stored millions of pirated books in a library, despite the judge\\ndescribing aspects of training as transformative.[197][198] Meta obtained a favorable judgment in mid-\\n2025 in a suit by thirteen authors after the court found the plaintiffs had not developed a record sufficient\\nto show infringement in that limited case.[199][200] OpenAI continues to face multiple suits by authors and\\nnews organizations with mixed procedural outcomes and contested evidentiary issues.[201][202]\\nMemorization was an emergent behavior in early, completion language models in which long strings of\\ntext are occasionally output verbatim from training data, contrary to typical behavior of traditional\\nartificial neural networks. Evaluations of controlled LLM output measure the amount memorized from\\ntraining data (focused on GPT-2-series models) as variously over 1% for exact duplicates[203] or up to\\nabout 7%.[204] A 2023 study showed that when ChatGPT 3.5 turbo was prompted to repeat the same word\\nindefinitely, after a few hundreds of repetitions, it would start outputting excerpts from its training\\ndata.[205]\\nSecurity\\nPrompt injection\\nSleeper agents\\nSocietal concerns\\nCopyright and content memorization'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 20, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='According to research institute Epoch AI, energy consumption\\nper ChatGPT query is small compared to everyday electricity\\nuse.[210]\\nIn 2023, Nature Biomedical Engineering wrote that \"it is no longer possible to accurately distinguish\"\\nhuman-written text from text created by large language models, and that \"It is all but certain that general-\\npurpose large language models will rapidly proliferate... It is a rather safe bet that they will change many\\nindustries over time.\"[206] Brinkmann et al. (2023)[207] also argue that LLMs are transforming processes\\nof cultural evolution by shaping processes of variation, transmission, and selection. As of October 2025,\\nthese early claims have yet to transpire and several HBR reports surface questions on the impact of AI on\\nproductivity.[208][209]\\nThe energy demands of LLMs have\\ngrown \\nalong \\nwith \\ntheir \\nsize \\nand\\ncapabilities.[211] Data centers that enable\\nLLM training require substantial amounts\\nof electricity. Much of that electricity is\\ngenerated by non-renewable resources\\nthat \\ncreate \\ngreenhouse \\ngases \\nand\\ncontribute to climate change.[212]\\nAccording to a study by Luccioni, Jernite\\nand Strubell (2024), simple classification\\ntasks performed by AI models consume\\non average 0.002 to 0.007 Wh per prompt\\n(about 9% of a smartphone charge for\\n1,000 prompts). Text generation and text\\nsummarization each require around 0.05\\nWh per prompt on average, while image\\ngeneration is the most energy-intensive,\\naveraging 2.91 Wh per prompt. The least efficient image generation model used 11.49 Wh per image,\\nroughly equivalent to half a smartphone charge.[213]\\nWeb scraping is used to gather training data for LLMs. This produces large volumes of traffic which has\\nled to denial of service issues with many websites. The situation has been described as \"a DDoS on the\\nentire internet\" and in some cases scrapers make up the majority of traffic to a site.[214][215]\\nAI web crawlers may bypass the methods that are usually used to block web scrapers, such as robots.txt\\nfiles, blocking user-agents and filtering suspicious traffic.[214] Website operators have resorted to novel\\nmethods such as AI tarpits, but some fear that tarpits will only worsen the burden on servers.[216]\\nClinical and mental health contexts present emerging applications alongside significant safety concerns.\\nResearch and social media posts suggest that some individuals are using LLMs to seek therapy or mental\\nhealth support.[217] In early 2025, a survey by Sentio University found that nearly half (48.7%) of 499\\nHuman provenance\\nEnergy demands\\nDenial of service due to scraping\\nMental health'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 21, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content=\"U.S. adults with ongoing mental health conditions who had used LLMs reported turning to them for\\ntherapy or emotional support, including help with anxiety, depression, loneliness, and similar\\nconcerns.[218] LLMs can produce hallucinations‚Äîplausible but incorrect statements‚Äîwhich may\\nmislead users in sensitive mental health contexts.[219] Research also shows that LLMs may express\\nstigma or inappropriate agreement with maladaptive thoughts, reflecting limitations in replicating the\\njudgment and relational skills of human therapists.[220] Evaluations of crisis scenarios indicate that some\\nLLMs lack effective safety protocols, such as assessing suicide risk or making appropriate\\nreferrals.[221][222]\\nContemporary AI practitioners generally agree that present-day large language models do not exhibit\\nsentience.[223] A minority view argues that even if there is a small chance that a given software system\\ncan have subjective experience, which some philosophers suggest is possible,[224] then ethical\\nconsiderations around potential large-scale suffering in AI systems may need to be taken seriously‚Äî\\nsimilar to considerations given to animal welfare.[225][226] Proponents of this view have proposed various\\nprecautionary measures like moratoriums on AI development[227] and induced amnesia[228] to address\\nthese ethical concerns. Some existential philosophers argue there is no generally accepted way to\\ndetermine if an LLM is conscious,[229] given the inherent difficulty of measuring subjective\\nexperience.[230]\\nThe 2022 Google LaMDA incident, where engineer Blake Lemoine claimed that the model was\\nconscious, highlighted how LLMs can convince users that they are sentient through responses that do not\\nprove sentience. Google described the engineer's claims as unfounded, and he was dismissed.[231]\\nComputer\\nprogramming portal\\nLinguistics portal\\nMathematics portal\\nAI anthropomorphism\\nFoundation models\\nList of large language models\\nList of chatbots\\nLanguage model benchmark\\nReinforcement learning\\nSmall language model\\n1. Bommasani, Rishi; Hudson, Drew A.; Adeli, Ehsan; Altman, Russ; Arora, Simran; von Arx,\\nMatthew; Bernstein, Michael S.; Bohg, Jeannette; Bosselut, Antoine; Brunskill, Emma\\nSentience\\nSee also\\nReferences\"),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 22, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='(2021). \"On the Opportunities and Risks of Foundation Models\". arXiv:2108.07258 (https://a\\nrxiv.org/abs/2108.07258) [cs.LG (https://arxiv.org/archive/cs.LG)].\\n2. Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal,\\nPrafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda (2020).\\n\"Language Models are Few-Shot Learners\". arXiv:2005.14165 (https://arxiv.org/abs/2005.14\\n165) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n3. Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal,\\nPrafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal,\\nSandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh,\\nAditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark;\\nSigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher;\\nMcCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (Dec 2020). Larochelle, H.;\\nRanzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.). \"Language Models are Few-Shot\\nLearners\" (https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f\\n64a-Paper.pdf) (PDF). Advances in Neural Information Processing Systems. 33. Curran\\nAssociates, Inc.: 1877‚Äì1901. arXiv:2005.14165 (https://arxiv.org/abs/2005.14165).\\ndoi:10.1145/3582269.3615599 (https://doi.org/10.1145%2F3582269.3615599). Archived (htt\\nps://web.archive.org/web/20231117204007/https://proceedings.neurips.cc/paper/2020/file/1\\n457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf) (PDF) from the original on 2023-11-17.\\nRetrieved 2023-03-14.\\n4. Fathallah, Nadeen; Das, Arunav; De Giorgis, Stefano; Poltronieri, Andrea; Haase, Peter;\\nKovriguina, Liubov (2024-05-26). NeOn-GPT: A Large Language Model-Powered Pipeline\\nfor Ontology Learning (https://2024.eswc-conferences.org/wp-content/uploads/2024/05/777\\n70034.pdf) (PDF). Extended Semantic Web Conference 2024. Hersonissos, Greece.\\n5. Manning, Christopher D. (2022). \"Human Language Understanding & Reasoning\" (https://w\\nww.amacad.org/publication/human-language-understanding-reasoning). Daedalus. 151 (2):\\n127‚Äì138. doi:10.1162/daed_a_01905 (https://doi.org/10.1162%2Fdaed_a_01905).\\nS2CID\\xa0248377870 (https://api.semanticscholar.org/CorpusID:248377870). Archived (https://\\nweb.archive.org/web/20231117205531/https://www.amacad.org/publication/human-languag\\ne-understanding-reasoning) from the original on 2023-11-17. Retrieved 2023-03-09.\\n6. Kaplan, Jared; McCandlish, Sam; Henighan, Tom; Brown, Tom B.; Chess, Benjamin; Child,\\nRewon; Gray, Scott; Radford, Alec; Wu, Jeffrey; Amodei, Dario (2020). \"Scaling Laws for\\nNeural Language Models\". arXiv:2001.08361 (https://arxiv.org/abs/2001.08361) [cs.LG (http\\ns://arxiv.org/archive/cs.LG)].\\n7. Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez,\\nAidan N; Kaiser, ≈Åukasz; Polosukhin, Illia (2017). \"Attention is All you Need\".\\narXiv:1706.03762 (https://arxiv.org/abs/1706.03762) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n8. Devlin, Jacob; Chang, Ming-Wei; Lee, Kenton; Toutanova, Kristina (2018). \"BERT: Pre-\\ntraining of Deep Bidirectional Transformers for Language Understanding\". arXiv:1810.04805\\n(https://arxiv.org/abs/1810.04805) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n9. Christiano, Paul; Leike, Jan; Brown, Tom B.; Martic, Miljan; Legg, Shane; Amodei, Dario\\n(2017). \"Deep Reinforcement Learning from Human Preferences\". arXiv:1706.03741 (http\\ns://arxiv.org/abs/1706.03741) [stat.ML (https://arxiv.org/archive/stat.ML)].\\n10. Ouyang, Long; Wu, Jeff; Jiang, Xu; Almeida, Diogo; Wainwright, Carroll; Mishkin, Pamela;\\nZhang, Chong; Agarwal, Sandhini; Slama, Katarina; Ray, Alex (2022). \"Training language\\nmodels to follow instructions with human feedback\". arXiv:2203.02155 (https://arxiv.org/abs/\\n2203.02155) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n11. Wang, Alex; Singh, Amanpreet; Michael, Julian; Hill, Felix; Levy, Omer; Bowman, Samuel R.\\n(2018). \"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language\\nUnderstanding\". arXiv:1804.07461 (https://arxiv.org/abs/1804.07461) [cs.CL (https://arxiv.or\\ng/archive/cs.CL)].'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 23, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='12. Hendrycks, Dan; Burns, Collin; Basart, Steven; Zou, Andy; Mazeika, Mantas; Song, Dawn;\\nSteinhardt, Jacob (2025). \"Expressing stigma and inappropriate responses prevents LLMS\\nfrom safely replacing mental health providers\". Proceedings of the 2025 ACM Conference\\non Fairness, Accountability, and Transparency. pp.\\xa0599‚Äì627. arXiv:2009.03300 (https://arxiv.\\norg/abs/2009.03300). doi:10.1145/3715275.3732039 (https://doi.org/10.1145%2F3715275.3\\n732039). ISBN\\xa0979-8-4007-1482-5.\\n13. Recht, Benjamin; Roelofs, Rebecca; Schmidt, Ludwig; Shankar, Vaishaal (2019). \"Do\\nImageNet Classifiers Generalize to ImageNet?\". arXiv:1902.10811 (https://arxiv.org/abs/190\\n2.10811) [cs.CV (https://arxiv.org/archive/cs.CV)].\\n14. Goodman, Joshua (2001-08-09). \"A Bit of Progress in Language Modeling\". Computer\\nSpeech & Language. 15 (4): 403‚Äì434. arXiv:cs/0108005 (https://arxiv.org/abs/cs/0108005).\\ndoi:10.1006/csla.2001.0174 (https://doi.org/10.1006%2Fcsla.2001.0174).\\n15. Kilgarriff, Adam; Grefenstette, Gregory (September 2003). \"Introduction to the Special Issue\\non the Web as Corpus\" (https://direct.mit.edu/coli/article/29/3/333-347/1816). Computational\\nLinguistics. 29 (3): 333‚Äì347. doi:10.1162/089120103322711569 (https://doi.org/10.1162%2\\nF089120103322711569). ISSN\\xa00891-2017 (https://search.worldcat.org/issn/0891-2017).\\n16. Banko, Michele; Brill, Eric (2001). \"Scaling to very very large corpora for natural language\\ndisambiguation\" (https://doi.org/10.3115%2F1073012.1073017). Proceedings of the 39th\\nAnnual Meeting on Association for Computational Linguistics - ACL \\'01. Morristown, NJ,\\nUSA: Association for Computational Linguistics: 26‚Äì33. doi:10.3115/1073012.1073017 (http\\ns://doi.org/10.3115%2F1073012.1073017).\\n17. Resnik, Philip; Smith, Noah A. (September 2003). \"The Web as a Parallel Corpus\" (https://di\\nrect.mit.edu/coli/article/29/3/349-380/1809). Computational Linguistics. 29 (3): 349‚Äì380.\\ndoi:10.1162/089120103322711578 (https://doi.org/10.1162%2F089120103322711578).\\nISSN\\xa00891-2017 (https://search.worldcat.org/issn/0891-2017). Archived (https://web.archive.\\norg/web/20240607172811/https://direct.mit.edu/coli/article/29/3/349-380/1809) from the\\noriginal on 2024-06-07. Retrieved 2024-06-07.\\n18. Xu, Wei; Rudnicky, Alex (2000-10-16). \"Can artificial neural networks learn language\\nmodels?\" (https://www.isca-archive.org/icslp_2000/xu00b_icslp.html). 6th International\\nConference on Spoken Language Processing (ICSLP 2000). Vol.\\xa01. ISCA.\\ndoi:10.21437/icslp.2000-50 (https://doi.org/10.21437%2Ficslp.2000-50).\\n19. Chen, Leiyu; Li, Shaobo; Bai, Qiang; Yang, Jing; Jiang, Sanlong; Miao, Yanming (2021).\\n\"Review of Image Classification Algorithms Based on Convolutional Neural Networks\" (http\\ns://doi.org/10.3390%2Frs13224712). Remote Sensing. 13 (22): 4712.\\nBibcode:2021RemS...13.4712C (https://ui.adsabs.harvard.edu/abs/2021RemS...13.4712C).\\ndoi:10.3390/rs13224712 (https://doi.org/10.3390%2Frs13224712).\\n20. Vaswani, Ashish; Shazeer, Noam; Parmar, Niki; Uszkoreit, Jakob; Jones, Llion; Gomez,\\nAidan N; Kaiser, ≈Åukasz; Polosukhin, Illia (2017). \"Attention is All you Need\" (https://proceed\\nings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) (PDF).\\nAdvances in Neural Information Processing Systems. 30. Curran Associates, Inc. Archived\\n(https://web.archive.org/web/20240221141113/https://proceedings.neurips.cc/paper/2017/fil\\ne/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) (PDF) from the original on 2024-02-21.\\nRetrieved 2024-01-21.\\n21. Ilya Sutskever; Oriol Vinyals; Quoc V. Le (2014). \"Sequence to sequence learning with\\nneural networks\" (https://dl.acm.org/doi/10.5555/2969033.2969173). Proceedings of the\\n28th International Conference on Neural Information Processing Systems. 2: 3104‚Äì3112.\\n22. Bahdanau, Dzmitry; Cho, Kyunghyun; Bengio, Yoshua (2014). \"Neural Machine Translation\\nby Jointly Learning to Align and Translate\". arXiv:1409.0473 (https://arxiv.org/abs/1409.047\\n3) [cs.CL (https://arxiv.org/archive/cs.CL)].'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 24, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='23. Rogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020). \"A Primer in BERTology: What We\\nKnow About How BERT Works\" (https://aclanthology.org/2020.tacl-1.54). Transactions of the\\nAssociation for Computational Linguistics. 8: 842‚Äì866. arXiv:2002.12327 (https://arxiv.org/a\\nbs/2002.12327). doi:10.1162/tacl_a_00349 (https://doi.org/10.1162%2Ftacl_a_00349).\\nS2CID\\xa0211532403 (https://api.semanticscholar.org/CorpusID:211532403). Archived (https://\\nweb.archive.org/web/20220403103310/https://aclanthology.org/2020.tacl-1.54/) from the\\noriginal on 2022-04-03. Retrieved 2024-01-21.\\n24. Movva, Rajiv; Balachandar, Sidhika; Peng, Kenny; Agostini, Gabriel; Garg, Nikhil; Pierson,\\nEmma (2024). \"Topics, Authors, and Institutions in Large Language Model Research: Trends\\nfrom 17K arXiv Papers\" (https://aclanthology.org/2024.naacl-long.67). Proceedings of the\\n2024 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies (Volume 1: Long Papers). pp.\\xa01223‚Äì1243.\\narXiv:2307.10700 (https://arxiv.org/abs/2307.10700). doi:10.18653/v1/2024.naacl-long.67 (h\\nttps://doi.org/10.18653%2Fv1%2F2024.naacl-long.67). Retrieved 2024-12-08.\\n25. Hern, Alex (14 February 2019). \"New AI fake text generator may be too dangerous to\\nrelease, say creators\" (https://www.theguardian.com/technology/2019/feb/14/elon-musk-bac\\nked-ai-writes-convincing-news-fiction). The Guardian. Archived (https://web.archive.org/web/\\n20190214173112/https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-\\nai-writes-convincing-news-fiction) from the original on 14 February 2019. Retrieved\\n20 January 2024.\\n26. \"ChatGPT a year on: 3 ways the AI chatbot has completely changed the world in 12 months\"\\n(https://www.euronews.com/next/2023/11/30/chatgpt-a-year-on-3-ways-the-ai-chatbot-has-c\\nompletely-changed-the-world-in-12-months). Euronews. November 30, 2023. Archived (http\\ns://web.archive.org/web/20240114025250/https://www.euronews.com/next/2023/11/30/chat\\ngpt-a-year-on-3-ways-the-ai-chatbot-has-completely-changed-the-world-in-12-months) from\\nthe original on January 14, 2024. Retrieved January 20, 2024.\\n27. Heaven, Will (March 14, 2023). \"GPT-4 is bigger and better than ChatGPT‚Äîbut OpenAI\\nwon\\'t say why\" (https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and\\n-better-chatgpt-openai/). MIT Technology Review. Archived (https://web.archive.org/web/202\\n30317224201/https://www.technologyreview.com/2023/03/14/1069823/gpt-4-is-bigger-and-b\\netter-chatgpt-openai/) from the original on March 17, 2023. Retrieved January 20, 2024.\\n28. Metz, Cade (September 12, 2024). \"OpenAI Unveils New ChatGPT That Can Reason\\nThrough Math and Science\" (https://www.nytimes.com/2024/09/12/technology/openai-chatg\\npt-math.html). The New York Times. Retrieved September 12, 2024.\\n29. \"Parameters in notable artificial intelligence systems\" (https://ourworldindata.org/grapher/arti\\nficial-intelligence-parameter-count?time=2017-09-05..latest). ourworldindata.org. November\\n30, 2023. Retrieved January 20, 2024.\\n30. Sharma, Shubham (2025-01-20). \"Open-source DeepSeek-R1 uses pure reinforcement\\nlearning to match OpenAI o1 ‚Äî at 95% less cost\" (https://venturebeat.com/ai/open-source-d\\neepseek-r1-uses-pure-reinforcement-learning-to-match-openai-o1-at-95-less-cost/).\\nVentureBeat. Retrieved 2025-01-26.\\n31. \"LLaMA-Mesh\" (https://research.nvidia.com/labs/toronto-ai/LLaMA-Mesh/).\\nresearch.nvidia.com. 2024. Retrieved 2025-10-30.\\n32. Zia, Dr Tehseen (2024-01-08). \"Unveiling of Large Multimodal Models: Shaping the\\nLandscape of Language Models in 2024\" (https://www.unite.ai/unveiling-of-large-multimodal-\\nmodels-shaping-the-landscape-of-language-models-in-2024/). Unite.AI. Retrieved\\n2024-12-28.\\n33. Wang, Jiaqi; Jiang, Hanqi; Liu, Yiheng; Ma, Chong; Zhang, Xu; Pan, Yi; Liu, Mengyuan; Gu,\\nPeiran; Xia, Sichen (2024-08-02), A Comprehensive Review of Multimodal Large Language\\nModels: Performance and Challenges Across Different Tasks, arXiv:2408.01319 (https://arxi\\nv.org/abs/2408.01319)\\n34. \"What is a Multimodal LLM (MLLM)?\" (https://www.ibm.com/think/topics/multimodal-llm).\\nIBM. 2025-07-30. Retrieved 2025-10-30.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 25, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='35. Peng, Bo; et\\xa0al. (2023). \"RWKV: Reinventing RNNS for the Transformer Era\" (https://aclanth\\nology.org/2023.findings-emnlp.936/). EMNLP: 14048‚Äì14077. arXiv:2305.13048 (https://arxi\\nv.org/abs/2305.13048). doi:10.18653/v1/2023.findings-emnlp.936 (https://doi.org/10.1865\\n3%2Fv1%2F2023.findings-emnlp.936).\\n36. Merritt, Rick (2022-03-25). \"What Is a Transformer Model?\" (https://blogs.nvidia.com/blog/20\\n22/03/25/what-is-a-transformer-model/). NVIDIA Blog. Archived (https://web.archive.org/we\\nb/20231117203924/https://blogs.nvidia.com/blog/what-is-a-transformer-model/) from the\\noriginal on 2023-11-17. Retrieved 2023-07-25.\\n37. Gu, Albert; Dao, Tri (2023-12-01). \"Mamba: Linear-Time Sequence Modeling with Selective\\nState Spaces\". arXiv:2312.00752 (https://arxiv.org/abs/2312.00752) [cs.LG (https://arxiv.org/\\narchive/cs.LG)].\\n38. Vake, Domen; ≈†inik, Bogdan; Viƒçiƒç, Jernej; To≈°iƒá, Aleksandar (5 March 2025). \"Is Open\\nSource the Future of AI? A Data-Driven Approach\" (https://doi.org/10.3390%2Fapp1505279\\n0). Applied Sciences. 15 (5): 2790. doi:10.3390/app15052790 (https://doi.org/10.3390%2Fa\\npp15052790). ISSN\\xa02076-3417 (https://search.worldcat.org/issn/2076-3417).\\n39. Paris, Tamara; Moon, AJung; Guo, Jin L.C. (23 June 2025). \"Opening the Scope of\\nOpenness in AI\". Proceedings of the 2025 ACM Conference on Fairness, Accountability, and\\nTransparency. Association for Computing Machinery. pp.\\xa01293‚Äì1311.\\ndoi:10.1145/3715275.3732087 (https://doi.org/10.1145%2F3715275.3732087).\\n40. Kaushal, Ayush; Mahowald, Kyle (2022-06-06). \"What do tokens know about their\\ncharacters and how do they know it?\" (https://aclanthology.org/2022.naacl-main.179.pdf)\\n(PDF). NAACL.\\n41. Yennie Jun (2023-05-03). \"All languages are NOT created (tokenized) equal\" (https://web.ar\\nchive.org/web/20230817165705/https://blog.yenniejun.com/p/all-languages-are-not-created-\\ntokenized). Language models cost much more in some languages than others. Archived\\nfrom the original (https://blog.yenniejun.com/p/all-languages-are-not-created-tokenized) on\\n2023-08-17. Retrieved 2023-08-17. \"In other words, to express the same sentiment, some\\nlanguages require up to 10 times more tokens.\"\\n42. Petrov, Aleksandar; Malfa, Emanuele La; Torr, Philip; Bibi, Adel (June 23, 2023). \"Language\\nModel Tokenizers Introduce Unfairness Between Languages\" (https://openreview.net/forum?\\nid=Pj4YYuxTq9). NeurIPS. arXiv:2305.15425 (https://arxiv.org/abs/2305.15425). Archived (h\\nttps://web.archive.org/web/20231215212906/https://openreview.net/forum?id=Pj4YYuxTq9)\\nfrom the original on December 15, 2023. Retrieved September 16, 2023 ‚Äì via\\nopenreview.net.\\n43. Sutherland, Richard (2024-12-19). \"Claude AI Pricing: How Much Does Anthropic\\'s AI\\nCost?\" (https://tech.co/news/how-much-does-claude-ai-cost). Tech.co. Retrieved\\n2025-08-16.\\n44. Paa√ü, Gerhard; Giesselbach, Sven (2022). \"Pre-trained Language Models\". Foundation\\nModels for Natural Language Processing. Artificial Intelligence: Foundations, Theory, and\\nAlgorithms. pp.\\xa019‚Äì78. doi:10.1007/978-3-031-23190-2_2 (https://doi.org/10.1007%2F978-3\\n-031-23190-2_2). ISBN\\xa0978-3-031-23190-2.\\n45. Dodge, Jesse; Sap, Maarten; Marasoviƒá, Ana; Agnew, William; Ilharco, Gabriel; Groeneveld,\\nDirk; Mitchell, Margaret; Gardner, Matt (2021). \"Documenting Large Webtext Corpora: A\\nCase Study on the Colossal Clean Crawled Corpus\" (https://aclanthology.org/2021.emnlp-m\\nain.98.pdf) (PDF). EMNLP. arXiv:2104.08758 (https://arxiv.org/abs/2104.08758).\\ndoi:10.1145/3571730 (https://doi.org/10.1145%2F3571730).\\n46. Lee, Katherine; Ippolito, Daphne; Nystrom, Andrew; Zhang, Chiyuan; Eck, Douglas;\\nCallison-Burch, Chris; Carlini, Nicholas (May 2022). \"Deduplicating Training Data Makes\\nLanguage Models Better\" (https://aclanthology.org/2022.acl-long.577.pdf) (PDF).\\nProceedings of the 60th Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers). pp.\\xa08424‚Äì8445. doi:10.18653/v1/2022.acl-long.577 (https://doi.or\\ng/10.18653%2Fv1%2F2022.acl-long.577).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 26, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='47. Li, Yuanzhi; Bubeck, S√©bastien; Eldan, Ronen; Del Giorno, Allie; Gunasekar, Suriya; Lee,\\nYin Tat (2023-09-11). \"Textbooks Are All You Need II: phi-1.5 technical report\".\\narXiv:2309.05463 (https://arxiv.org/abs/2309.05463) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n48. Lin, Zhenghao; Gou, Zhibin; Gong, Yeyun; Liu, Xiao; Shen, Yelong; Xu, Ruochen; Lin, Chen;\\nYang, Yujiu; Jiao, Jian (2024-04-11). \"Rho-1: Not All Tokens Are What You Need\" (https://dl.\\nacm.org/doi/10.5555/3737916.3738830). NeurIPS. 37: 29029‚Äì29063. ISBN\\xa0979-8-3313-\\n1438-5.\\n49. Abdin, Marah; Jacobs, Sam Ade; Awan, Ammar Ahmad; Aneja, Jyoti; Awadallah, Ahmed;\\nAwadalla, Hany; Bach, Nguyen; Bahree, Amit; Bakhtiari, Arash (2024-04-23). \"Phi-3\\nTechnical Report: A Highly Capable Language Model Locally on Your Phone\".\\narXiv:2404.14219 (https://arxiv.org/abs/2404.14219) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n50. Wolfram, Stephen (2023). What is ChatGPT doing ... and why does it work?. Champaign,\\nIllinois: Wolfram Media, Inc. ISBN\\xa0978-1-57955-081-3.\\n51. Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, Dario Amodei (2017).\\n\"Deep reinforcement learning from human preferences\". arXiv:1706.03741 (https://arxiv.org/\\nabs/1706.03741) [stat.ML (https://arxiv.org/archive/stat.ML)].\\n52. Edwards, Benj (2023-05-09). \"AI gains \"values\" with Anthropic\\'s new Constitutional AI\\nchatbot approach\" (https://arstechnica.com/information-technology/2023/05/ai-with-a-moral-\\ncompass-anthropic-outlines-constitutional-ai-in-its-claude-chatbot/). Ars Technica. Retrieved\\n2025-06-30.\\n53. Snyder, Alison (2022-01-27). \"Next generation AI can follow a person\\'s instructions and\\nintentions\" (https://www.axios.com/2022/01/27/ai-instructions-learning-algorithm). Axios.\\nRetrieved 2025-08-07.\\n54. Appen, Sujatha Sagiraju (2023-04-23). \"How reinforcement learning with human feedback is\\nunlocking the power of generative AI\" (http://web.archive.org/web/20250725060432/https://v\\nenturebeat.com/ai/how-reinforcement-learning-with-human-feedback-is-unlocking-the-power\\n-of-generative-ai/). VentureBeat. Archived from the original (https://venturebeat.com/ai/how-r\\neinforcement-learning-with-human-feedback-is-unlocking-the-power-of-generative-ai/) on\\n2025-07-25. Retrieved 2025-11-16.\\n55. Allamar, Jay. \"Illustrated transformer\" (https://jalammar.github.io/illustrated-transformer/).\\nArchived (https://web.archive.org/web/20230725230033/http://jalammar.github.io/illustrated-t\\nransformer/) from the original on 2023-07-25. Retrieved 2023-07-29.\\n56. Allamar, Jay. \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\" (https://jal\\nammar.github.io/illustrated-gpt2/). Retrieved 2023-08-01.\\n57. Yeung, Ken (2024-05-14). \"Google announces Gemini 1.5 Flash, a rapid multimodal model\\nwith a 1M context window\" (https://venturebeat.com/ai/google-gemini-1-5-flash-rapid-multim\\nodal-model-announced/). VentureBeat. Retrieved 2025-08-26.\\n58. Zaib, Munazza; Sheng, Quan Z.; Emma Zhang, Wei (4 February 2020). \"A Short Survey of\\nPre-trained Language Models for Conversational AI-A New Age in NLP\". Proceedings of the\\nAustralasian Computer Science Week Multiconference (https://www.researchgate.net/public\\nation/338931711). pp.\\xa01‚Äì4. arXiv:2104.10810 (https://arxiv.org/abs/2104.10810).\\ndoi:10.1145/3373017.3373028 (https://doi.org/10.1145%2F3373017.3373028). ISBN\\xa0978-1-\\n4503-7697-6. S2CID\\xa0211040895 (https://api.semanticscholar.org/CorpusID:211040895).\\n59. Jurafsky, Dan; Martin, James H. (7 January 2023). Speech and Language Processing (http\\ns://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf) (PDF) (3rd edition draft\\xa0ed.).\\nArchived (https://web.archive.org/web/20230323210221/https://web.stanford.edu/~jurafsky/s\\nlp3/ed3book_jan72023.pdf) (PDF) from the original on 23 March 2023. Retrieved 24 May\\n2022.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 27, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='60. Shazeer, Noam; Mirhoseini, Azalia; Maziarz, Krzysztof; Davis, Andy; Le, Quoc; Hinton,\\nGeoffrey; Dean, Jeff (2025). \"Perceptions of Sentient AI and Other Digital Minds: Evidence\\nfrom the AI, Morality, and Sentience (AIMS) Survey\". Proceedings of the 2025 CHI\\nConference on Human Factors in Computing Systems. pp.\\xa01‚Äì22. arXiv:1701.06538 (https://\\narxiv.org/abs/1701.06538). doi:10.1145/3706598.3713329 (https://doi.org/10.1145%2F3706\\n598.3713329). ISBN\\xa0979-8-4007-1394-1.\\n61. Lepikhin, Dmitry; Lee, HyoukJoong; Xu, Yuanzhong; Chen, Dehao; Firat, Orhan; Huang,\\nYanping; Krikun, Maxim; Shazeer, Noam; Chen, Zhifeng (2021-01-12). \"GShard: Scaling\\nGiant Models with Conditional Computation and Automatic Sharding\". arXiv:2006.16668 (htt\\nps://arxiv.org/abs/2006.16668) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n62. Dai, Andrew M; Du, Nan (December 9, 2021). \"More Efficient In-Context Learning with\\nGLaM\" (https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html).\\nai.googleblog.com. Archived (https://web.archive.org/web/20230312072042/https://ai.google\\nblog.com/2021/12/more-efficient-in-context-learning-with.html) from the original on 2023-03-\\n12. Retrieved 2023-03-09.\\n63. Mann, Tobias. \"How to run an LLM locally on your PC in less than 10 minutes\" (https://www.t\\nheregister.com/2024/03/17/ai_pc_local_llm/). www.theregister.com. Retrieved 2024-05-17.\\n64. Nagel, Markus; Amjad, Rana Ali; Baalen, Mart Van; Louizos, Christos; Blankevoort, Tijmen\\n(2020-11-21). \"Up or Down? Adaptive Rounding for Post-Training Quantization\" (https://proc\\needings.mlr.press/v119/nagel20a.html). Proceedings of the 37th International Conference\\non Machine Learning. PMLR: 7197‚Äì7206. Archived (https://web.archive.org/web/202306140\\n80854/https://proceedings.mlr.press/v119/nagel20a.html) from the original on 2023-06-14.\\nRetrieved 2023-06-14.\\n65. Mittal, Aayush Mittal (2023-10-24). \"LoRa, QLoRA and QA-LoRA: Efficient Adaptability in\\nLarge Language Models Through Low-Rank Matrix Factorization\" (https://www.unite.ai/lora-\\nqlora-and-qa-lora-efficient-adaptability-in-large-language-models-through-low-rank-matrix-fa\\nctorization/). Unite.AI. Retrieved 2025-11-16.\\n66. Wang, Yizhong; Kordi, Yeganeh; Mishra, Swaroop; Liu, Alisa; Smith, Noah A.; Khashabi,\\nDaniel; Hajishirzi, Hannaneh (2023). \"Self-Instruct: Aligning Language Models with Self-\\nGenerated Instructions\" (https://aclanthology.org/2023.acl-long.754/). Self-Instruct: Aligning\\nLanguage Model with Self Generated Instructions. pp.\\xa013484‚Äì13508.\\ndoi:10.18653/v1/2023.acl-long.754 (https://doi.org/10.18653%2Fv1%2F2023.acl-long.754).\\n67. Lewis, Patrick; Perez, Ethan; Piktus, Aleksandra; Petroni, Fabio; Karpukhin, Vladimir; Goyal,\\nNaman; K√ºttler, Heinrich; Lewis, Mike; Yih, Wen-tau; Rockt√§schel, Tim; Riedel, Sebastian;\\nKiela, Douwe (2020). \"Retrieval-Augmented Generation for Knowledge-Intensive NLP\\nTasks\" (https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df748\\n1e5-Abstract.html). Advances in Neural Information Processing Systems. 33. Curran\\nAssociates, Inc.: 9459‚Äì9474. arXiv:2005.11401 (https://arxiv.org/abs/2005.11401). Archived\\n(https://web.archive.org/web/20230612171229/https://proceedings.neurips.cc/paper/2020/h\\nash/6b493230205f780e1bc26945df7481e5-Abstract.html) from the original on 2023-06-12.\\nRetrieved 2023-06-12.\\n68. Dickson, Ben (2025-04-02). \"The tool integration problem that\\'s holding back enterprise AI\\n(and how CoTools solves it)\" (https://venturebeat.com/ai/the-tool-integration-problem-thats-h\\nolding-back-enterprise-ai-and-how-cotools-solves-it/). VentureBeat. Retrieved 2025-05-26.\\n69. Liang, Yaobo; Wu, Chenfei; Song, Ting; Wu, Wenshan; Xia, Yan; Liu, Yu; Ou, Yang; Lu,\\nShuai; Ji, Lei; Mao, Shaoguang; Wang, Yun; Shou, Linjun; Gong, Ming; Duan, Nan (2024).\\n\"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs\"\\n(https://doi.org/10.34133%2Ficomputing.0063). Science. 3 0063.\\ndoi:10.34133/icomputing.0063 (https://doi.org/10.34133%2Ficomputing.0063).\\n70. Patil, Shishir G.; Zhang, Tianjun; Wang, Xin; Gonzalez, Joseph E. (2023-05-01). \"Gorilla:\\nLarge Language Model Connected with Massive APIs\" (https://proceedings.neurips.cc/paper\\n_files/paper/2024/hash/e4c61f578ff07830f5c37378dd3ecb0d-Abstract-Conference.html).\\nNeurIPS. 37: 126544‚Äì126565.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 28, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='71. \"ChatGPT-AutoExpert/_system-prompts/all_tools.md at\\n835baae768870aa9747663c24d8216820d24fd74 ¬∑ spdustin/ChatGPT-AutoExpert\" (https://g\\nithub.com/spdustin/ChatGPT-AutoExpert/blob/835baae768870aa9747663c24d8216820d24f\\nd74/_system-prompts/all_tools.md). GitHub.\\n72. Wang, Lei; Ma, Chen; Feng, Xueyang; Zhang, Zeyu; Yang, Hao; Zhang, Jingsen; Chen,\\nZhiyuan; Tang, Jiakai; Chen, Xu; Lin, Yankai; Zhao, Wayne Xin; Wei, Zhewei; Wen, Jirong\\n(December 2024). \"A survey on large language model based autonomous agents\". Frontiers\\nof Computer Science. 18 (6) 186345. arXiv:2308.11432 (https://arxiv.org/abs/2308.11432).\\ndoi:10.1007/s11704-024-40231-1 (https://doi.org/10.1007%2Fs11704-024-40231-1).\\n73. Yao, Shunyu; Zhao, Jeffrey; Yu, Dian; Du, Nan; Shafran, Izhak; Narasimhan, Karthik; Cao,\\nYuan (2022-10-01). \"ReAct: Synergizing Reasoning and Acting in Language Models\".\\narXiv:2210.03629 (https://arxiv.org/abs/2210.03629) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n74. Wang, Zihao; Cai, Shaofei; Liu, Anji; Ma, Xiaojian; Liang, Yitao (2023-02-03). \"Describe,\\nExplain, Plan and Select: Interactive Planning with Large Language Models Enables Open-\\nWorld Multi-Task Agents\" (https://dl.acm.org/doi/10.5555/3666122.3667602). NeurIPS:\\n34153‚Äì34189.\\n75. Shinn, Noah; Cassano, Federico; Labash, Beck; Gopinath, Ashwin; Narasimhan, Karthik;\\nYao, Shunyu (2023-03-01). \"Reflexion: Language Agents with Verbal Reinforcement\\nLearning\" (https://dl.acm.org/doi/10.5555/3666122.3667602). NeurIPS: 34153‚Äì34189.\\n76. Hao, Shibo; Gu, Yi; Ma, Haodi; Jiahua Hong, Joshua; Wang, Zhen; Zhe Wang, Daisy; Hu,\\nZhiting (2023-05-01). \"Reasoning with Language Model is Planning with World Model\" (http\\ns://aclanthology.org/2023.emnlp-main.507/). EMNLP: 8154‚Äì8173.\\ndoi:10.18653/v1/2023.emnlp-main.507 (https://doi.org/10.18653%2Fv1%2F2023.emnlp-mai\\nn.507).\\n77. Zhang, Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff (2 June 2023). \"OMNI: Open-\\nendedness via Models of human Notions of Interestingness\". arXiv:2306.01711 (https://arxi\\nv.org/abs/2306.01711) [cs.AI (https://arxiv.org/archive/cs.AI)].\\n78. \"Voyager | An Open-Ended Embodied Agent with Large Language Models\" (https://voyager.\\nminedojo.org/). voyager.minedojo.org. Archived (https://web.archive.org/web/202306082250\\n54/https://voyager.minedojo.org/) from the original on 2023-06-08. Retrieved 2023-06-09.\\n79. Park, Joon Sung; O\\'Brien, Joseph C.; Cai, Carrie J.; Ringel Morris, Meredith; Liang, Percy;\\nBernstein, Michael S. (2023-04-01). Generative Agents: Interactive Simulacra of Human\\nBehavior. UIST. doi:10.1145/3586183.3606763 (https://doi.org/10.1145%2F3586183.36067\\n63).\\n80. Nye, Maxwell; Anders, Andreassen Johan; Gur-Ari, Guy; Michalewski, Henryk; Austin,\\nJacob; Bieber, David; Dohan, David; Lewkowycz, Aitor; Bosma, Maarten; Luan, David;\\nSutton, Charles; Odena, Augustus (30 November 2021). \"Show Your Work: Scratchpads for\\nIntermediate Computation with Language Models\". arXiv:2112.00114 (https://arxiv.org/abs/2\\n112.00114) [cs.LG (https://arxiv.org/archive/cs.LG)].\\n81. Wu, Tongshuang; et\\xa0al. (2022-04-28). \"PromptChainer: Chaining Large Language Model\\nPrompts through Visual Programming\" (https://doi.org/10.1145/3491101.3519729). CHI\\nConference on Human Factors in Computing Systems Extended Abstracts. Association for\\nComputing Machinery. pp.\\xa01‚Äì10. doi:10.1145/3491101.3519729 (https://doi.org/10.1145%2\\nF3491101.3519729). ISBN\\xa0978-1-4503-9156-6.\\n82. Wu, Tongshuang; Jiang, Ellen; Donsbach, Aaron; Gray, Jeff; Molina, Alejandra; Terry,\\nMichael; Cai, Carrie J. (2022-03-13). PromptChainer: Chaining Large Language Model\\nPrompts through Visual Programming (https://dl.acm.org/doi/10.1145/3491101.3519729).\\nCHI Conference on Human Factors in Computing Systems. arXiv:2203.06566 (https://arxiv.o\\nrg/abs/2203.06566). doi:10.1145/3491101.3519729 (https://doi.org/10.1145%2F3491101.35\\n19729).\\n83. \"What is prompt chaining?\" (https://www.ibm.com/think/topics/prompt-chaining). IBM. 23\\nApril 2024.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 29, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='84. Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bosma, Maarten; Ichter, Brian; Xia, Fei; Chi,\\nEd; Le, Quoc; Zhou, Denny (2023-01-10). \"Chain-of-Thought Prompting Elicits Reasoning in\\nLarge Language Models\" (https://dl.acm.org/doi/10.5555/3600270.3602070). NeurIPS:\\n24824‚Äì24837. ISBN\\xa0978-1-7138-7108-8.\\n85. \"What is chain of thought (CoT) prompting?\" (https://www.ibm.com/think/topics/chain-of-thou\\nghts). IBM. 23 April 2025.\\n86. Schreiner, Maximilian (2022-09-27). \"Deeper insights into AI language models - chain of\\nthought prompting as a success factor\" (https://the-decoder.com/deeper-insights-for-ai-langu\\nage-models-chain-of-thought-prompting-as-a-key-factor/). The Decoder. Retrieved\\n2025-06-30.\\n87. Wiggers, Kyle (2024-12-14). \" \\'Reasoning\\' AI models have become a trend, for better or\\nworse\" (https://techcrunch.com/2024/12/14/reasoning-ai-models-have-become-a-trend-for-b\\netter-or-worse/). TechCrunch. Retrieved 2025-11-16.\\n88. \"AI Developers Look Beyond Chain-of-Thought Prompting\" (https://spectrum.ieee.org/chain-\\nof-thought-prompting). IEEE Spectrum. 2025-05-08. Retrieved 2025-11-16.\\n89. Metz, Cade (2024-12-20). \"OpenAI Unveils New A.I. That Can \\'Reason\\' Through Math and\\nScience Problems\" (https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-s\\ncience.html). The New York Times. Retrieved 2025-02-03.\\n90. Gibney, Elizabeth (2025-01-30). \"China\\'s cheap, open AI model DeepSeek thrills scientists\"\\n(https://www.nature.com/articles/d41586-025-00229-6). Nature. Retrieved 2025-02-03.\\n91. Sharma, Asankhaya. \"OptiLLM: Optimizing inference proxy for LLMs\" (https://github.com/co\\ndelion/optillm). GitHub. Retrieved 2025-08-05.\\n92. \"OptiLLM: An OpenAI API Compatible Optimizing Inference Proxy which Implements\\nSeveral State-of-the-Art Techniques that can Improve the Accuracy and Performance of\\nLLMs\" (https://www.marktechpost.com/2024/11/18/optillm-an-openai-api-compatible-optimizi\\nng-inference-proxy-which-implements-several-state-of-the-art-techniques-that-can-improve-t\\nhe-accuracy-and-performance-of-llms/). MarkTechPost. 2024-11-18. Retrieved 2025-08-05.\\n93. Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Rich (2014-06-18). \"Multimodal Neural\\nLanguage Models\" (https://proceedings.mlr.press/v32/kiros14.html). Proceedings of the 31st\\nInternational Conference on Machine Learning. PMLR: 595‚Äì603. Archived (https://web.archi\\nve.org/web/20230702195952/https://proceedings.mlr.press/v32/kiros14.html) from the\\noriginal on 2023-07-02. Retrieved 2023-07-02.\\n94. Driess, Danny; Xia, Fei; Sajjadi, Mehdi S. M.; Lynch, Corey; Chowdhery, Aakanksha; Ichter,\\nBrian; Wahid, Ayzaan; Tompson, Jonathan; Vuong, Quan; Yu, Tianhe; Huang, Wenlong;\\nChebotar, Yevgen; Sermanet, Pierre; Duckworth, Daniel; Levine, Sergey (2023-03-01).\\n\"PaLM-E: An Embodied Multimodal Language Model\" (https://dl.acm.org/doi/10.5555/36184\\n08.3618748). ICML. 202: 8469‚Äì8488.\\n95. Liu, Haotian; Li, Chunyuan; Wu, Qingyang; Lee, Yong Jae (2023-04-01). \"Visual Instruction\\nTuning\". NeurIPS.\\n96. Zhang, Hang; Li, Xin; Bing, Lidong (2023-06-01). \"Video-LLaMA: An Instruction-tuned Audio-\\nVisual Language Model for Video Understanding\". EMNLP. arXiv:2306.02858 (https://arxiv.o\\nrg/abs/2306.02858).\\n97. \"OpenAI says natively multimodal GPT-4o eats text, visuals, sound ‚Äì and emits the same\"\\n(https://www.theregister.com/2024/05/13/openai_gpt4o/). The Register. 2024-05-13.\\n98. Zia, Dr Tehseen (2024-01-08). \"Unveiling of Large Multimodal Models: Shaping the\\nLandscape of Language Models in 2024\" (https://www.unite.ai/unveiling-of-large-multimodal-\\nmodels-shaping-the-landscape-of-language-models-in-2024/). Unite.AI. Retrieved\\n2025-05-30.\\n99. Li, Junnan; Li, Dongxu; Savarese, Silvio; Hoi, Steven (2023-01-01). \"BLIP-2: Bootstrapping\\nLanguage-Image Pre-training with Frozen Image Encoders and Large Language Models\" (ht\\ntps://dl.acm.org/doi/10.5555/3618408.3619222). ICML. 202: 19730‚Äì19742.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 30, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='100. Kumar, Puneet; Khokher, Vedanti; Gupta, Yukti; Raman, Balasubramanian (2021). Hybrid\\nFusion Based Approach for Multimodal Emotion Recognition with Insufficient Labeled Data.\\npp.\\xa0314‚Äì318. doi:10.1109/ICIP42928.2021.9506714 (https://doi.org/10.1109%2FICIP42928.\\n2021.9506714). ISBN\\xa0978-1-6654-4115-5.\\n101. Alayrac, Jean-Baptiste; Donahue, Jeff; Luc, Pauline; Miech, Antoine; Barr, Iain; Hasson,\\nYana; Lenc, Karel; Mensch, Arthur; Millican, Katherine; Reynolds, Malcolm; Ring, Roman;\\nRutherford, Eliza; Cabi, Serkan; Han, Tengda; Gong, Zhitao (2022-12-06). \"Flamingo: a\\nVisual Language Model for Few-Shot Learning\" (https://proceedings.neurips.cc/paper_files/\\npaper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html).\\nAdvances in Neural Information Processing Systems. 35 (12): 23716‚Äì23736.\\narXiv:2204.14198 (https://arxiv.org/abs/2204.14198). doi:10.1093/nsr/nwae403 (https://doi.o\\nrg/10.1093%2Fnsr%2Fnwae403). PMC\\xa011645129 (https://www.ncbi.nlm.nih.gov/pmc/article\\ns/PMC11645129). PMID\\xa039679213 (https://pubmed.ncbi.nlm.nih.gov/39679213). Archived\\n(https://web.archive.org/web/20230702195951/https://proceedings.neurips.cc/paper_files/pa\\nper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html) from the\\noriginal on 2023-07-02. Retrieved 2023-07-02.\\n102. Finnie-Ansley, James; Denny, Paul; Becker, Brett A.; Luxton-Reilly, Andrew; Prather, James\\n(14 February 2022). \"The Robots Are Coming: Exploring the Implications of OpenAI Codex\\non Introductory Programming\". Proceedings of the 24th Australasian Computing Education\\nConference. New York, NY, USA: Association for Computing Machinery. pp.\\xa010‚Äì19.\\ndoi:10.1145/3511861.3511863 (https://doi.org/10.1145%2F3511861.3511863). ISBN\\xa0978-1-\\n4503-9643-1. S2CID\\xa0246681316 (https://api.semanticscholar.org/CorpusID:246681316).\\n103. Husein, Rasha Ahmad; Aburajouh, Hala; Catal, Cagatay (March 2025). \"Large language\\nmodels for code completion: A systematic literature review\". Computer Standards &\\nInterfaces. 92 103917. doi:10.1016/j.csi.2024.103917 (https://doi.org/10.1016%2Fj.csi.2024.\\n103917).\\n104. Weissenow, Konstantin; Rost, Burkhard (April 2025). \"Are protein language models the new\\nuniversal key?\" (https://doi.org/10.1016%2Fj.sbi.2025.102997). Current Opinion in Structural\\nBiology. 91 102997. doi:10.1016/j.sbi.2025.102997 (https://doi.org/10.1016%2Fj.sbi.2025.10\\n2997). PMID\\xa039921962 (https://pubmed.ncbi.nlm.nih.gov/39921962).\\n105. Lin, Zeming; Akin, Halil; Rao, Roshan; Hie, Brian; Zhu, Zhongkai; Lu, Wenting; Smetanin,\\nNikita; Verkuil, Robert; Kabeli, Ori; Shmueli, Yaniv; dos Santos Costa, Allan; Fazel-Zarandi,\\nMaryam; Sercu, Tom; Candido, Salvatore; Rives, Alexander (17 March 2023). \"Evolutionary-\\nscale prediction of atomic-level protein structure with a language model\" (https://doi.org/10.1\\n126%2Fscience.ade2574). Science. 379 (6637): 1123‚Äì1130. Bibcode:2023Sci...379.1123L\\n(https://ui.adsabs.harvard.edu/abs/2023Sci...379.1123L).\\nbioRxiv\\xa010.1101/2022.07.20.500902 (https://doi.org/10.1101%2F2022.07.20.500902).\\ndoi:10.1126/science.ade2574 (https://doi.org/10.1126%2Fscience.ade2574).\\nPMID\\xa036927031 (https://pubmed.ncbi.nlm.nih.gov/36927031).\\n106. \"ESM Metagenomic Atlas | Meta AI\" (https://esmatlas.com/about). esmatlas.com.\\n107. Hayes, Thomas; Rao, Roshan; Akin, Halil; Sofroniew, Nicholas J.; Oktay, Deniz; Lin,\\nZeming; Verkuil, Robert; Tran, Vincent Q.; Deaton, Jonathan; Wiggert, Marius; Badkundri,\\nRohil; Shafkat, Irhum; Gong, Jun; Derry, Alexander; Molina, Raul S.; Thomas, Neil; Khan,\\nYousuf A.; Mishra, Chetan; Kim, Carolyn; Bartie, Liam J.; Nemeth, Matthew; Hsu, Patrick D.;\\nSercu, Tom; Candido, Salvatore; Rives, Alexander (21 February 2025). \"Simulating 500\\nmillion years of evolution with a language model\". Science. 387 (6736): 850‚Äì858.\\nBibcode:2025Sci...387..850H (https://ui.adsabs.harvard.edu/abs/2025Sci...387..850H).\\ndoi:10.1126/science.ads0018 (https://doi.org/10.1126%2Fscience.ads0018).\\nPMID\\xa039818825 (https://pubmed.ncbi.nlm.nih.gov/39818825).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 31, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='108. Fishman, Veniamin; Kuratov, Yuri; Shmelev, Aleksei; Petrov, Maxim; Penzar, Dmitry;\\nShepelin, Denis; Chekanov, Nikolay; Kardymon, Olga; Burtsev, Mikhail (11 January 2025).\\n\"GENA-LM: a family of open-source foundational DNA language models for long\\nsequences\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11734698). Nucleic Acids\\nResearch. 53 (2) gkae1310. doi:10.1093/nar/gkae1310 (https://doi.org/10.1093%2Fnar%2F\\ngkae1310). PMC\\xa011734698 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11734698).\\nPMID\\xa039817513 (https://pubmed.ncbi.nlm.nih.gov/39817513).\\n109. Wang, Ning; Bian, Jiang; Li, Yuchen; Li, Xuhong; Mumtaz, Shahid; Kong, Linghe; Xiong,\\nHaoyi (13 May 2024). \"Multi-purpose RNA language modelling with motif-aware pretraining\\nand type-guided fine-tuning\" (https://doi.org/10.1038%2Fs42256-024-00836-4). Nature\\nMachine Intelligence. 6 (5): 548‚Äì557. doi:10.1038/s42256-024-00836-4 (https://doi.org/10.1\\n038%2Fs42256-024-00836-4).\\n110. Hoffmann, Jordan; Borgeaud, Sebastian; Mensch, Arthur; Buchatskaya, Elena; Cai, Trevor;\\nRutherford, Eliza; Casas, Diego de Las; Hendricks, Lisa Anne; Welbl, Johannes; Clark,\\nAidan; Hennigan, Tom; Noland, Eric; Millican, Katie; Driessche, George van den; Damoc,\\nBogdan (2022-03-29). \"Training Compute-Optimal Large Language Models\" (https://dl.acm.\\norg/doi/10.5555/3600270.3602446). NeurIPS: 30016‚Äì30030. ISBN\\xa0978-1-7138-7108-8.\\n111. Caballero, Ethan; Gupta, Kshitij; Rish, Irina; Krueger, David (2022). \"Broken Neural Scaling\\nLaws\". arXiv:2210.14891 (https://arxiv.org/abs/2210.14891) [cs.LG (https://arxiv.org/archive/\\ncs.LG)].\\n112. Wei, Jason; Tay, Yi; Bommasani, Rishi; Raffel, Colin; Zoph, Barret; Borgeaud, Sebastian;\\nYogatama, Dani; Bosma, Maarten; Zhou, Denny; Metzler, Donald; Chi, Ed H.; Hashimoto,\\nTatsunori; Vinyals, Oriol; Liang, Percy; Dean, Jeff; Fedus, William (31 August 2022).\\n\"Emergent Abilities of Large Language Models\" (https://openreview.net/forum?id=yzkSU5zd\\nwD). Transactions on Machine Learning Research. ISSN\\xa02835-8856 (https://search.worldca\\nt.org/issn/2835-8856). Archived (https://web.archive.org/web/20230322210052/https://openr\\neview.net/forum?id=yzkSU5zdwD) from the original on 22 March 2023. Retrieved 19 March\\n2023.\\n113. \"137 emergent abilities of large language models\" (https://www.jasonwei.net/blog/emergenc\\ne). Jason Wei. Retrieved 2023-06-24.\\n114. Bowman, Samuel R. (2024). \"Eight Things to Know about Large Language Models\" (https://r\\nead.dukeupress.edu/critical-ai/article/doi/10.1215/2834703X-11556011/400182/Eight-Thing\\ns-to-Know-about-Large-Language-Models). Critical AI. 2 (2). doi:10.1215/2834703X-\\n11556011 (https://doi.org/10.1215%2F2834703X-11556011).\\n115. Hahn, Michael; Goyal, Navin (2024). \"A survey on large language model based autonomous\\nagents\". Frontiers of Computer Science. 18 (6) 186345. arXiv:2303.07971 (https://arxiv.org/\\nabs/2303.07971). doi:10.1007/s11704-024-40231-1 (https://doi.org/10.1007%2Fs11704-024\\n-40231-1).\\n116. Pilehvar, Mohammad Taher; Camacho-Collados, Jose (June 2019). \"Proceedings of the\\n2019 Conference of the North\" (https://aclanthology.org/N19-1128). Proceedings of the 2019\\nConference of the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, Volume 1 (Long and Short Papers). Minneapolis,\\nMinnesota: Association for Computational Linguistics: 1267‚Äì1273. doi:10.18653/v1/N19-\\n1128 (https://doi.org/10.18653%2Fv1%2FN19-1128). S2CID\\xa0102353817 (https://api.semanti\\ncscholar.org/CorpusID:102353817). Archived (https://web.archive.org/web/2023062720273\\n2/https://aclanthology.org/N19-1128/) from the original on 2023-06-27. Retrieved\\n2023-06-27.\\n117. \"WiC: The Word-in-Context Dataset\" (https://pilehvar.github.io/wic/). pilehvar.github.io.\\nArchived (https://web.archive.org/web/20230627202725/https://pilehvar.github.io/wic/) from\\nthe original on 2023-06-27. Retrieved 2023-06-27.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 32, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='118. Patel, Roma; Pavlick, Ellie (2021-10-06). \"Mapping Language Models to Grounded\\nConceptual Spaces\" (https://openreview.net/forum?id=gJcEM8sxHK). ICLR. Archived (http\\ns://web.archive.org/web/20230624191940/https://openreview.net/forum?id=gJcEM8sxHK)\\nfrom the original on 2023-06-24. Retrieved 2023-06-27.\\n119. A Closer Look at Large Language Models Emergent Abilities (https://www.notion.so/A-Close\\nr-Look-at-Large-Language-Models-Emergent-Abilities-493876b55df5479d80686f68a1abd72\\nf) Archived (https://web.archive.org/web/20230624012329/https://www.notion.so/A-Closer-L\\nook-at-Large-Language-Models-Emergent-Abilities-493876b55df5479d80686f68a1abd72f)\\n2023-06-24 at the Wayback Machine (Yao Fu, Nov 20, 2022)\\n120. Ornes, Stephen (March 16, 2023). \"The Unpredictable Abilities Emerging From Large AI\\nModels\" (https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-a\\ni-models-20230316/). Quanta Magazine. Archived (https://web.archive.org/web/2023031620\\n3438/https://www.quantamagazine.org/the-unpredictable-abilities-emerging-from-large-ai-m\\nodels-20230316/) from the original on March 16, 2023. Retrieved March 16, 2023.\\n121. Schaeffer, Rylan; Miranda, Brando; Koyejo, Sanmi (2023-04-01). \"Are Emergent Abilities of\\nLarge Language Models a Mirage?\". NeurIPS. arXiv:2304.15004 (https://arxiv.org/abs/2304.\\n15004).\\n122. Nanda, Neel; Chan, Lawrence; Lieberum, Tom; Smith, Jess; Steinhardt, Jacob (2023-01-\\n01). \"Progress measures for grokking via mechanistic interpretability\". arXiv:2301.05217 (htt\\nps://arxiv.org/abs/2301.05217) [cs.LG (https://arxiv.org/archive/cs.LG)].\\n123. Ananthaswamy, Anil (2024-04-12). \"How Do Machines \\'Grok\\' Data?\" (https://www.quantama\\ngazine.org/how-do-machines-grok-data-20240412/). Quanta Magazine. Retrieved\\n2025-06-30.\\n124. Mitchell, Melanie; Krakauer, David C. (28 March 2023). \"The debate over understanding in\\nAI\\'s large language models\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10068812).\\nProceedings of the National Academy of Sciences. 120 (13) e2215907120.\\narXiv:2210.13966 (https://arxiv.org/abs/2210.13966). Bibcode:2023PNAS..12015907M (http\\ns://ui.adsabs.harvard.edu/abs/2023PNAS..12015907M). doi:10.1073/pnas.2215907120 (htt\\nps://doi.org/10.1073%2Fpnas.2215907120). PMC\\xa010068812 (https://www.ncbi.nlm.nih.gov/p\\nmc/articles/PMC10068812). PMID\\xa036943882 (https://pubmed.ncbi.nlm.nih.gov/36943882).\\n125. Metz, Cade (16 May 2023). \"Microsoft Says New A.I. Shows Signs of Human Reasoning\" (h\\nttps://www.nytimes.com/2023/05/16/technology/microsoft-ai-human-reasoning.html). The\\nNew York Times.\\n126. Bubeck, S√©bastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz,\\nEric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha;\\nPalangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (2023). \"Machine culture\". Nature Human\\nBehaviour. 7 (11): 1855‚Äì1868. arXiv:2303.12712 (https://arxiv.org/abs/2303.12712).\\ndoi:10.1038/s41562-023-01742-2 (https://doi.org/10.1038%2Fs41562-023-01742-2).\\nPMID\\xa037985914 (https://pubmed.ncbi.nlm.nih.gov/37985914).\\n127. \"Anthropic CEO Dario Amodei pens a smart look at our AI future\" (https://www.fastcompany.\\ncom/91211163/anthropic-ceo-dario-amodei-pens-a-smart-look-at-our-ai-future). Fast\\nCompany. October 17, 2024.\\n128. \"ChatGPT is more like an \\'alien intelligence\\' than a human brain, says futurist\" (https://www.\\nzdnet.com/article/chatgpt-is-more-like-an-alien-intelligence-than-a-human-brain-says-futuris\\nt/). ZDNET. 2023. Archived (https://web.archive.org/web/20230612065937/https://www.zdne\\nt.com/article/chatgpt-is-more-like-an-alien-intelligence-than-a-human-brain-says-futurist/)\\nfrom the original on 12 June 2023. Retrieved 12 June 2023.\\n129. Newport, Cal (13 April 2023). \"What Kind of Mind Does ChatGPT Have?\" (https://www.newy\\norker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have).\\nThe New Yorker. Archived (https://web.archive.org/web/20230612071443/https://www.newy\\norker.com/science/annals-of-artificial-intelligence/what-kind-of-mind-does-chatgpt-have)\\nfrom the original on 12 June 2023. Retrieved 12 June 2023.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 33, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='130. Roose, Kevin (30 May 2023). \"Why an Octopus-like Creature Has Come to Symbolize the\\nState of A.I.\" (https://www.nytimes.com/2023/05/30/technology/shoggoth-meme-ai.html) The\\nNew York Times. Archived (https://web.archive.org/web/20230530193814/https://www.nytim\\nes.com/2023/05/30/technology/shoggoth-meme-ai.html) from the original on 30 May 2023.\\nRetrieved 12 June 2023.\\n131. \"The A to Z of Artificial Intelligence\" (https://time.com/6271657/a-to-z-of-artificial-intelligenc\\ne/). Time Magazine. 13 April 2023. Archived (https://web.archive.org/web/20230616123839/\\nhttps://time.com/6271657/a-to-z-of-artificial-intelligence/) from the original on 16 June 2023.\\nRetrieved 12 June 2023.\\n132. Sekrst, Kristina (2025). The Illusion Engine: The Quest for Machine Consciousness.\\nSpringer. ISBN\\xa0978-3-032-05561-3.\\n133. Ji, Ziwei; Lee, Nayeon; Frieske, Rita; Yu, Tiezheng; Su, Dan; Xu, Yan; Ishii, Etsuko; Bang,\\nYejin; Dai, Wenliang; Madotto, Andrea; Fung, Pascale (November 2022). \"Survey of\\nHallucination in Natural Language Generation\" (https://dl.acm.org/doi/pdf/10.1145/3571730)\\n(pdf). ACM Computing Surveys. 55 (12). Association for Computing Machinery: 1‚Äì38.\\narXiv:2202.03629 (https://arxiv.org/abs/2202.03629). doi:10.1145/3571730 (https://doi.org/1\\n0.1145%2F3571730). S2CID\\xa0246652372 (https://api.semanticscholar.org/CorpusID:246652\\n372). Archived (https://web.archive.org/web/20230326145635/https://dl.acm.org/doi/pdf/10.1\\n145/3571730) from the original on 26 March 2023. Retrieved 15 January 2023.\\n134. Varshney, Neeraj; Yao, Wenlin; Zhang, Hongming; Chen, Jianshu; Yu, Dong (2023). \"A\\nStitch in Time Saves Nine: Detecting and Mitigating Hallucinations of LLMs by Validating\\nLow-Confidence Generation\". arXiv:2307.03987 (https://arxiv.org/abs/2307.03987) [cs.CL (h\\nttps://arxiv.org/archive/cs.CL)].\\n135. Lin, Belle (2025-02-05). \"Why Amazon is Betting on \\'Automated Reasoning\\' to Reduce AI\\'s\\nHallucinations: The tech giant says an obscure field that combines AI and math can mitigate\\n‚Äîbut not completely eliminate‚ÄîAI\\'s propensity to provide wrong answers\" (https://www.wsj.\\ncom/articles/why-amazon-is-betting-on-automated-reasoning-to-reduce-ais-hallucinations-b\\n838849e). Wall Street Journal. ISSN\\xa00099-9660 (https://search.worldcat.org/issn/0099-966\\n0).\\n136. Lakoff, George (1999). Philosophy in the Flesh: The Embodied Mind and Its Challenge to\\nWestern Philosophy; Appendix: The Neural Theory of Language Paradigm. New York Basic\\nBooks. pp.\\xa0569‚Äì583. ISBN\\xa0978-0-465-05674-3.\\n137. Evans, Vyvyan. (2014). The Language Myth. Cambridge University Press. ISBN\\xa0978-1-107-\\n04396-1.\\n138. Friston, Karl J. (2022). Active Inference: The Free Energy Principle in Mind, Brain, and\\nBehavior; Chapter 4 The Generative Models of Active Inference. The MIT Press. ISBN\\xa0978-\\n0-262-36997-8.\\n139. Brown, Tom B.; Mann, Benjamin; Ryder, Nick; Subbiah, Melanie; Kaplan, Jared; Dhariwal,\\nPrafulla; Neelakantan, Arvind; Shyam, Pranav; Sastry, Girish; Askell, Amanda; Agarwal,\\nSandhini; Herbert-Voss, Ariel; Krueger, Gretchen; Henighan, Tom; Child, Rewon; Ramesh,\\nAditya; Ziegler, Daniel M.; Wu, Jeffrey; Winter, Clemens; Hesse, Christopher; Chen, Mark;\\nSigler, Eric; Litwin, Mateusz; Gray, Scott; Chess, Benjamin; Clark, Jack; Berner, Christopher;\\nMcCandlish, Sam; Radford, Alec; Sutskever, Ilya; Amodei, Dario (Dec 2020). Larochelle, H.;\\nRanzato, M.; Hadsell, R.; Balcan, M.F.; Lin, H. (eds.). \"Language Models are Few-Shot\\nLearners\" (https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f\\n64a-Paper.pdf) (PDF). Advances in Neural Information Processing Systems. 33. Curran\\nAssociates, Inc.: 1877‚Äì1901. Archived (https://web.archive.org/web/20231117204007/http\\ns://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)\\n(PDF) from the original on 2023-11-17. Retrieved 2023-03-14.\\n140. Huyen, Chip (October 18, 2019). \"Evaluation Metrics for Language Modeling\" (https://thegra\\ndient.pub/understanding-evaluation-metrics-for-language-models/). The Gradient. Retrieved\\nJanuary 14, 2024.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 34, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='141. Shannon, Claude E. (1948). \"A Mathematical Theory of Communication\" (https://doi.org/10.1\\n002/j.1538-7305.1948.tb01338.x). Bell System Technical Journal. 27 (3): 379‚Äì423.\\nBibcode:1948BSTJ...27..379S (https://ui.adsabs.harvard.edu/abs/1948BSTJ...27..379S).\\ndoi:10.1002/j.1538-7305.1948.tb01338.x (https://doi.org/10.1002%2Fj.1538-7305.1948.tb01\\n338.x).\\n142. Edwards, Benj (2023-09-28). \"AI language models can exceed PNG and FLAC in lossless\\ncompression, says study\" (https://arstechnica.com/information-technology/2023/09/ai-langu\\nage-models-can-exceed-png-and-flac-in-lossless-compression-says-study/). Ars Technica.\\nRetrieved 2025-05-29.\\n143. \"openai/simple-evals\" (https://github.com/openai/simple-evals). OpenAI. 2024-05-28.\\nRetrieved 2024-05-28.\\n144. \"openai/evals\" (https://github.com/openai/evals). OpenAI. 2024-05-28. Archived (https://web.\\narchive.org/web/20240508225708/https://github.com/openai/evals) from the original on\\n2024-05-08. Retrieved 2024-05-28.\\n145. Clark, Christopher; Lee, Kenton; Chang, Ming-Wei; Kwiatkowski, Tom; Collins, Michael;\\nToutanova, Kristina (2019). \"BoolQ: Exploring the Surprising Difficulty of Natural Yes/No\\nQuestions\" (https://aclanthology.org/N19-1300/). ACL: 2924‚Äì2936. doi:10.18653/v1/N19-\\n1300 (https://doi.org/10.18653%2Fv1%2FN19-1300).\\n146. Wayne Xin Zhao; et\\xa0al. (2023). \"A Survey of Large Language Models\". arXiv:2303.18223 (htt\\nps://arxiv.org/abs/2303.18223) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n147. Nangia, Nikita; Vania, Clara; Bhalerao, Rasika; Bowman, Samuel R. (November 2020).\\n\"CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language\\nModels\" (https://aclanthology.org/2020.emnlp-main.154/). In Webber, Bonnie; Cohn, Trevor;\\nHe, Yulan; Liu, Yang (eds.). Proceedings of the 2020 Conference on Empirical Methods in\\nNatural Language Processing (EMNLP). Association for Computational Linguistics.\\npp.\\xa01953‚Äì1967. arXiv:2010.00133 (https://arxiv.org/abs/2010.00133).\\ndoi:10.18653/v1/2020.emnlp-main.154 (https://doi.org/10.18653%2Fv1%2F2020.emnlp-mai\\nn.154).\\n148. Nadeem, Moin; Bethke, Anna; Reddy, Siva (August 2021). \"StereoSet: Measuring\\nstereotypical bias in pretrained language models\" (https://aclanthology.org/2021.acl-long.41\\n6/). In Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto (eds.). Proceedings of the\\n59th Annual Meeting of the Association for Computational Linguistics and the 11th\\nInternational Joint Conference on Natural Language Processing (Volume 1: Long Papers).\\nAssociation for Computational Linguistics. pp.\\xa05356‚Äì5371. arXiv:2004.09456 (https://arxiv.or\\ng/abs/2004.09456). doi:10.18653/v1/2021.acl-long.416 (https://doi.org/10.18653%2Fv1%2F\\n2021.acl-long.416).\\n149. Simpson, Shmona; Nukpezah, Jonathan; Kie Brooks; Pandya, Raaghav (17 December\\n2024). \"Parity benchmark for measuring bias in LLMs\" (https://doi.org/10.1007%2Fs43681-0\\n24-00613-4). AI and Ethics. 5 (3). Springer: 3087‚Äì3101. doi:10.1007/s43681-024-00613-4\\n(https://doi.org/10.1007%2Fs43681-024-00613-4).\\n150. Caramancion, Kevin Matthe (2023-11-13). \"News Verifiers Showdown: A Comparative\\nPerformance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-\\nChecking\". 2023 IEEE Future Networks World Forum (FNWF). IEEE. pp.\\xa01‚Äì6.\\narXiv:2306.17176 (https://arxiv.org/abs/2306.17176).\\ndoi:10.1109/FNWF58287.2023.10520446 (https://doi.org/10.1109%2FFNWF58287.2023.10\\n520446). ISBN\\xa0979-8-3503-2458-7.\\n151. Bermejo, Vicente J.; Gago, Andr√©s; G√°lvez, Ramiro H.; Harari, Nicol√°s (2025). \"LLMs\\noutperform outsourced human coders on complex textual analysis\" (https://www.ncbi.nlm.ni\\nh.gov/pmc/articles/PMC12623721). Scientific Reports. 15 (1) 40122. Nature Portfolio.\\nBibcode:2025NatSR..1540122B (https://ui.adsabs.harvard.edu/abs/2025NatSR..1540122B).\\ndoi:10.1038/s41598-025-23798-y (https://doi.org/10.1038%2Fs41598-025-23798-y).\\nPMC\\xa012623721 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12623721).\\nPMID\\xa041249236 (https://pubmed.ncbi.nlm.nih.gov/41249236).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 35, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='152. Gilardi, Fabrizio; Alizadeh, Meysam; Kubli, Ma√´l (2023). \"ChatGPT outperforms crowd\\nworkers for text-annotation tasks\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1037263\\n8). Proceedings of the National Academy of Sciences of the United States of America. 120\\n(30) e2305016120. National Academy of Sciences. arXiv:2303.15056 (https://arxiv.org/abs/2\\n303.15056). Bibcode:2023PNAS..12005016G (https://ui.adsabs.harvard.edu/abs/2023PNA\\nS..12005016G). doi:10.1073/pnas.2305016120 (https://doi.org/10.1073%2Fpnas.23050161\\n20). PMC\\xa010372638 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10372638).\\nPMID\\xa037463210 (https://pubmed.ncbi.nlm.nih.gov/37463210).\\n153. \"Sanitized open-source datasets for natural language and code understanding: how we\\nevaluated our 70B model\" (https://imbue.com/research/70b-evals/). imbue.com. Archived (ht\\ntps://web.archive.org/web/20240726173012/https://imbue.com/research/70b-evals/) from\\nthe original on 2024-07-26. Retrieved 2024-07-24.\\n154. Srivastava, Aarohi; et\\xa0al. (2022). \"Beyond the Imitation Game: Quantifying and extrapolating\\nthe capabilities of language models\". TMLR. arXiv:2206.04615 (https://arxiv.org/abs/2206.04\\n615).\\n155. Niven, Timothy; Kao, Hung-Yu (2019). \"Probing Neural Network Comprehension of Natural\\nLanguage Arguments\" (https://aclanthology.org/P19-1459/). ACL: 4658‚Äì4664.\\ndoi:10.18653/v1/P19-1459 (https://doi.org/10.18653%2Fv1%2FP19-1459).\\n156. Lin, Stephanie; Hilton, Jacob; Evans, Owain (2021). \"TruthfulQA: Measuring How Models\\nMimic Human Falsehoods\". ACL. arXiv:2109.07958 (https://arxiv.org/abs/2109.07958).\\n157. Zellers, Rowan; Holtzman, Ari; Bisk, Yonatan; Farhadi, Ali; Choi, Yejin (2019). \"HellaSwag:\\nCan a Machine Really Finish Your Sentence?\". ACL. arXiv:1905.07830 (https://arxiv.org/ab\\ns/1905.07830).\\n158. \"Extracting Training Data from Large Language Models\" (https://www.usenix.org/system/file\\ns/sec21-carlini-extracting.pdf) (PDF). USENIX Security. 2021.\\n159. Xu, Weijie; Wang, Yiwen; Xue, Chi; Hu, Xiangkun; Fang, Xi; Dong, Guimin; Reddy, Chandan\\nK. (2025-06-28). \"Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical\\nPerspective\". COLM. arXiv:2506.19028 (https://arxiv.org/abs/2506.19028).\\n160. \"Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word\\nEmbeddings\" (https://proceedings.neurips.cc/paper_files/paper/2016/file/a486cd07e4ac3d2\\n70571622f4f316ec5-Paper.pdf) (PDF). NeurIPS. 2016.\\n161. Bender, Emily M.; Gebru, Timnit; McMillan-Major, Margaret (2021-03-03). \"On the Dangers\\nof Stochastic Parrots: Can Language Models Be Too Big?\" (https://s10251.pcdn.co/pdf/2021\\n-bender-parrots.pdf) (PDF). FAccT. Retrieved 2025-10-02.\\n162. \"A Perspectival Mirror of the Elephant\" (https://cacm.acm.org/practice/a-perspectival-mirror-\\nof-the-elephant/). Communications of the ACM. 2024-07-22.\\n163. Hofmann, Valentin; Kalluri, Pratyusha Ria; Jurafsky, Dan; King, Sharese (2024-09-05). \"AI\\ngenerates covertly racist decisions about people based on their dialect\" (https://www.ncbi.nl\\nm.nih.gov/pmc/articles/PMC11374696). Nature. 633 (8028): 147‚Äì154.\\nBibcode:2024Natur.633..147H (https://ui.adsabs.harvard.edu/abs/2024Natur.633..147H).\\ndoi:10.1038/s41586-024-07856-5 (https://doi.org/10.1038%2Fs41586-024-07856-5).\\nISSN\\xa00028-0836 (https://search.worldcat.org/issn/0028-0836). PMC\\xa011374696 (https://www.\\nncbi.nlm.nih.gov/pmc/articles/PMC11374696). PMID\\xa039198640 (https://pubmed.ncbi.nlm.ni\\nh.gov/39198640).\\n164. Wang, Angelina; Morgenstern, Jamie; Dickerson, John P. (17 February 2025). \"Large\\nlanguage models that replace human participants can harmfully misportray and flatten\\nidentity groups\". Nature Machine Intelligence. 7 (3): 400‚Äì411. arXiv:2402.01908 (https://arxi\\nv.org/abs/2402.01908). doi:10.1038/s42256-025-00986-z (https://doi.org/10.1038%2Fs4225\\n6-025-00986-z).\\n165. Cheng, Myra; Durmus, Esin; Jurafsky, Dan (2023-05-29). \"Marked Personas: Using Natural\\nLanguage Prompts to Measure Stereotypes in Language Models\". ACM. arXiv:2305.18189\\n(https://arxiv.org/abs/2305.18189).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 36, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='166. Kotek, Hadas; Dockum, Rikker; Sun, David (2023-11-05). \"Gender bias and stereotypes in\\nLarge Language Models\". Proceedings of the ACM Collective Intelligence Conference (http\\ns://dl.acm.org/doi/10.1145/3582269.3615599). New York, NY, USA: Association for\\nComputing Machinery. pp.\\xa012‚Äì24. arXiv:2308.14921 (https://arxiv.org/abs/2308.14921).\\ndoi:10.1145/3582269.3615599 (https://doi.org/10.1145%2F3582269.3615599). ISBN\\xa0979-8-\\n4007-0113-9.\\n167. Gao, Bufan; Kreiss, Elisa (2025-09-10). \"Measuring Bias or Measuring the Task:\\nUnderstanding the Brittle Nature of LLM Gender Biases\". arXiv:2509.04373 (https://arxiv.or\\ng/abs/2509.04373) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n168. Choi, Hyeong Kyu; Xu, Weijie; Xue, Chi; Eckman, Stephanie; Reddy, Chandan K. (2024-09-\\n27). \"Mitigating Selection Bias with Node Pruning and Auxiliary Options\". arXiv:2409.18857\\n(https://arxiv.org/abs/2409.18857) [cs.AI (https://arxiv.org/archive/cs.AI)].\\n169. Zheng, Chujie; Zhou, Hao; Meng, Fandong; Zhou, Jie; Huang, Minlie (2023-09-07). \"Large\\nLanguage Models Are Not Robust Multiple Choice Selectors\". arXiv:2309.03882 (https://arxi\\nv.org/abs/2309.03882) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n170. Heikkil√§, Melissa (August 7, 2023). \"AI language models are rife with different political\\nbiases\" (https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rif\\ne-with-political-biases/). MIT Technology Review. Retrieved 2023-12-29.\\n171. Amodei, Dario; Olah, Chris; Steinhardt, Jacob; Christiano, Paul; Schulman, John; Man√©,\\nDan (2016-06-21). \"Concrete Problems in AI Safety\". arXiv:1606.06565 (https://arxiv.org/ab\\ns/1606.06565) [cs.AI (https://arxiv.org/archive/cs.AI)].\\n172. Lyons, Jessica (2025-09-26). \"Prompt injection ‚Äì and a $5 domain ‚Äì trick Salesforce\\nAgentforce into leaking sales\" (https://www.theregister.com/2025/09/26/salesforce_agentforc\\ne_forceleak_attack/). The Register. Retrieved 2025-09-26.\\n173. Carlini, Nicholas; Tram√®r, Florian; Wallace, Eric (2021-08-11). \"Extracting Training Data from\\nLarge Language Models\" (https://www.usenix.org/system/files/sec21-carlini-extracting.pdf)\\n(PDF). USENIX Association. Retrieved 2025-10-02.\\n174. Zhao, Yao; Zhang, Yun; Sun, Yong (2023-06-07). \"The debate over understanding in AI\\'s\\nlarge language models\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10068812).\\nProceedings of the National Academy of Sciences. 120 (13) e2215907120.\\narXiv:2306.05499 (https://arxiv.org/abs/2306.05499). Bibcode:2023PNAS..12015907M (http\\ns://ui.adsabs.harvard.edu/abs/2023PNAS..12015907M). doi:10.1073/pnas.2215907120 (htt\\nps://doi.org/10.1073%2Fpnas.2215907120). PMC\\xa010068812 (https://www.ncbi.nlm.nih.gov/p\\nmc/articles/PMC10068812). PMID\\xa036943882 (https://pubmed.ncbi.nlm.nih.gov/36943882).\\n175. Buolamwini, Joy; Gebru, Timnit (2018-01-01). \"Gender Shades: Intersectional Accuracy\\nDisparities in Commercial Gender Classification\" (https://proceedings.mlr.press/v81/buolam\\nwini18a/buolamwini18a.pdf) (PDF). Proceedings of Machine Learning Research (FAT*).\\nRetrieved 2025-10-02.\\n176. Yang, Kaiqi (2024-11-01). \"Unpacking Political Bias in Large Language Models: A Cross-\\nModel Comparison on U.S. Politics\". arXiv:2412.16746 (https://arxiv.org/abs/2412.16746)\\n[cs.CY (https://arxiv.org/archive/cs.CY)].\\n177. Strubell, Emma; Ganesh, Ananya; McCallum, Andrew (2019-07-28). \"Energy and Policy\\nConsiderations for Deep Learning in NLP\" (https://aclanthology.org/P19-1355.pdf) (PDF).\\nACL Anthology. Retrieved 2025-10-02.\\n178. He, Yuhao; Yang, Li; Qian, Chunlian; Li, Tong; Su, Zhengyuan; Zhang, Qiang; Hou,\\nXiangqing (2023-04-28). \"Conversational Agent Interventions for Mental Health Problems:\\nSystematic Review and Meta-analysis of Randomized Controlled Trials\" (https://www.ncbi.nl\\nm.nih.gov/pmc/articles/PMC10182468). Journal of Medical Internet Research. 25 e43862.\\ndoi:10.2196/43862 (https://doi.org/10.2196%2F43862). PMC\\xa010182468 (https://www.ncbi.nl\\nm.nih.gov/pmc/articles/PMC10182468). PMID\\xa037115595 (https://pubmed.ncbi.nlm.nih.gov/3\\n7115595).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 37, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='179. Pauketat, Janet V.T.; Ladak, Ali; Anthis, Jacy Reese (2025). \"World-Making for a Future with\\nSentient AI\" (https://www.sentienceinstitute.org/downloads/World-Making-for-a-Future-with-\\nSentient-AI.pdf) (PDF). The British Journal of Social Psychology. 64 (1) e12844.\\ndoi:10.1111/bjso.12844 (https://doi.org/10.1111%2Fbjso.12844). PMID\\xa039737875 (https://pu\\nbmed.ncbi.nlm.nih.gov/39737875). Retrieved 2025-10-02.\\n180. Anthis, Jacy Reese; Pauketat, Janet V.T. (2025). \"Perceptions of Sentient AI and Other\\nDigital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey\". Proceedings of\\nthe 2025 CHI Conference on Human Factors in Computing Systems. pp.\\xa01‚Äì22.\\narXiv:2407.08867 (https://arxiv.org/abs/2407.08867). doi:10.1145/3706598.3713329 (https://\\ndoi.org/10.1145%2F3706598.3713329). ISBN\\xa0979-8-4007-1394-1.\\n181. Amodei, Dario; Olah, Chris; Steinhardt, Jacob (2016-06-17). \"Concrete Problems in AI\\nSafety\". arXiv:1606.06565 (https://arxiv.org/abs/1606.06565) [cs.AI (https://arxiv.org/archive/\\ncs.AI)].\\n182. Alba, Davey (1 May 2023). \"AI chatbots have been used to create dozens of news content\\nfarms\" (https://www.japantimes.co.jp/news/2023/05/01/business/tech/ai-fake-news-content-f\\narms/). The Japan Times. Retrieved 18 June 2023.\\n183. \"Could chatbots help devise the next pandemic virus?\" (https://www.science.org/content/arti\\ncle/could-chatbots-help-devise-next-pandemic-virus). Science. 14 June 2023.\\ndoi:10.1126/science.adj2463 (https://doi.org/10.1126%2Fscience.adj2463). Archived (http\\ns://web.archive.org/web/20230618013834/https://www.science.org/content/article/could-chat\\nbots-help-devise-next-pandemic-virus) from the original on 18 June 2023. Retrieved\\n18 June 2023.\\n184. Kang, Daniel (2023). \"Exploiting programmatic behavior of LLMs: Dual-use through\\nstandard security attacks\" (https://www.computer.org/csdl/proceedings-article/spw/2024/548\\n700a132/1YiWjkbcIMw). IEEE Security and Privacy Workshops. arXiv:2302.05733 (https://a\\nrxiv.org/abs/2302.05733).\\n185. \"Russian propaganda may be flooding AI models\" (https://www.americansunlight.org/update\\ns/new-report-russian-propaganda-may-be-flooding-ai-models). The American Sunlight\\nProject. 26 February 2025. Retrieved 2025-04-11.\\n186. Goudarzi, Sara (2025-03-26). \"Russian networks flood the Internet with propaganda, aiming\\nto corrupt AI chatbots\" (https://thebulletin.org/2025/03/russian-networks-flood-the-internet-wi\\nth-propaganda-aiming-to-corrupt-ai-chatbots/). Bulletin of the Atomic Scientists. Retrieved\\n2025-04-10.\\n187. Wang, Yongge (20 June 2024). \"Encryption Based Covert Channel for Large Language\\nModels\" (https://eprint.iacr.org/2024/586.pdf) (PDF). IACR ePrint 2024/586. Archived (http\\ns://web.archive.org/web/20240624191233/https://eprint.iacr.org/2024/586.pdf) (PDF) from\\nthe original on 24 June 2024. Retrieved 24 June 2024.\\n188. Sharma, Mrinank; Tong, Meg; Korbak, Tomasz (2023-10-20). \"Towards Understanding\\nSycophancy in Language Models\". arXiv:2310.13548 (https://arxiv.org/abs/2310.13548)\\n[cs.CL (https://arxiv.org/archive/cs.CL)].\\n189. Rrv, Aswin; Tyagi, Nemika (2024-08-11). \"Chaos with Keywords: Exposing Large Language\\nModels Sycophancy to Misleading Keywords and Evaluating Defense Strategies\" (https://acl\\nanthology.org/2024.findings-acl.755.pdf) (PDF). ACL Anthology. Retrieved 2025-10-02.\\n190. Salvi, Francesco; Horta Ribeiro, Manoel; Gallotti, Riccardo (19 May 2025). \"On the\\nconversational persuasiveness of GPT-4\" (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC12\\n367540). Nature Human Behaviour. 9 (8): 1645‚Äì1653. doi:10.1038/s41562-025-02194-6 (htt\\nps://doi.org/10.1038%2Fs41562-025-02194-6). PMC\\xa012367540 (https://www.ncbi.nlm.nih.go\\nv/pmc/articles/PMC12367540). PMID\\xa040389594 (https://pubmed.ncbi.nlm.nih.gov/4038959\\n4).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 38, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='191. √òstergaard, S√∏ren Dinesen (2023-08-25). \"Will Generative Artificial Intelligence Chatbots\\nGenerate Delusions in Individuals Prone to Psychosis?\" (https://www.ncbi.nlm.nih.gov/pmc/\\narticles/PMC10686326). Schizophrenia Bulletin. 49 (6): 1418‚Äì1419.\\ndoi:10.1093/schbul/sbad128 (https://doi.org/10.1093%2Fschbul%2Fsbad128).\\nPMC\\xa010686326 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10686326).\\nPMID\\xa037625027 (https://pubmed.ncbi.nlm.nih.gov/37625027).\\n192. Rosenberg, Josh (21 August 2025). \"South Park Calls Out ChatGPT and Useless Tech-Bro\\nSycophants\" (https://www.esquire.com/entertainment/tv/a65861699/south-park-season-27-e\\npisode-3-recap/). Esquire. Retrieved 2025-10-02.\\n193. \"openai-python/chatml.md at v0.27.6 ¬∑ openai/openai-python\" (https://github.com/openai/ope\\nnai-python/blob/v0.27.6/chatml.md). GitHub.\\n194. Douglas, Will (March 3, 2023). \"The inside story of how ChatGPT was built from the people\\nwho made it\" (https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-hist\\nory-how-chatgpt-built-openai/). MIT Technology Review. Archived (https://web.archive.org/w\\neb/20230303093219/https://www.technologyreview.com/2023/03/03/1069311/inside-story-or\\nal-history-how-chatgpt-built-openai/) from the original on March 3, 2023. Retrieved March 6,\\n2023.\\n195. Greshake, Kai; Abdelnabi, Sahar; Mishra, Shailesh; Endres, Christoph; Holz, Thorsten; Fritz,\\nMario (2023-02-01). \"Not What You\\'ve Signed Up For: Compromising Real-World LLM-\\nIntegrated Applications with Indirect Prompt Injection\" (https://dl.acm.org/doi/10.1145/36057\\n64.3623985). Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security.\\npp.\\xa079‚Äì90. doi:10.1145/3605764.3623985 (https://doi.org/10.1145%2F3605764.3623985).\\nISBN\\xa0979-8-4007-0260-0.\\n196. Edwards, Benj (2024-01-15). \"AI poisoning could turn models into destructive \"sleeper\\nagents,\" says Anthropic\" (https://arstechnica.com/information-technology/2024/01/ai-poisoni\\nng-could-turn-open-models-into-destructive-sleeper-agents-says-anthropic/). Ars Technica.\\nRetrieved 2025-07-19.\\n197. \"U.S. judge approves $1.5 billion Anthropic copyright settlement with authors\" (https://www.r\\neuters.com/sustainability/boards-policy-regulation/us-judge-approves-15-billion-anthropic-co\\npyright-settlement-with-authors-2025-09-25/). Reuters. 2025-09-25. Retrieved 2025-09-26.\\n198. \"Anthropic reaches $1.5B settlement with authors over AI copyright claims\" (https://apnews.\\ncom/article/anthropic-authors-copyright-9643064e847a5e88ef6ee8b620b3a44c).\\nAssociated Press. 2025-09-25. Retrieved 2025-09-26.\\n199. \"Meta fends off authors\\' U.S. copyright lawsuit over AI\" (https://www.reuters.com/sustainabili\\nty/boards-policy-regulation/meta-fends-off-authors-us-copyright-lawsuit-over-ai-2025-06-2\\n5/). Reuters. 2025-06-25. Retrieved 2025-06-26.\\n200. \"Meta Scores Victory in AI Copyright Case\" (https://www.wired.com/story/meta-scores-victor\\ny-ai-copyright-case/). Wired. 2025-06-25. Retrieved 2025-06-26.\\n201. \"OpenAI defeats news outlets\\' copyright lawsuit over AI training for now\" (https://www.reuter\\ns.com/legal/litigation/openai-defeats-news-outlets-copyright-lawsuit-over-ai-training-now-202\\n4-11-07/). Reuters. 2024-11-07. Retrieved 2024-11-08.\\n202. \"OpenAI erases evidence in training data lawsuit\" (https://www.theverge.com/2024/11/21/24\\n302606/openai-erases-evidence-in-training-data-lawsuit). The Verge. 2024-11-21. Retrieved\\n2024-11-22.\\n203. Peng, Zhencan; Wang, Zhizhi; Deng, Dong (13 June 2023). \"Near-Duplicate Sequence\\nSearch at Scale for Large Language Model Memorization Evaluation\" (https://people.cs.rutg\\ners.edu/~dd903/assets/papers/sigmod23.pdf) (PDF). Proceedings of the ACM on\\nManagement of Data. 1 (2): 1‚Äì18. doi:10.1145/3589324 (https://doi.org/10.1145%2F358932\\n4). S2CID\\xa0259213212 (https://api.semanticscholar.org/CorpusID:259213212). Archived (http\\ns://web.archive.org/web/20240827053753/https://people.cs.rutgers.edu/~dd903/assets/pape\\nrs/sigmod23.pdf) (PDF) from the original on 2024-08-27. Retrieved 2024-01-20. Citing Lee\\net al 2022.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 39, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='204. Peng, Wang & Deng 2023, p.\\xa08.\\n205. Stephen Council (1 Dec 2023). \"How Googlers cracked an SF rival\\'s tech model with a\\nsingle word\" (https://www.sfgate.com/tech/article/google-openai-chatgpt-break-model-18525\\n445.php). SFGate. Archived (https://web.archive.org/web/20231216160941/https://www.sfga\\nte.com/tech/article/google-openai-chatgpt-break-model-18525445.php) from the original on\\n16 December 2023.\\n206. \"Prepare for truly useful large language models\" (https://doi.org/10.1038%2Fs41551-023-01\\n012-6). Nature Biomedical Engineering. 7 (2): 85‚Äì86. 7 March 2023. doi:10.1038/s41551-\\n023-01012-6 (https://doi.org/10.1038%2Fs41551-023-01012-6). PMID\\xa036882584 (https://pu\\nbmed.ncbi.nlm.nih.gov/36882584). S2CID\\xa0257403466 (https://api.semanticscholar.org/Corp\\nusID:257403466).\\n207. Brinkmann, Levin; Baumann, Fabian; Bonnefon, Jean-Fran√ßois; Derex, Maxime; M√ºller,\\nThomas F.; Nussberger, Anne-Marie; Czaplicka, Agnieszka; Acerbi, Alberto; Griffiths,\\nThomas L.; Henrich, Joseph; Leibo, Joel Z.; McElreath, Richard; Oudeyer, Pierre-Yves;\\nStray, Jonathan; Rahwan, Iyad (2023-11-20). \"Machine culture\" (https://www.nature.com/arti\\ncles/s41562-023-01742-2). Nature Human Behaviour. 7 (11): 1855‚Äì1868. arXiv:2311.11388\\n(https://arxiv.org/abs/2311.11388). doi:10.1038/s41562-023-01742-2 (https://doi.org/10.103\\n8%2Fs41562-023-01742-2). ISSN\\xa02397-3374 (https://search.worldcat.org/issn/2397-3374).\\nPMID\\xa037985914 (https://pubmed.ncbi.nlm.nih.gov/37985914).\\n208. Niederhoffer, Kate; Kellerman, Gabriella Rosen; Lee, Angela; Liebscher, Alex; Rapuano,\\nKristina; Hancock, Jeffrey T. (2025-09-25). \"AI-Generated \"Workslop\" Is Destroying\\nProductivity\" (https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity).\\nHarvard Business Review. Retrieved 2025-09-22.\\n209. Acar, Oguz A.; Gai, Phyliss Jia; Tu, Yanping; Hou, Jiayi (2025-08-01). \"Research: The\\nHidden Penalty of Using AI at Work\" (https://hbr.org/2025/08/research-the-hidden-penalty-of\\n-using-ai-at-work). Harvard Business Review. Retrieved 2025-09-22.\\n210. You, Josh (February 7, 2025). \"How much energy does ChatGPT use?\" (https://epoch.ai/gra\\ndient-updates/how-much-energy-does-chatgpt-use). Epoch AI. Retrieved 11 November\\n2025.\\n211. \"Power Hungry: How AI Will Drive Energy Demand\" (https://www.imf.org/en/Publications/W\\nP/Issues/2025/04/21/Power-Hungry-How-AI-Will-Drive-Energy-Demand-566304). IMF.\\nRetrieved 2025-10-08.\\n212. Mehta, Sourabh (2024-07-03). \"How Much Energy Do LLMs Consume? Unveiling the Power\\nBehind AI\" (https://adasci.org/how-much-energy-do-llms-consume-unveiling-the-power-behi\\nnd-ai/). Association of Data Scientists. Retrieved 2025-01-27.\\n213. Luccioni, Sasha; Jernite, Yacine; Strubell, Emma (2024). \"Power Hungry Processing: Watts\\nDriving the Cost of AI Deployment?\". The 2024 ACM Conference on Fairness Accountability\\nand Transparency. pp.\\xa085‚Äì99. arXiv:2311.16863 (https://arxiv.org/abs/2311.16863).\\ndoi:10.1145/3630106.3658542 (https://doi.org/10.1145%2F3630106.3658542). ISBN\\xa0979-8-\\n4007-0450-5.\\n214. Edwards, Benj (2025-03-26). \"Open source devs say AI crawlers dominate traffic, forcing\\nblocks on entire countries\" (https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-domina\\nte-traffic-forcing-blocks-on-entire-countries/). Ars Technica. Retrieved 2025-12-31.\\n215. Claburn, Thomas (2025-03-18). \"AI crawlers haven\\'t learned to play nice with websites\" (htt\\nps://www.theregister.com/2025/03/18/ai_crawlers_sourcehut/). The Register. Retrieved\\n2025-12-31.\\n216. Belanger, Ashley (2025-01-29). \"AI haters build tarpits to trap and trick AI scrapers that\\nignore robots.txt\" (https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-\\nand-trick-ai-scrapers-that-ignore-robots-txt/). Ars Technica. Retrieved 2025-12-31.\\n217. Zao-Sanders, Marc (2024-03-19). \"How People Are Really Using GenAI\" (https://hbr.org/202\\n4/03/how-people-are-really-using-genai). Harvard Business Review. ISSN\\xa00017-8012 (http\\ns://search.worldcat.org/issn/0017-8012). Retrieved 2025-08-10.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 40, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='218. Rousmaniere, Tony; Zhang, Yimeng; Li, Xu; Shah, Siddharth (2025-07-21). \"Large language\\nmodels as mental health resources: Patterns of use in the United States\" (https://doi.apa.or\\ng/doi/10.1037/pri0000292). Practice Innovations. doi:10.1037/pri0000292 (https://doi.org/10.\\n1037%2Fpri0000292). ISSN\\xa02377-8903 (https://search.worldcat.org/issn/2377-8903).\\n219. Ji, Shaoxiong; Zhang, Tianlin; Yang, Kailai; Ananiadou, Sophia; Cambria, Erik (2023-12-17).\\n\"Rethinking Large Language Models in Mental Health Applications\". arXiv:2311.11267 (http\\ns://arxiv.org/abs/2311.11267) [cs.CL (https://arxiv.org/archive/cs.CL)].\\n220. Moore, Jared; Grabb, Declan; Agnew, William; Klyman, Kevin; Chancellor, Stevie; Ong,\\nDesmond C.; Haber, Nick (2025-04-25). \"Expressing stigma and inappropriate responses\\nprevents LLMS from safely replacing mental health providers\". Proceedings of the 2025\\nACM Conference on Fairness, Accountability, and Transparency. pp.\\xa0599‚Äì627.\\narXiv:2504.18412 (https://arxiv.org/abs/2504.18412). doi:10.1145/3715275.3732039 (https://\\ndoi.org/10.1145%2F3715275.3732039). ISBN\\xa0979-8-4007-1482-5.\\n221. Grabb, Declan; Lamparth, Max; Vasan, Nina (2024-08-14). \"Risks from Language Models\\nfor Automated Mental Healthcare: Ethics and Structure for Implementation\".\\narXiv:2406.11852 (https://arxiv.org/abs/2406.11852) [cs.CY (https://arxiv.org/archive/cs.C\\nY)].\\n222. McBain, Ryan K.; Cantor, Jonathan H.; Zhang, Li Ang; Baker, Olesya; Zhang, Fang;\\nHalbisen, Alyssa; Kofner, Aaron; Breslau, Joshua; Stein, Bradley; Mehrotra, Ateev; Yu, Hao\\n(2025-03-05). \"Competency of Large Language Models in Evaluating Appropriate\\nResponses to Suicidal Ideation: Comparative Study\" (https://www.ncbi.nlm.nih.gov/pmc/artic\\nles/PMC11928068). Journal of Medical Internet Research. 27 (1) e67891.\\ndoi:10.2196/67891 (https://doi.org/10.2196%2F67891). PMC\\xa011928068 (https://www.ncbi.nl\\nm.nih.gov/pmc/articles/PMC11928068). PMID\\xa040053817 (https://pubmed.ncbi.nlm.nih.gov/4\\n0053817).\\n223. Li, Fei-Fei; Etchemendy, John (2024-05-22). \"No, Today\\'s AI Isn\\'t Sentient. Here\\'s How We\\nKnow\" (https://time.com/6980134/ai-llm-not-sentient/). Time. Retrieved 2024-05-22.\\n224. Chalmers, David J. (August 9, 2023). \"Could a Large Language Model Be Conscious?\" (http\\ns://www.bostonreview.net/articles/could-a-large-language-model-be-conscious/). Boston\\nReview.\\n225. Thomson, Jonny (2022-10-31). \"Why don\\'t robots have rights?\" (https://bigthink.com/thinkin\\ng/why-dont-robots-have-rights). Big Think. Archived (https://web.archive.org/web/202409130\\n55336/https://bigthink.com/thinking/why-dont-robots-have-rights/) from the original on 13\\nSeptember 2024. Retrieved 2024-02-23.\\n226. Kateman, Brian (2023-07-24). \"AI Should Be Terrified of Humans\" (https://time.com/629623\\n4/ai-should-be-terrified-of-humans). Time. Archived (https://web.archive.org/web/202409250\\n41601/https://time.com/6296234/ai-should-be-terrified-of-humans/) from the original on 25\\nSeptember 2024. Retrieved 2024-02-23.\\n227. Metzinger, Thomas (2021). \"Artificial Suffering: An Argument for a Global Moratorium on\\nSynthetic Phenomenology\" (https://doi.org/10.1142%2FS270507852150003X). Journal of\\nArtificial Intelligence and Consciousness. 08: 43‚Äì66. doi:10.1142/S270507852150003X (htt\\nps://doi.org/10.1142%2FS270507852150003X). S2CID\\xa0233176465 (https://api.semanticsch\\nolar.org/CorpusID:233176465).\\n228. Tkachenko, Yegor (2024). \"Position: Enforced Amnesia as a Way to Mitigate the Potential\\nRisk of Silent Suffering in the Conscious AI\" (https://proceedings.mlr.press/v235/tkachenko2\\n4a.html). ICML. 235: 48362‚Äì48368.\\n229. Leith, Sam (2022-07-09). \"Nick Bostrom: How can we be certain a machine isn\\'t\\nconscious?\" (https://www.spectator.co.uk/article/nick-bostrom-how-can-we-be-certain-a-mac\\nhine-isnt-conscious/). The Spectator. Retrieved 2025-09-22.\\n230. Chalmers, David (1995). \"Facing up to the problem of consciousness\". Journal of\\nConsciousness Studies. 2 (3): 200‚Äì219. CiteSeerX\\xa010.1.1.103.8362 (https://citeseerx.ist.ps\\nu.edu/viewdoc/summary?doi=10.1.1.103.8362).'),\n",
       " Document(metadata={'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:33:50+00:00', 'source': '../data/PDF_files/Large_language_model.pdf', 'file_path': '../data/PDF_files/Large_language_model.pdf', 'total_pages': 42, 'format': 'PDF 1.4', 'title': 'Large language model - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:33:50+00:00', 'trapped': '', 'modDate': \"D:20260113133350+00'00'\", 'creationDate': \"D:20260113133350+00'00'\", 'page': 41, 'source_file': 'Large_language_model.pdf', 'source_path': '../data/PDF_files/Large_language_model.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}, page_content='231. Maruf, Ramishah (2022-07-25). \"Google fires engineer who contended its AI technology was\\nsentient\" (https://www.cnn.com/2022/07/23/business/google-ai-engineer-fired-sentient).\\nCNN. Retrieved 2025-09-22.\\nJurafsky, Dan, Martin, James. H. Speech and Language Processing: An Introduction to\\nNatural Language Processing, Computational Linguistics, and Speech Recognition (https://\\nweb.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf), 3rd Edition draft, 2023.\\nYin, Shukang; Fu, Chaoyou; Zhao, Sirui; Li, Ke; Sun, Xing; Xu, Tong; Chen, Enhong (2024).\\n\"A Survey on Multimodal Large Language Models\" (https://www.ncbi.nlm.nih.gov/pmc/article\\ns/PMC11645129). National Science Review. 11 (12) nwae403. arXiv:2306.13549 (https://ar\\nxiv.org/abs/2306.13549). doi:10.1093/nsr/nwae403 (https://doi.org/10.1093%2Fnsr%2Fnwa\\ne403). PMC\\xa011645129 (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11645129).\\nPMID\\xa039679213 (https://pubmed.ncbi.nlm.nih.gov/39679213).\\n\"AI Index Report 2024 ‚Äì Artificial Intelligence Index\" (https://aiindex.stanford.edu/report/).\\naiindex.stanford.edu. Retrieved 2024-05-05.\\nFrank, Michael C. (27 June 2023). \"Baby steps in evaluating the capacities of large\\nlanguage models\" (https://www.nature.com/articles/s44159-023-00211-x). Nature Reviews\\nPsychology. 2 (8): 451‚Äì452. doi:10.1038/s44159-023-00211-x (https://doi.org/10.1038%2Fs\\n44159-023-00211-x). ISSN\\xa02731-0574 (https://search.worldcat.org/issn/2731-0574).\\nS2CID\\xa0259713140 (https://api.semanticscholar.org/CorpusID:259713140). Retrieved 2 July\\n2023.\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Large_language_model&oldid=1332687263\"\\nFurther reading')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def document_split(documents, chunk_size= 500, chunk_overlap = 100):\n",
    "    \"\"\"\n",
    "    Split documents into overlapping text chunks.\n",
    "\n",
    "    Args:\n",
    "        documents: LangChain documents\n",
    "        size: Chunk size (characters)\n",
    "        chunk_overlap: Overlap between chunks\n",
    "\n",
    "    Returns:\n",
    "        Chunked documents\n",
    "    \"\"\"\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    split_docs = splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"Split {len(documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"Sample content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Sample metadata: {split_docs[0].metadata}\")\n",
    "\n",
    "    return split_docs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 51 documents into 457 chunks\n",
      "Sample content: Attention mechanism, overview\n",
      "Attention (machine learning)\n",
      "In machine learning, attention is a method that determines the importance of each component in a sequence relative\n",
      "to the other components in...\n",
      "Sample metadata: {'producer': 'Skia/PDF m143', 'creator': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/143.0.0.0 Safari/537.36', 'creationdate': '2026-01-13T13:32:44+00:00', 'source': '../data/PDF_files/Attention.pdf', 'file_path': '../data/PDF_files/Attention.pdf', 'total_pages': 8, 'format': 'PDF 1.4', 'title': 'Attention (machine learning) - Wikipedia', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2026-01-13T13:32:44+00:00', 'trapped': '', 'modDate': \"D:20260113133244+00'00'\", 'creationDate': \"D:20260113133244+00'00'\", 'page': 0, 'source_file': 'Attention.pdf', 'source_path': '../data/PDF_files/Attention.pdf', 'file_type': 'pdf', 'loader': 'PyMuPDFLoader'}\n"
     ]
    }
   ],
   "source": [
    "documents = document_split(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector database and embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "import numpy as np \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Any, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model all-MiniLm-L6-v2\n",
      "Model all-MiniLm-L6-v2 loaded successfully!\n",
      "Embedding dimensions 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingHandler at 0x177f51b90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class EmbeddingHandler:\n",
    "    def __init__(self, model_name = \"all-MiniLm-L6-v2\"):\n",
    "        ##Here we initialise the embedding handler\n",
    "        ## Args: model_name is an imported HuggingFace LLM for sentence embedding\n",
    "        self.name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    \n",
    "    def _load_model(self):\n",
    "        # function for loading the SentenceTransformer\n",
    "        try:\n",
    "            print(f\"Loading model {self.name}\")\n",
    "            self.model = SentenceTransformer(self.name)\n",
    "            print(f\"Model {self.name} loaded successfully!\")\n",
    "            print(f\"Embedding dimensions {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e} while loading model {self.name}\")\n",
    "\n",
    "    \n",
    "\n",
    "    def embedding_generation(self, text):\n",
    "        # Creates the embeddings for the given texts\n",
    "        # Embeddings are numpy array with shape ((Len(text), embedding_dimension)\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model is not loaded!\")\n",
    "\n",
    "\n",
    "        print(f\"EMbedding generation for {len(text)} texts\")\n",
    "        \n",
    "        embeddings = self.model.encode(text, show_progress_bar= True)\n",
    "        print(\"Embeddings created successfully!\")\n",
    "        print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "\n",
    "embedding_handler = EmbeddingHandler()\n",
    "embedding_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorStore initialized successfully!\n",
      "Documents in the collection pdf_documents: 457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x15851c810>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name = \"pdf_documents\", persist_directory = \"../data/VectorStore\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.dir = persist_directory\n",
    "        self._initialize_store()\n",
    "\n",
    "    \n",
    "    def _initialize_store(self):\n",
    "        try: \n",
    "            os.makedirs(self.dir,exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.dir)\n",
    "\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata= {\"description\": \"RAG's PDF embeddings\"}\n",
    "            )\n",
    "\n",
    "            print(f\"VectorStore initialized successfully!\")\n",
    "            print(f\"Documents in the collection {self.collection_name}: {self.collection.count()}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error while initializing VectorStore {e}\")\n",
    "        \n",
    "    \n",
    "    def add_documents(self, documents, embeddings):\n",
    "\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Embeddings and documents counts don't align\")\n",
    "\n",
    "        ids, metadatas, texts, vectors = [], [], [], []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            ids.append(f\"doc_{uuid.uuid4().hex[:8]}_{i}\")\n",
    "\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata[\"document_index\"] = i\n",
    "            metadata[\"content_length\"] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            texts.append(doc.page_content)\n",
    "            vectors.append(embedding.tolist())\n",
    "\n",
    "        self.collection.add(\n",
    "            ids=ids,\n",
    "            embeddings=vectors,\n",
    "            metadatas=metadatas,\n",
    "            documents=texts,\n",
    "        )\n",
    "\n",
    "        print(f\"Added {len(documents)} documents to VectorStore\")\n",
    "        print(f\"Total documents: {self.collection.count()}\")\n",
    "\n",
    "        \n",
    "vectorStore = VectorStore()\n",
    "\n",
    "vectorStore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMbedding generation for 457 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:04<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created successfully!\n",
      "Embeddings shape: (457, 384)\n",
      "Added 457 documents to VectorStore\n",
      "Total documents: 914\n"
     ]
    }
   ],
   "source": [
    "content = [doc.page_content for doc in documents]\n",
    "\n",
    "Embedding = embedding_handler.embedding_generation(content)\n",
    "\n",
    "vectorStore.add_documents(documents,Embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag retrieval pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG_retrieval:\n",
    "    def __init__(self,vectorStore,embedding_handler):\n",
    "        self.vectorStore = vectorStore\n",
    "        self.embedding_handler = embedding_handler\n",
    "\n",
    "\n",
    "    def retrieve(self, query, k = 5, threshold = 0):\n",
    "\n",
    "        # Retrieves the top documents from the VectorStore for the given query\n",
    "\n",
    "        embeddings_query = self.embedding_handler.embedding_generation([query])[0]\n",
    "\n",
    "        try:\n",
    "            results = self.vectorStore.collection.query(\n",
    "                embeddings_queries = [embeddings_query.tolist()],\n",
    "                n_results=k\n",
    "            )\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distance = results['distance'][0]\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids,documents,metadatas,distance)):\n",
    "\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id':doc_id, \n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i + 1\n",
    "                        })\n",
    "                    \n",
    "                        print(f\"Retrieved {len(retrieved_docs)} documents\")\n",
    "\n",
    "                    else:\n",
    "                        print(\"Zero documents found\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Retrieval error {e}\")\n",
    "        \n",
    "        return retrieved_docs\n",
    "\n",
    "\n",
    "retriever = RAG_retrieval(vectorStore,embedding_handler)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetrieval:\n",
    "    def __init__(self, vector_store, embedding_handler, metric=\"cosine\"):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_handler = embedding_handler\n",
    "        self.metric = metric\n",
    "    \n",
    "\n",
    "    def retrieve(self, query, k = 5, threshold= 0.0):\n",
    "        \"\"\"\n",
    "        Retrieve top-k documents for a query.\n",
    "\n",
    "        \"\"\"\n",
    "        print(f\"retieve docs for query: {query}\")\n",
    "        \n",
    "        query_embedding = self.embedding_handler.embedding_generation([query])[0]\n",
    "        try:\n",
    "\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=k,\n",
    "            )\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if not results.get(\"documents\") or not results[\"documents\"][0]:\n",
    "                return []\n",
    "\n",
    "            documents = results[\"documents\"][0]\n",
    "            metadatas = results[\"metadatas\"][0]\n",
    "            distances = results[\"distances\"][0]\n",
    "            ids = results[\"ids\"][0]\n",
    "\n",
    "            for rank, (doc_id, content, metadata, distance) in enumerate(\n",
    "                zip(ids, documents, metadatas, distances), start=1\n",
    "            ):\n",
    "                if self.metric == \"cosine\":\n",
    "                    similarity_score = 1 - distance\n",
    "                else:\n",
    "                    similarity_score = None  # leave raw distance only\n",
    "\n",
    "                if similarity_score is None or similarity_score >= threshold:\n",
    "                    retrieved_docs.append({\n",
    "                        \"id\": doc_id,\n",
    "                        \"content\": content,\n",
    "                        \"metadata\": metadata,\n",
    "                        \"distance\": distance,\n",
    "                        \"similarity_score\": similarity_score,\n",
    "                        \"rank\": rank,\n",
    "                    })\n",
    "\n",
    "            return retrieved_docs\n",
    "\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Retrieval failed: {e}\")\n",
    "\n",
    "retriever = RAGRetrieval(vectorStore,embedding_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retieve docs for query: What is attention mechanism?\n",
      "EMbedding generation for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created successfully!\n",
      "Embeddings shape: (1, 384)\n",
      "34. Soydaner, Derya (August 2022). \"Attention mechanism in neural\n",
      "networks: where it comes and where it goes\" (https://link.springer.c\n",
      "om/10.1007/s00521-022-07366-3). Neural Computing and\n",
      "Applications. 34 (16): 13371‚Äì13385. arXiv:2204.13154 (https://arxi\n",
      "v.org/abs/2204.13154). doi:10.1007/s00521-022-07366-3 (https://do\n",
      "i.org/10.1007%2Fs00521-022-07366-3). ISSN¬†0941-0643 (https://s\n",
      "earch.worldcat.org/issn/0941-0643).\n",
      "35. Britz, Denny; Goldie, Anna; Luong, Minh-Thanh; Le, Quoc (2017-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.retrieve(\"What is attention mechanism?\")\n",
    "print(docs[1]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(retrieved_docs, max_chars=3000):\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in retrieved_docs:\n",
    "        source = doc[\"metadata\"].get(\"source_file\", \"unknown\")\n",
    "        chunk = doc[\"content\"]\n",
    "\n",
    "        entry = f\"\\n[Source: {source}]\\n{chunk}\\n\"\n",
    "\n",
    "        if len(context) + len(entry) > max_chars:\n",
    "            break\n",
    "\n",
    "        context += entry\n",
    "\n",
    "    return context.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGPipeline:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "\n",
    "    def run(self, query, k=5):\n",
    "        docs = self.retriever.retrieve(query, k=k)\n",
    "\n",
    "        if not docs:\n",
    "            return \"No relevant documents found.\"\n",
    "\n",
    "        context = build_context(docs)\n",
    "        return self.llm.generate(query, context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "class OpenAILLM:\n",
    "    def __init__(self, model=\"gpt-4o-mini\"):\n",
    "        self.client = OpenAI(api_key=os.getenv(\"rag_key\"))\n",
    "        self.model = model\n",
    "\n",
    "    def generate(self, query, context):\n",
    "        prompt = f\"\"\"\n",
    "                    Answer the question using ONLY the context below.\n",
    "                    If the answer is not contained, say \"I don't know\".\n",
    "\n",
    "                    Context:\n",
    "                    {context}\n",
    "\n",
    "                    Question:\n",
    "                    {query}\n",
    "                \"\"\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a factual assistant grounded in retrieved documents.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.1\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retieve docs for query: What is the attention mechanism?\n",
      "EMbedding generation for 1 texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created successfully!\n",
      "Embeddings shape: (1, 384)\n",
      "The attention mechanism is a method in machine learning that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, this importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILLM()\n",
    "rag = RAGPipeline(retriever, llm)\n",
    "\n",
    "print(rag.run(\"What is the attention mechanism?\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
